---
layout: notion
title: "Test-Time Learning for Large Language Models"
description:
date: 2025-07-14 21:25:46 +09:00
tags: AI
categories: Paper
giscus_comments: true
related_posts: false

featured: false
pretty_table: true

toc:
  beginning: false  # 맨 앞에 목차
  sidebar: left  # 목차가 사이드바 왼쪽에 붙어있음
---
<div class="page-body"><table id="228451cf-7b79-800d-bf86-c79f3d2a2615" class="simple-table"><tbody><tr id="228451cf-7b79-805d-980b-ff8b78824400"><th id="MApI" class="simple-table-header-color simple-table-header" style="width:125.5px">ArXiv</th><td id="L|H:" class="" style="width:580.5px"><a href="https://arxiv.org/abs/2505.20633">https://arxiv.org/abs/2505.20633</a></td></tr><tr id="228451cf-7b79-80d6-8c6f-daa59183b94f"><th id="MApI" class="simple-table-header-color simple-table-header" style="width:125.5px">Project Page</th><td id="L|H:" class="" style="width:580.5px"></td></tr><tr id="228451cf-7b79-8089-bbe5-d4dd3c3bc5f4"><th id="MApI" class="simple-table-header-color simple-table-header" style="width:125.5px">Github Code</th><td id="L|H:" class="" style="width:580.5px"></td></tr></tbody></table><figure class="block-color-teal_background callout" style="white-space:pre-wrap;display:flex" id="228451cf-7b79-80c0-acd7-fa4383b79091"><div style="font-size:1.5em"><span class="icon">💡</span></div><div style="width:100%"><strong>Key Differentiator</strong><br>Perplexity Minimization<br>기존 TTA (ex. Tent, EATA, COME)는 전부 <strong>entropy minimization</strong> 기반<br>→ 출력 분포의 불확실성을 낮추는 방향<br>하지만 이 논문은 <strong>LLM의 autoregressive 구조</strong>를 고려해<br>→ 출력 entropy가 아니라 <strong>입력 perplexity를 최소화</strong>하는 완전히 다른 objective를 제안</div></figure><p id="228451cf-7b79-80ac-8355-e2df159c9edb" class="">
</p><h2 id="228451cf-7b79-8069-b876-f517d055bf9d" class="">2. Related Work</h2><p id="22b451cf-7b79-8057-b85b-f612da90620e" class="">기존 방법들의 특징과 LLM에서의 한계</p><p id="22b451cf-7b79-80ed-bf02-dabf2515d36f" class="">
</p><h3 id="228451cf-7b79-80b1-8eab-eea3d94e8d10" class=""><strong>Fine-tuning</strong></h3><p id="228451cf-7b79-8093-9704-e2652b31e113" class="">: 라벨된 데이터를 기반으로 모델 파라미터를 업데이트</p><p id="228451cf-7b79-8028-8cb1-d8e61caf0731" class="">→ 라벨링 비용이 크고, 현실에서 계속해서 라벨된 데이터를 구하기 힘듦</p><p id="22b451cf-7b79-8024-aa59-e40974b3ac58" class="">
</p><h3 id="228451cf-7b79-8060-95a7-f6be2b99ddcc" class=""><strong>RAG (Retrieval-Augmented Generation)</strong></h3><p id="228451cf-7b79-802d-8528-c9348f82fdb1" class="">: 외부 지식 베이스에서 관련 정보를 찾아와 응답에 반영</p><p id="228451cf-7b79-80cd-9319-cd8664844426" class="">→ 검색 품질에 의존 + 검색 비용 있음</p><p id="22b451cf-7b79-8096-a355-ef77f22c55f5" class="">
</p><h3 id="228451cf-7b79-80d3-8616-ffdf47dcc54a" class=""><strong>TTT (Test-Time Training)</strong></h3><p id="228451cf-7b79-80b2-8fdd-c458256d278e" class="">: 훈련 데이터나 knowledge base에서 유사한 데이터를 찾아서 모델을 미세 조정</p><p id="228451cf-7b79-800e-a381-e3753bc18e28" class="">→ 훈련 데이터 접근 필요 + 검색 과정이 느림</p><p id="22b451cf-7b79-80d4-98e6-d9435ebe0d98" class="">
</p><h3 id="228451cf-7b79-806e-bd2b-f6b5030fa76e" class=""><strong>TTA (Test-Time Adaptation)</strong></h3><p id="22b451cf-7b79-8036-9885-cf7a0c88ce7b" class="">: 라벨 없는 테스트 데이터를 이용해 모델을 적응시킴</p><p id="22b451cf-7b79-80c5-b51a-e1b2e771c319" class="">
</p><p id="22b451cf-7b79-80cf-8d6b-d0ae3b185971" class="">→ 대부분 <strong>entropy minimization</strong> (출력의 확률 분포를 단일하게 만드는 방식)을 사용</p><p id="22b451cf-7b79-80e9-bf59-f47bc95dce14" class="">→ LLM은 <strong>autoregressive 구조</strong>인데, 이 구조를 무시하고 entropy만 최소화하면 효과가 떨어짐</p><p id="22b451cf-7b79-80d2-aa7e-c43d60607bd5" class="">
</p><hr id="22b451cf-7b79-800f-81bc-ee0e3cee3a40"/><p id="230451cf-7b79-8086-8407-cc24beab462a" class="">
</p><h3 id="230451cf-7b79-805e-8ad1-d0b1d19b8b87" class=""><strong>기존 LLM TTA가 불가능한 이유</strong></h3><ul id="22b451cf-7b79-80d4-bb4d-e00cc1d837c7" class="bulleted-list"><li style="list-style-type:disc">기존 TTA는 주로 BatchNorm 통계(mean/var)를 업데이트하면서 적응</li></ul><ul id="22b451cf-7b79-8063-86d2-c78a9d17f579" class="bulleted-list"><li style="list-style-type:disc">그런데 LLM에는 BatchNorm이 없고 대신 LayerNorm을 쓰고,<p id="22b451cf-7b79-80d0-a1f7-ccf970ff75a7" class="">LayerNorm은 test-time에서 업데이트할 게 없음 → 기존 방식 적용 불가</p></li></ul><p id="22b451cf-7b79-80af-901a-fe22ff50417a" class="">
</p><p id="22b451cf-7b79-801a-9d31-f74b41c0aa98" class=""><strong>그럼 LLM에서는 어떤 test-time 신호가 있는가?</strong></p><p id="22b451cf-7b79-8037-90c1-c09d1596301f" class="">→ 입력 perplexity를 이용해서</p><p id="22b451cf-7b79-8073-90b1-feb1c83fbd42" class="">→ backprop 가능한 self-supervised objective를 설계함</p><p id="22b451cf-7b79-805e-80da-ea2e2cdbba5b" class="">
</p><p id="22b451cf-7b79-8093-9665-c1b6bc4b6983" class="">
</p><hr id="22b451cf-7b79-800e-811f-d68d1ee16165"/><p id="22b451cf-7b79-80c0-abeb-c57e8d13259a" class="">
</p><p id="22b451cf-7b79-80aa-8994-fa63cb4c7425" class="">
</p><h3 id="22b451cf-7b79-80bf-82bd-c566a88da574" class="">Why <span style="border-bottom:0.05em solid">Entropy Minimization </span>Doesn’t Work Well for LLMs?</h3><p id="230451cf-7b79-80cc-8e08-ea5ef940e2f3" class="">
</p><h3 id="22b451cf-7b79-804f-a601-d6a0f9501b1e" class=""><strong>Entropy란?</strong></h3><p id="22b451cf-7b79-807a-8542-d52534288f34" class="">entropy = uncertainty</p><p id="22b451cf-7b79-80fa-a0bc-e6ec970a595a" class="">[0.5, 0.5] → high entropy</p><p id="22b451cf-7b79-805b-9ef8-e6391cc368fc" class="">[0.99, 0.01] → less entropy</p><h3 id="22b451cf-7b79-8027-904a-fc5f2404dd21" class=""><strong>Autoregressive한 LLM은?</strong></h3><p id="22b451cf-7b79-8019-8603-eb9f20de0c39" class="">Predict tokens one by one</p><p id="22b451cf-7b79-8079-984a-dce9ef943987" class="">Each prediction depends on previous tokens</p><p id="22b451cf-7b79-805c-a553-d93f7659651a" class="">Errors accumulate over time</p><div id="22b451cf-7b79-803a-be75-dc152dd1ef88" class="column-list"><div id="22b451cf-7b79-8080-b2fa-df7a1cbaa807" style="width:56.25%" class="column"><h3 id="22b451cf-7b79-800b-8a63-e72445209a53" class=""><strong>문제점</strong></h3><p id="230451cf-7b79-80f2-92b3-c4a928cd37ca" class="">
</p><ul id="22b451cf-7b79-8006-8513-f83cf997efe9" class="bulleted-list"><li style="list-style-type:disc">Ignores token dependencies</li></ul><ul id="22b451cf-7b79-8035-8ca3-c8f240e2eb74" class="bulleted-list"><li style="list-style-type:disc">Optimizes locally, not globally</li></ul><ul id="22b451cf-7b79-8096-aba3-d6e3cb6f63a4" class="bulleted-list"><li style="list-style-type:disc">Early mistakes → later tokens collapse</li></ul><p id="22b451cf-7b79-8038-93ac-f862f030098b" class="">
</p></div><div id="22b451cf-7b79-80ec-a2f1-c9ead77b92d1" style="width:43.75%" class="column"><figure id="22b451cf-7b79-80d4-825f-ca3ab88bf03b" class="image"><a href="/files/2025-07-14-ttl-llm/image.webp"><img style="width:288px" src="/files/2025-07-14-ttl-llm/image.webp"/></a></figure><p id="230451cf-7b79-80cc-8cd6-dec69deb905f" class="">
</p></div></div><p id="22b451cf-7b79-8020-8fd3-d3b4ab3e46fc" class="">
</p><p id="22b451cf-7b79-80cd-a96f-cab01fea9a61" class="">
</p><hr id="22b451cf-7b79-8011-9b3e-edf816abbd60"/><p id="22b451cf-7b79-8016-ad45-e818e1b80858" class="">
</p><h2 id="22b451cf-7b79-80e4-8a54-cf80354bfa81" class="">4.1 Perplexity Minimization for Test-Time Learning</h2><p id="22b451cf-7b79-8019-a676-e5db3decf359" class="">Entropy 기반의 문제점 해결책</p><h3 id="22b451cf-7b79-8012-a037-c4abb7fce194" class=""><strong>perplexity</strong></h3><p id="22b451cf-7b79-809f-bbec-e6992e9dd450" class="">: A metric that measures how confidently a language model predicts a given sequence</p><p id="22b451cf-7b79-8006-ac32-dd5ebd11e917" class="">언어 모델이 <strong>주어진 시퀀스를 얼마나 “자신 있게” 예측했는가</strong>를 측정하는 지표</p><figure id="230451cf-7b79-80e2-86d9-ff48b844df8b" class="equation"><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><div class="equation-container"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><munder><mrow><mi>min</mi><mo>⁡</mo></mrow><mi mathvariant="normal">Θ</mi></munder><mi mathvariant="script">P</mi><mo stretchy="false">(</mo><mi>y</mi><mo>∣</mo><mi>x</mi><mo separator="true">;</mo><mi mathvariant="normal">Θ</mi><mo stretchy="false">)</mo><mo>=</mo><munder><mrow><mi>min</mi><mo>⁡</mo></mrow><mi mathvariant="normal">Θ</mi></munder><msup><mi>e</mi><mrow><mo fence="true">(</mo><mo>−</mo><mfrac><mn>1</mn><mi>T</mi></mfrac><munderover><mo>∑</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mi>T</mi></munderover><mi>log</mi><mo>⁡</mo><mi>p</mi><mo stretchy="false">(</mo><msub><mi>y</mi><mi>t</mi></msub><mo>∣</mo><mi>x</mi><mo separator="true">,</mo><msub><mi>y</mi><mrow><mn>1</mn><mo>:</mo><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo separator="true">;</mo><mi mathvariant="normal">Θ</mi><mo stretchy="false">)</mo><mo fence="true">)</mo></mrow></msup></mrow><annotation encoding="application/x-tex">\min_{\Theta} \mathcal{P}(y \mid x; \Theta) = \min_{\Theta} e^{\left(-\frac{1}{T} \sum_{t=1}^{T} \log p(y_t \mid x, y_{1:t-1}; \Theta) \right)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.4943em;vertical-align:-0.7443em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6679em;"><span style="top:-2.3557em;margin-left:0em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">Θ</span></span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span><span class="mop">min</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.7443em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathcal" style="margin-right:0.08222em;">P</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">x</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">Θ</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.8548em;vertical-align:-0.7443em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6679em;"><span style="top:-2.3557em;margin-left:0em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">Θ</span></span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span><span class="mop">min</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.7443em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:1.1105em;"><span style="top:-3.413em;margin-right:0.05em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="minner mtight"><span class="mopen sizing reset-size3 size6 mtight delimcenter" style="top:0.075em;"><span class="mtight">(</span></span><span class="mord mtight">−</span><span class="mord mtight"><span class="mopen nulldelimiter sizing reset-size3 size6"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8443em;"><span style="top:-2.656em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span><span style="top:-3.2255em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line mtight" style="border-bottom-width:0.049em;"></span></span><span style="top:-3.384em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.344em;"><span></span></span></span></span></span><span class="mclose nulldelimiter sizing reset-size3 size6"></span></span><span class="mspace mtight" style="margin-right:0.1952em;"></span><span class="mop mtight"><span class="mop op-symbol small-op mtight" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9191em;"><span style="top:-2.1786em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-2.931em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3214em;"><span></span></span></span></span></span></span><span class="mspace mtight" style="margin-right:0.1952em;"></span><span class="mop mtight"><span class="mtight">l</span><span class="mtight">o</span><span class="mtight" style="margin-right:0.01389em;">g</span></span><span class="mspace mtight" style="margin-right:0.1952em;"></span><span class="mord mathnormal mtight">p</span><span class="mopen mtight">(</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2963em;"><span style="top:-2.357em;margin-left:-0.0359em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mrel mtight">∣</span><span class="mord mathnormal mtight">x</span><span class="mpunct mtight">,</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3173em;"><span style="top:-2.357em;margin-left:-0.0359em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mrel mtight">:</span><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2025em;"><span></span></span></span></span></span></span><span class="mpunct mtight">;</span><span class="mord mtight">Θ</span><span class="mclose mtight">)</span><span class="mclose sizing reset-size3 size6 mtight delimcenter" style="top:0.075em;"><span class="mtight">)</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></div></figure><ul id="22b451cf-7b79-80aa-93e4-e18ad13542f3" class="bulleted-list"><li style="list-style-type:disc">log probability가 클수록 → 예측 잘함 → perplexity 낮음</li></ul><ul id="22b451cf-7b79-80dc-9da9-d29959795c5c" class="bulleted-list"><li style="list-style-type:disc">확률 예측이 낮고 불확실할수록 → perplexity 높음</li></ul><p id="22c451cf-7b79-8088-93db-ccb79cc8c008" class="">
</p><h3 id="22c451cf-7b79-80e4-933a-e66aab6d807b" class=""><strong>TTA에서의 문제점을 해결</strong></h3><p id="22c451cf-7b79-80af-964d-eea408ed9f48" class="">entropy는 <code>[p₁, p₂, ..., p_T]</code> 각 토큰에 대해 개별적으로 확률 분포를 만들어서 토큰간의 관계보다는, 각 위치에서 단일 정답을 강하게 만들려고 함. → 토큰 간 dependency 무시</p><p id="22c451cf-7b79-80f8-9ac8-c584410a694d" class="">→ 시그마로 전체 시퀀스에 대한 joint probability의 log loss를 구하기 때문에 토큰 간 의존성을 완전히 반영함</p><p id="22c451cf-7b79-8017-a413-df787ab2890d" class="">→ 전체 문장을 얼마나 잘 예측했는가? 기준으로 loss 줌</p><p id="22c451cf-7b79-80e9-90f8-c969a60f5bfc" class="">→ 글로벌한 관점에서 모델을 업데이트</p><p id="22c451cf-7b79-808b-81ac-d224c631a7d2" class="">
</p><h3 id="22b451cf-7b79-8030-8496-e5c591256d54" class=""><strong>문제점</strong></h3><p id="22b451cf-7b79-8016-ad51-da552a92301e" class="">테스트 시엔 ground truth가 없음 → output perplexity를 못 씀</p><p id="22b451cf-7b79-8031-b297-fd2fcc442c04" class="">x = input / y = output</p><ul id="22b451cf-7b79-803a-952a-d16556f33984" class="bulleted-list"><li style="list-style-type:disc">LLM 성능을 올리려면 당연히 <strong>P(y | x)</strong> 를 줄이는 게 맞음</li></ul><ul id="22b451cf-7b79-8031-b5af-efaf2fb11fdb" class="bulleted-list"><li style="list-style-type:disc">하지만 <strong>test-time에는 y를 모르기 때문에</strong> 위의 식을 직접 쓸 수 없다.</li></ul><p id="22b451cf-7b79-8054-99f1-dc0f70799dde" class="">
</p><p id="22b451cf-7b79-8002-b89a-d8935b987385" class="">→ 발견</p><p id="22b451cf-7b79-803b-86cf-df6b8d5e5b04" class=""> <strong>P(y | x)를 줄이는 대신 P(x)를 줄이는 것도 효과가 있다</strong>는 것</p><p id="22b451cf-7b79-80ea-a5c1-e77486f97e74" class="">
</p><p id="22b451cf-7b79-8037-ba96-c3308d51b6d8" class="">
</p><p id="22b451cf-7b79-8063-b945-cfa80144b7f0" class="">&quot;The trend of LLM’s perplexity to the input P(x; Θ) and perplexity to the output P(y|x; Θ) is the same.”</p><p id="22b451cf-7b79-8091-8f82-c078051a9c88" class="">
</p><div id="22b451cf-7b79-8045-b456-d6a344cb5192" class="column-list"><div id="22b451cf-7b79-80e1-9914-f452026468d7" style="width:50%" class="column"><figure id="22b451cf-7b79-808d-9d6f-c94e5f0e107d" class="image"><a href="/files/2025-07-14-ttl-llm/image%201.webp"><img style="width:336px" src="/files/2025-07-14-ttl-llm/image%201.webp"/></a></figure></div><div id="22b451cf-7b79-803e-a42f-e85c7790930c" style="width:50%" class="column"><p id="22b451cf-7b79-8089-abb1-e1930f44f1fe" class="">왼쪽 그래프를 보면,</p><p id="22b451cf-7b79-8055-b92b-ccef550f09ce" class=""> input/output perplexity를 측정했을때 </p><p id="22b451cf-7b79-80c0-83e7-e489e5f385e1" class="">강한 상관관계를 보인다.</p><p id="22b451cf-7b79-806e-9a60-e917943754e8" class="">
</p><p id="22b451cf-7b79-80f2-9f1e-d1189df5b071" class="">→ 입력 perplexity를 줄이면 출력도 같이 좋아짐</p></div></div><figure id="230451cf-7b79-80b4-9896-c4b2ca0261b2" class="equation"><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><div class="equation-container"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><munder><mrow><mi>min</mi><mo>⁡</mo></mrow><mi mathvariant="normal">Θ</mi></munder><mi mathvariant="script">P</mi><mo stretchy="false">(</mo><mi>y</mi><mo>∣</mo><mi>x</mi><mo separator="true">;</mo><mi mathvariant="normal">Θ</mi><mo stretchy="false">)</mo><mo>=</mo><munder><mrow><mi>min</mi><mo>⁡</mo></mrow><mi mathvariant="normal">Θ</mi></munder><msup><mi>e</mi><mrow><mo fence="true">(</mo><mo>−</mo><mfrac><mn>1</mn><mi>T</mi></mfrac><munderover><mo>∑</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mi>T</mi></munderover><mi>log</mi><mo>⁡</mo><mi>p</mi><mo stretchy="false">(</mo><msub><mi>y</mi><mi>t</mi></msub><mo>∣</mo><mi>x</mi><mo separator="true">,</mo><msub><mi>y</mi><mrow><mn>1</mn><mo>:</mo><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo separator="true">;</mo><mi mathvariant="normal">Θ</mi><mo stretchy="false">)</mo><mo fence="true">)</mo></mrow></msup></mrow><annotation encoding="application/x-tex">\min_{\Theta} \mathcal{P}(y \mid x; \Theta) = \min_{\Theta} e^{\left(-\frac{1}{T} \sum_{t=1}^{T} \log p(y_t \mid x, y_{1:t-1}; \Theta) \right)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.4943em;vertical-align:-0.7443em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6679em;"><span style="top:-2.3557em;margin-left:0em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">Θ</span></span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span><span class="mop">min</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.7443em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathcal" style="margin-right:0.08222em;">P</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">x</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">Θ</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.8548em;vertical-align:-0.7443em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6679em;"><span style="top:-2.3557em;margin-left:0em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">Θ</span></span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span><span class="mop">min</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.7443em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:1.1105em;"><span style="top:-3.413em;margin-right:0.05em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="minner mtight"><span class="mopen sizing reset-size3 size6 mtight delimcenter" style="top:0.075em;"><span class="mtight">(</span></span><span class="mord mtight">−</span><span class="mord mtight"><span class="mopen nulldelimiter sizing reset-size3 size6"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8443em;"><span style="top:-2.656em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span><span style="top:-3.2255em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line mtight" style="border-bottom-width:0.049em;"></span></span><span style="top:-3.384em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.344em;"><span></span></span></span></span></span><span class="mclose nulldelimiter sizing reset-size3 size6"></span></span><span class="mspace mtight" style="margin-right:0.1952em;"></span><span class="mop mtight"><span class="mop op-symbol small-op mtight" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9191em;"><span style="top:-2.1786em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-2.931em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3214em;"><span></span></span></span></span></span></span><span class="mspace mtight" style="margin-right:0.1952em;"></span><span class="mop mtight"><span class="mtight">l</span><span class="mtight">o</span><span class="mtight" style="margin-right:0.01389em;">g</span></span><span class="mspace mtight" style="margin-right:0.1952em;"></span><span class="mord mathnormal mtight">p</span><span class="mopen mtight">(</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2963em;"><span style="top:-2.357em;margin-left:-0.0359em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mrel mtight">∣</span><span class="mord mathnormal mtight">x</span><span class="mpunct mtight">,</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3173em;"><span style="top:-2.357em;margin-left:-0.0359em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mrel mtight">:</span><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2025em;"><span></span></span></span></span></span></span><span class="mpunct mtight">;</span><span class="mord mtight">Θ</span><span class="mclose mtight">)</span><span class="mclose sizing reset-size3 size6 mtight delimcenter" style="top:0.075em;"><span class="mtight">)</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></div></figure><p id="230451cf-7b79-808e-91c6-d67fe9432091" class="">에서 y를 쓰지 않는 다음으로 변경</p><figure id="230451cf-7b79-80e1-8af6-e3b385d9201f" class="equation"><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><div class="equation-container"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi mathvariant="script">P</mi><mo stretchy="false">(</mo><mo stretchy="false">{</mo><msub><mi>x</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>x</mi><mn>2</mn></msub><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msub><mi>x</mi><mi>T</mi></msub><mo stretchy="false">}</mo><mo stretchy="false">)</mo><mo>=</mo><msup><mi>e</mi><mrow><mo fence="true">(</mo><mo>−</mo><mfrac><mn>1</mn><mi>T</mi></mfrac><munderover><mo>∑</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mi>T</mi></munderover><mi>log</mi><mo>⁡</mo><mi>p</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mi>t</mi></msub><mo>∣</mo><msub><mi>x</mi><mrow><mn>1</mn><mo>:</mo><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo separator="true">;</mo><mi mathvariant="normal">Θ</mi><mo stretchy="false">)</mo><mo fence="true">)</mo></mrow></msup></mrow><annotation encoding="application/x-tex">\mathcal{P}(\{x_1, x_2, \ldots, x_T\}) = e^{\left(-\frac{1}{T} \sum_{t=1}^{T} \log p(x_t \mid x_{1:t-1}; \Theta) \right)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathcal" style="margin-right:0.08222em;">P</span><span class="mopen">({</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">})</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.1105em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:1.1105em;"><span style="top:-3.413em;margin-right:0.05em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="minner mtight"><span class="mopen sizing reset-size3 size6 mtight delimcenter" style="top:0.075em;"><span class="mtight">(</span></span><span class="mord mtight">−</span><span class="mord mtight"><span class="mopen nulldelimiter sizing reset-size3 size6"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8443em;"><span style="top:-2.656em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span><span style="top:-3.2255em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line mtight" style="border-bottom-width:0.049em;"></span></span><span style="top:-3.384em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.344em;"><span></span></span></span></span></span><span class="mclose nulldelimiter sizing reset-size3 size6"></span></span><span class="mspace mtight" style="margin-right:0.1952em;"></span><span class="mop mtight"><span class="mop op-symbol small-op mtight" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9191em;"><span style="top:-2.1786em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-2.931em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3214em;"><span></span></span></span></span></span></span><span class="mspace mtight" style="margin-right:0.1952em;"></span><span class="mop mtight"><span class="mtight">l</span><span class="mtight">o</span><span class="mtight" style="margin-right:0.01389em;">g</span></span><span class="mspace mtight" style="margin-right:0.1952em;"></span><span class="mord mathnormal mtight">p</span><span class="mopen mtight">(</span><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2963em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mrel mtight">∣</span><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3173em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mrel mtight">:</span><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2025em;"><span></span></span></span></span></span></span><span class="mpunct mtight">;</span><span class="mord mtight">Θ</span><span class="mclose mtight">)</span><span class="mclose sizing reset-size3 size6 mtight delimcenter" style="top:0.075em;"><span class="mtight">)</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></div></figure><p id="230451cf-7b79-8016-9ece-d43fecc884bd" class="">
</p><p id="22b451cf-7b79-809b-a4f0-f83cb06db2c9" class="">
</p><hr id="22b451cf-7b79-80db-912f-f953489d36d3"/><p id="22b451cf-7b79-80b5-8202-c66ff8f65492" class="">
</p><h2 id="22b451cf-7b79-8060-8efc-da7cfbc12828" class="">4.2 Sample Efficient Learning Strategy</h2><p id="22b451cf-7b79-8069-b76a-c9fa77f63e82" class="">
</p><p id="22b451cf-7b79-80c6-a8fc-ffe640566cb1" class="">TTL에서 <strong>모든 테스트 샘플을 다 사용해서 업데이트</strong>하면:</p><ul id="22b451cf-7b79-80e0-bbc5-cd3bc109c1ac" class="bulleted-list"><li style="list-style-type:disc">계산량 낭비</li></ul><ul id="22b451cf-7b79-80f3-a140-e8ba2999fc26" class="bulleted-list"><li style="list-style-type:disc">효과 없는 샘플에 모델이 오히려 흔들릴 수 있음</li></ul><p id="22b451cf-7b79-800e-895e-ded62c0c3963" class="">
</p><div id="22b451cf-7b79-80e8-89a0-e7822864d27d" class="column-list"><div id="22b451cf-7b79-8089-a719-d4da4f4ee9cd" style="width:37.5%" class="column"><figure id="22b451cf-7b79-806c-aba4-e7fd671d9778" class="image"><a href="/files/2025-07-14-ttl-llm/image%202.webp"><img style="width:336px" src="/files/2025-07-14-ttl-llm/image%202.webp"/></a></figure></div><div id="22b451cf-7b79-8027-8161-f6329f7f4cb2" style="width:62.5%" class="column"><p id="22b451cf-7b79-8004-995d-d0e2c021b7b1" class="">→  발견</p><ul id="22b451cf-7b79-803a-908a-c41aab4cfd39" class="bulleted-list"><li style="list-style-type:disc">high-perplexity 샘플로 학습하면 더 높은 ROUGE 성능</li></ul><ul id="22b451cf-7b79-8029-8d68-ee421c997c49" class="bulleted-list"><li style="list-style-type:disc">low-perplexity 샘플만 쓰면 성능 <strong>오히려 떨어짐</strong></li></ul><p id="22b451cf-7b79-8098-b73e-df38c7e2c5da" class=""><strong>Low-perplexity input</strong>은 이미 잘 맞추는 것이라 정보 거의 없기 때문.</p></div></div><p id="22c451cf-7b79-80e5-a7c2-f063f5939090" class="">
</p><blockquote id="22c451cf-7b79-8088-bcf2-fa358c76c5cc" class="">ROUGE(Recall-Oriented Understudy for Gisting Evaluation):<p id="22c451cf-7b79-80bd-8090-ceb01df31db6" class="">자연어 생성 결과를 <strong>reference 문장과 비교해 얼마나 잘 일치하는지</strong> 평가하</p><p id="22c451cf-7b79-80df-8adc-f1404765db4b" class="">ROUGE-L : Longest Common Subsequence (LCS) 기반으로 공통 부분문자열 </p></blockquote><p id="230451cf-7b79-8030-9bfa-faad42424686" class="">
</p><ul id="230451cf-7b79-803c-bc28-caf02439d3ae" class="bulleted-list"><li style="list-style-type:disc"><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mrow><mi>min</mi><mo>⁡</mo></mrow><mover accent="true"><mi mathvariant="normal">Θ</mi><mo>ˉ</mo></mover></msub><mi>S</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mi mathvariant="script">P</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">;</mo><mi mathvariant="normal">Θ</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\min_{\bar{\Theta}} S(x) \mathcal{P}(x; \Theta)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop"><span class="mop">min</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.4707em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord accent mtight"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8201em;"><span style="top:-2.7em;"><span class="pstrut" style="height:2.7em;"></span><span class="mord mtight">Θ</span></span><span style="top:-2.9523em;"><span class="pstrut" style="height:2.7em;"></span><span class="accent-body" style="left:-0.25em;"><span class="mord mtight">ˉ</span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2293em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mord mathcal" style="margin-right:0.08222em;">P</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">Θ</span><span class="mclose">)</span></span></span></span></span><span>﻿</span></span> → informative한 샘플만 골라 쓰자</li></ul><ul id="22b451cf-7b79-80e7-9cb4-dfec00a320fa" class="bulleted-list"><li style="list-style-type:disc">각 샘플마다 perplexity를 기반으로 점수 S(x) 를 매기고</li></ul><ul id="22b451cf-7b79-800e-a918-e95010177d34" class="bulleted-list"><li style="list-style-type:disc">S(x)가 높은 샘플만 backpropagation에 사용</li></ul><figure id="230451cf-7b79-800b-9a76-c7f7f3f97c97" class="equation"><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><div class="equation-container"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>S</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mi>λ</mi><mo>⋅</mo><msup><mi>e</mi><mrow><mi>log</mi><mo>⁡</mo><mi mathvariant="script">P</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">;</mo><mi mathvariant="normal">Θ</mi><mo stretchy="false">)</mo><mo>−</mo><mi>log</mi><mo>⁡</mo><msub><mi>P</mi><mn>0</mn></msub></mrow></msup><mo>⋅</mo><msub><mi mathvariant="double-struck">I</mi><mrow><mo stretchy="false">{</mo><mi mathvariant="script">P</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">;</mo><mi mathvariant="normal">Θ</mi><mo stretchy="false">)</mo><mo>&gt;</mo><msub><mi>P</mi><mn>0</mn></msub><mo stretchy="false">}</mo></mrow></msub><mo stretchy="false">(</mo><mi mathvariant="bold">x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">S(x) = \lambda \cdot e^{\log \mathcal{P}(x; \Theta) - \log P_0} \cdot \mathbb{I}_{\{ \mathcal{P}(x; \Theta) &gt; P_0 \}}(\mathbf{x})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">λ</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.938em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.938em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mop mtight"><span class="mtight">l</span><span class="mtight">o</span><span class="mtight" style="margin-right:0.01389em;">g</span></span><span class="mspace mtight" style="margin-right:0.1952em;"></span><span class="mord mathcal mtight" style="margin-right:0.08222em;">P</span><span class="mopen mtight">(</span><span class="mord mathnormal mtight">x</span><span class="mpunct mtight">;</span><span class="mord mtight">Θ</span><span class="mclose mtight">)</span><span class="mbin mtight">−</span><span class="mop mtight"><span class="mtight">l</span><span class="mtight">o</span><span class="mtight" style="margin-right:0.01389em;">g</span></span><span class="mspace mtight" style="margin-right:0.1952em;"></span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3173em;"><span style="top:-2.357em;margin-left:-0.1389em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.1052em;vertical-align:-0.3552em;"></span><span class="mord"><span class="mord mathbb">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.5198em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">{</span><span class="mord mathcal mtight" style="margin-right:0.08222em;">P</span><span class="mopen mtight">(</span><span class="mord mathnormal mtight">x</span><span class="mpunct mtight">;</span><span class="mord mtight">Θ</span><span class="mclose mtight">)</span><span class="mrel mtight">&gt;</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3173em;"><span style="top:-2.357em;margin-left:-0.1389em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mclose mtight">}</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3552em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathbf">x</span><span class="mclose">)</span></span></span></span></span></div></figure><p id="22b451cf-7b79-8056-baf8-d4da99a94231" class="">Low-perplexity 샘플은 제외하고, High-perplexity 샘플은 비중을 크게 부여해서 학습에 반영</p><p id="22c451cf-7b79-8075-89a5-f7fd08f21c1f" class="">여기서 아라비아숫자 2 같이 생긴건, indicator function (지시 함수)를 의미한다.</p><p id="22c451cf-7b79-80dc-8467-f48d4cc2e5d6" class="">즉, 조건을 만족하면 <code>1</code>, 만족하지 않으면 <code>0</code>이 되는 <strong>불연속 함수</strong></p><p id="22c451cf-7b79-809c-861a-dd2af8f766e5" class="">
</p><p id="22b451cf-7b79-8000-aebb-c031cf1589e6" class="">
</p><p id="22b451cf-7b79-8018-b849-d33839c764d4" class=""><strong>효과</strong></p><ul id="22b451cf-7b79-80b5-b634-d475be485bc7" class="bulleted-list"><li style="list-style-type:disc">불필요한 샘플 업데이트를 줄여 <strong>계산량 감소</strong></li></ul><ul id="22b451cf-7b79-80bb-9d5b-d69a1614058d" class="bulleted-list"><li style="list-style-type:disc">더 informative한 샘플로만 업데이트해서 <strong>성능 향상</strong></li></ul><p id="22b451cf-7b79-8085-b569-c0aaa414d180" class="">
</p><p id="22b451cf-7b79-80b0-b0c9-d96ccdd7b53a" class="">
</p><hr id="22b451cf-7b79-80f5-afa7-dde5edf2c716"/><p id="22b451cf-7b79-805f-8a98-ce2bb3e01437" class="">
</p><h2 id="22b451cf-7b79-8076-b30d-e659baf153f4" class="">4.3 Modulating Parameters for Test-Time Learning</h2><p id="22b451cf-7b79-80e7-99b3-d197ce57271e" class="">
</p><div id="22b451cf-7b79-8058-879c-fabc5f27b061" class="column-list"><div id="22b451cf-7b79-8061-a316-c76db6c9cdd0" style="width:37.5%" class="column"><figure id="22b451cf-7b79-80c7-ad5a-d193dd6e0ab0" class="image"><a href="/files/2025-07-14-ttl-llm/image%203.webp"><img style="width:384px" src="/files/2025-07-14-ttl-llm/image%203.webp"/></a></figure></div><div id="22b451cf-7b79-80f4-81b3-cd120d1b174d" style="width:62.5%" class="column"><p id="22b451cf-7b79-804a-a5a2-e7bd244d4a44" class="">LoRA(Low-Rank Adaptation)는 일부 linear layer에 작은 랭크의 보조 행렬 A, B를 추가해서 업데이트함</p><p id="22b451cf-7b79-808e-9310-fd8c334f1770" class="">→ LoRA로만 업데이트한 경우, full-param update보다 original 성능 유지력이 훨씬 좋음</p><p id="22b451cf-7b79-80ea-a2cc-cab53efecf78" class="">도메인 적응 중에도 task 성능 유지 → <strong>forgetting 억제</strong></p><p id="22b451cf-7b79-80d1-b0b3-dc82c626f69b" class="">
</p></div></div><figure id="230451cf-7b79-80cd-b778-da016b47b2d2" class="equation"><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><div class="equation-container"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><munder><mrow><mi>min</mi><mo>⁡</mo></mrow><mover accent="true"><mi mathvariant="normal">Θ</mi><mo>~</mo></mover></munder><mi>S</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mi mathvariant="script">P</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">;</mo><mover accent="true"><mi mathvariant="normal">Θ</mi><mo>~</mo></mover><mo stretchy="false">)</mo><mo>=</mo><munder><mrow><mi>min</mi><mo>⁡</mo></mrow><mrow><mi mathvariant="normal">Δ</mi><mi mathvariant="normal">Θ</mi></mrow></munder><mi>S</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mi mathvariant="script">P</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">;</mo><mi mathvariant="normal">Θ</mi><mo>+</mo><mi mathvariant="normal">Δ</mi><mi mathvariant="normal">Θ</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\min_{\tilde{\Theta}} S(x)\mathcal{P}(x; \tilde{\Theta}) = \min_{\Delta\Theta} S(x)\mathcal{P}(x; \Theta + \Delta\Theta)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.8303em;vertical-align:-0.9101em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6679em;"><span style="top:-2.1899em;margin-left:0em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord accent mtight"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9202em;"><span style="top:-2.7em;"><span class="pstrut" style="height:2.7em;"></span><span class="mord mtight">Θ</span></span><span style="top:-3.3023em;"><span class="pstrut" style="height:2.7em;"></span><span class="accent-body" style="left:-0.25em;"><span class="mord mtight">~</span></span></span></span></span></span></span></span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span><span class="mop">min</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.9101em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mord mathcal" style="margin-right:0.08222em;">P</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9202em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord">Θ</span></span><span style="top:-3.6023em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.25em;"><span class="mord">~</span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.4943em;vertical-align:-0.7443em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6679em;"><span style="top:-2.3557em;margin-left:0em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">ΔΘ</span></span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span><span class="mop">min</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.7443em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mord mathcal" style="margin-right:0.08222em;">P</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">Θ</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">ΔΘ</span><span class="mclose">)</span></span></span></span></span></div></figure><p id="22b451cf-7b79-80e9-9330-e11f33f34a22" class="">LoRA를 사용하기 때문에 위와 같은 식이 됨</p><p id="22b451cf-7b79-80eb-af86-d6f29188262e" class="">
</p><p id="22b451cf-7b79-8043-9202-fe27643a3084" class="">
</p><hr id="22b451cf-7b79-801c-92c6-c0f157df1135"/><p id="22b451cf-7b79-8067-9e46-d2839d65f719" class="">
</p><h2 id="22b451cf-7b79-803c-b447-d379191c4e1c" class="">5.1. Experimental Settings</h2><h3 id="22b451cf-7b79-806f-bc4b-c17fec07bb04" class="">Benchmark: AdaptEval</h3><ul id="22b451cf-7b79-80c0-8a47-f33d0d9d22f4" class="bulleted-list"><li style="list-style-type:disc">논문에서 만든 새로운 평가 벤치마크</li></ul><ul id="22b451cf-7b79-8033-95e6-f705c912a85e" class="bulleted-list"><li style="list-style-type:disc">다양한 도메인과 과제 유형을 포함하여 <strong>LLM의 적응 능력</strong>을 다각도로 평가</li></ul><table id="22b451cf-7b79-806f-a184-fd148ff700c1" class="simple-table"><thead class="simple-table-header"><tr id="22b451cf-7b79-80b9-8216-e09179b828b6"><th id="x;wa" class="simple-table-header-color simple-table-header">Bench</th><th id="@QS^" class="simple-table-header-color simple-table-header">목적</th><th id="hGn_" class="simple-table-header-color simple-table-header" style="width:415px">포함된 데이터셋</th></tr></thead><tbody><tr id="22b451cf-7b79-8050-a97e-c598c4582ad8"><td id="x;wa" class=""><strong>DomainBench</strong></td><td id="@QS^" class="">도메인 지식 적응</td><td id="hGn_" class="" style="width:415px">Geography, Agriculture, Medicine, Finance</td></tr><tr id="22b451cf-7b79-805f-805b-e0366f300f74"><td id="x;wa" class=""><strong>InstructionBench</strong></td><td id="@QS^" class="">지시 따르기</td><td id="hGn_" class="" style="width:415px">Alpaca-GPT4, Dolly, InstructionWild</td></tr><tr id="22b451cf-7b79-80c5-90d5-c7153b21311d"><td id="x;wa" class=""><strong>ReasoningBench</strong></td><td id="@QS^" class="">논리 추론</td><td id="hGn_" class="" style="width:415px">GSM8K, MetaMath, Logiqa</td></tr></tbody></table><h3 id="22b451cf-7b79-8090-9837-cfacb0eb138e" class="">평가 지표 (Metrics)</h3><ul id="22b451cf-7b79-8094-b75e-d4b62e6aa1ee" class="bulleted-list"><li style="list-style-type:disc"><strong>DomainBench, InstructionBench</strong> → <em>ROUGE-Lsum (R-Lsum)</em></li></ul><ul id="22b451cf-7b79-80ab-a5ec-ed82c42d59d8" class="bulleted-list"><li style="list-style-type:disc"><strong>ReasoningBench</strong> → <em>Exact Match (EM)</em></li></ul><blockquote id="22b451cf-7b79-8061-9fca-ce8d9a499ab1" class="">각각의 task 특성에 맞는 대표 지표를 사용함</blockquote><h3 id="22b451cf-7b79-805d-bab5-dfdfea8b94c6" class="">LLM 모델</h3><ul id="22b451cf-7b79-80ac-b3f9-d8e91dad9bf2" class="bulleted-list"><li style="list-style-type:disc">Llama3.2-3B-Instruct</li></ul><ul id="22b451cf-7b79-80f5-a54a-e1c0a2a1d13c" class="bulleted-list"><li style="list-style-type:disc">Llama3-8B-Instruct</li></ul><ul id="22b451cf-7b79-803c-9b29-f44aa645dd24" class="bulleted-list"><li style="list-style-type:disc">Llama2-13B-Chat</li></ul><ul id="22b451cf-7b79-80d0-a3c1-dcbc2cf29e75" class="bulleted-list"><li style="list-style-type:disc">Qwen2.5-7B-Instruct</li></ul><h3 id="22b451cf-7b79-80c8-b489-ce4448fda412" class="">Baselines</h3><ul id="22b451cf-7b79-80a1-baaa-ee7655df6b69" class="bulleted-list"><li style="list-style-type:disc"><strong>Tent</strong> (Entropy minimization 기반 TTA)</li></ul><ul id="22b451cf-7b79-807e-9947-d0564e2fe18e" class="bulleted-list"><li style="list-style-type:disc"><strong>EATA</strong> (low-entropy 샘플 선택 기반 TTA)</li></ul><ul id="22b451cf-7b79-8009-9cae-d1e144d7d670" class="bulleted-list"><li style="list-style-type:disc"><strong>COME</strong> (보수적 entropy 최소화 방식)</li></ul><p id="22b451cf-7b79-8076-8d13-e8c387243eab" class="">→ 모두 <strong>unlabeled test data만 사용하는 최신 TTA 기법</strong></p><p id="22b451cf-7b79-8081-9c09-ecd77960708f" class="">→ 공정한 비교를 위해 모두 offline 설정에 맞춰 재구현</p><h3 id="22b451cf-7b79-805a-9328-e1f29ea7be44" class="">구현 세팅</h3><ul id="22b451cf-7b79-802f-b0de-c3583499666f" class="bulleted-list"><li style="list-style-type:disc">Optimizer: Adam</li></ul><ul id="22b451cf-7b79-8016-8e4b-ce9dcdcc0978" class="bulleted-list"><li style="list-style-type:disc">Learning rate:<ul id="22b451cf-7b79-8060-9337-e2c7c430cf0f" class="bulleted-list"><li style="list-style-type:circle">DomainBench: 5e-5</li></ul><ul id="22b451cf-7b79-802a-81da-ca917a92c5e2" class="bulleted-list"><li style="list-style-type:circle">InstructionBench: 5e-5</li></ul><ul id="22b451cf-7b79-80e0-8016-d590e3baaf5e" class="bulleted-list"><li style="list-style-type:circle">ReasoningBench: 1e-6</li></ul></li></ul><ul id="22b451cf-7b79-80ee-9d82-d120beee772f" class="bulleted-list"><li style="list-style-type:disc">Batch size: 1</li></ul><ul id="22b451cf-7b79-8027-8f35-fb97f233b585" class="bulleted-list"><li style="list-style-type:disc">Decoding: Greedy, temperature = 0</li></ul><ul id="22b451cf-7b79-8031-b115-c59335bdf603" class="bulleted-list"><li style="list-style-type:disc">λ = 0.1, P₀ = e³ (샘플 선택 threshold)</li></ul><p id="22b451cf-7b79-80dc-9b7c-da98efb9a160" class="">
</p><p id="22b451cf-7b79-80b5-a45f-ddf3d45f3929" class="">
</p><hr id="22b451cf-7b79-808d-bce7-c662edcbe5c3"/><p id="22b451cf-7b79-80ba-b772-e77544948d0c" class="">
</p><h2 id="22b451cf-7b79-8047-986b-c2b7453a279c" class="">5.2 Comparison Experiments</h2><figure id="22b451cf-7b79-8071-9b5b-f4e8f38666b7" class="image"><a href="/files/2025-07-14-ttl-llm/image%204.webp"><img style="width:709.984375px" src="/files/2025-07-14-ttl-llm/image%204.webp"/></a></figure><p id="22b451cf-7b79-8014-bec8-e0ad209884aa" class="">TLM은 모든 task category에서 baseline 대비 우수한 성능을 달성</p><ul id="22b451cf-7b79-8055-a1b4-d52799f4ea97" class="bulleted-list"><li style="list-style-type:disc"><strong>DomainBench</strong>: 전문 용어, 도메인-specific 표현들 (예: 의료, 금융 용어)</li></ul><ul id="22b451cf-7b79-80d4-912b-d118f0b91abe" class="bulleted-list"><li style="list-style-type:disc"><strong>InstructionBench</strong>: 지시문의 표현 방식, 말투, 요청 스타일 적응</li></ul><p id="22b451cf-7b79-80db-948f-c5d2407fc9f7" class="">→ 이런 과제들은 모델이 새로운 용어, 문장 패턴에만 적응하면 성능이 올라감</p><p id="22b451cf-7b79-8009-9831-dbbbcd270c21" class="">→ 그리고 TLM은 입력 perplexity 최소화 → 문장 표현에 대한 이해 강화</p><p id="22b451cf-7b79-804e-b07b-db22d1e7ffb7" class="">→ 즉, perplexity 기반 self-supervised 적응이 직접적으로 효과적임</p><p id="22b451cf-7b79-80c6-8dae-e60e4a58a3d9" class="">
</p><div id="22b451cf-7b79-802b-8b42-e84e1fdf880e" class="column-list"><div id="22b451cf-7b79-80f3-a7d1-ce15107538ce" style="width:50%" class="column"><figure id="22b451cf-7b79-802c-ab67-d7e14075ab15" class="image"><a href="/files/2025-07-14-ttl-llm/image%205.webp"><img style="width:332px" src="/files/2025-07-14-ttl-llm/image%205.webp"/></a></figure></div><div id="22b451cf-7b79-8020-b29a-f75e3ae39b95" style="width:50%" class="column"><p id="22b451cf-7b79-80d0-b6f1-d2b5e55d3055" class="">이 표만 값이 <strong>Exact Match (EM)</strong>임. </p><p id="22b451cf-7b79-8070-8751-d791e5cc2360" class="">→ 정확히 답을 얼마나 맞췄는가</p><p id="22b451cf-7b79-8045-ba19-e62087ea1ce1" class="">
</p><p id="22b451cf-7b79-8062-b589-e807433cfba0" class="">ReasoningBench도 좋아지긴 했지만, 논리 구조가 핵심이라 <strong>chain-of-thought reasoning</strong>이 중요함</p><p id="22b451cf-7b79-80c9-8a38-eca49092ba34" class="">→ test-time에 입력만 보고 모델을 개선하는 건 <strong>제한적인 효과만 있음</strong></p><p id="22b451cf-7b79-8055-9b99-c162ef3317b4" class="">→ 특히 reasoning 능력은 이미 pretraining + fine-tuning 단계에서 깊게 학습되어야 함</p><p id="22b451cf-7b79-8027-887d-cd7fdea3b5d2" class="">
</p></div></div><p id="22b451cf-7b79-80ee-8934-e5ec6d344e1e" class="">
</p><hr id="22b451cf-7b79-8084-a678-c310067f1f3b"/><p id="22b451cf-7b79-80be-89b2-fe7c9f69ac65" class="">
</p><h2 id="22b451cf-7b79-8097-b262-c86e66f48e2e" class="">5.3 Ablation Studies</h2><table id="22b451cf-7b79-806b-931f-fd565d6cc30d" class="simple-table"><thead class="simple-table-header"><tr id="22b451cf-7b79-803e-9848-cebd00c9c859"><th id="NdW_" class="simple-table-header-color simple-table-header">버전</th><th id="PZJ&gt;" class="simple-table-header-color simple-table-header" style="width:523px">설명</th></tr></thead><tbody><tr id="22b451cf-7b79-80c7-bade-f4bc54bb1c7b"><td id="NdW_" class=""><strong>Original LLM</strong></td><td id="PZJ&gt;" class="" style="width:523px">아무런 TTL 적용 안 한 원본</td></tr><tr id="22b451cf-7b79-80e8-8158-cd3c3d8cff56"><td id="NdW_" class=""><strong>Ours (w/o SEL)</strong></td><td id="PZJ&gt;" class="" style="width:523px">샘플 선택 없이 input perplexity만 최소화</td></tr><tr id="22b451cf-7b79-80e4-b87b-c06ec7a799eb"><td id="NdW_" class=""><strong>Ours</strong></td><td id="PZJ&gt;" class="" style="width:523px">full TLM = SEL + LoRA + perplexity minimization</td></tr></tbody></table><figure id="22b451cf-7b79-80ab-9b48-c17d2424ec6a" class="image"><a href="/files/2025-07-14-ttl-llm/image%206.webp"><img style="width:576px" src="/files/2025-07-14-ttl-llm/image%206.webp"/></a></figure><h3 id="22b451cf-7b79-80fb-9c8c-e7d4bd2eaad7" class="">Input Perplexity Minimization</h3><p id="22b451cf-7b79-8029-b8de-e1a8b28f738d" class="">→ 성능 향상의 <strong>주된 원인</strong></p><p id="22b451cf-7b79-80b8-808b-ca69ab929e32" class="">→ SEL 없이도 30~80% 향상</p><h3 id="22b451cf-7b79-8086-b230-e7af2025574a" class="">Sample Efficient Learning (SEL)</h3><p id="22b451cf-7b79-8099-9864-e7f4dfc2e941" class="">→ 추가 향상은 적지만,</p><p id="22b451cf-7b79-804c-a8d6-f4845c0e603d" class="">→ <strong>계산량 줄이면서 성능 유지</strong></p><div id="22b451cf-7b79-809d-8569-f3df818b2e44" class="column-list"><div id="22b451cf-7b79-80bf-a45e-cf6cc6af559e" style="width:56.25%" class="column"><h3 id="22b451cf-7b79-8023-af92-d6a7bb1cd8ff" class="">Threshold P0 (perplexity margin)</h3><p id="22b451cf-7b79-806e-901b-da0bf4f8adfa" class="">
</p><figure id="22b451cf-7b79-80db-bf16-c2473e09b4fc" class="image"><a href="/files/2025-07-14-ttl-llm/image%207.webp"><img style="width:373.484375px" src="/files/2025-07-14-ttl-llm/image%207.webp"/></a></figure><p id="22b451cf-7b79-8072-9c17-e88475d100ed" class="">→다양한 P0∈{e2,e3,...,e6} 실험</p><p id="22b451cf-7b79-80ce-8792-f6ec7579ecbd" class="">→ P0=e3 일 때 가장 안정적이고 좋은 성능</p><p id="22b451cf-7b79-8063-8075-f0624658fb82" class="">
</p></div><div id="22b451cf-7b79-80ae-b03b-eeb3f837d635" style="width:43.74999999999999%" class="column"><figure id="22b451cf-7b79-80d9-853b-ecad71c1ec0d" class="image"><a href="/files/2025-07-14-ttl-llm/image%208.webp"><img style="width:709.9921875px" src="/files/2025-07-14-ttl-llm/image%208.webp"/></a></figure></div></div><p id="22b451cf-7b79-8077-9eaa-c2b74ba1f05b" class="">
</p><hr id="22b451cf-7b79-8014-a1a4-c578275d97ef"/><p id="22b451cf-7b79-8065-8aad-eca5739e6a76" class="">
</p><h2 id="22b451cf-7b79-8026-a58c-c72686281227" class="">5.4 More Discussions</h2><p id="22b451cf-7b79-801d-8028-eeabc1ef7394" class="">
</p><figure id="22b451cf-7b79-806b-bef5-f038dc0278bf" class="image"><a href="/files/2025-07-14-ttl-llm/image%209.webp"><img style="width:624px" src="/files/2025-07-14-ttl-llm/image%209.webp"/></a></figure><h3 id="22b451cf-7b79-80c0-b561-de8aac31ab2d" class="">Online Test-Time Experiments</h3><p id="22b451cf-7b79-8063-bbb0-c3bfb4bddf82" class="">test-time에 <strong>샘플 하나씩</strong> 들어오는 상황에서도 TLM이 잘 작동하는가?</p><ul id="22b451cf-7b79-80db-a63b-fb81d7cc63c2" class="bulleted-list"><li style="list-style-type:disc">처음에는 high-perplexity 샘플이 많아서 업데이트 많이 하다가</li></ul><ul id="22b451cf-7b79-805e-829b-d91ff8857edd" class="bulleted-list"><li style="list-style-type:disc">점점 모델이 적응하면서 low-perplexity 샘플이 늘어남 → <strong>자동으로 학습 중단됨</strong></li></ul><p id="22b451cf-7b79-8056-8755-dd63887d439d" class="">
</p><h3 id="22b451cf-7b79-80ae-b304-d83d4b3931ed" class="">Experiments on Quantized LLM</h3><p id="22b451cf-7b79-8003-a5b1-c3b0ca13f8e3" class="">TLM은 quantized 모델에서도 성능 향상 유지</p><p id="22b451cf-7b79-8014-a026-c3ee7936bbad" class="">→ 메모리 제한 환경에서도 실용적</p><p id="22b451cf-7b79-8032-9711-d6eacef7c389" class="">
</p><p id="22b451cf-7b79-80d0-bf9f-c8340887a299" class="">
</p><hr id="22b451cf-7b79-80b4-af8d-fddd20b9d7a9"/><p id="22b451cf-7b79-808f-a576-e94a6c1e04c1" class="">
</p><h2 id="22b451cf-7b79-8024-8585-c06378b78970" class="">Limitation</h2><p id="22b451cf-7b79-80cc-a7ad-e5cb7d214552" class="">따로 언급은 없지만 굳이 뽑자면,</p><p id="22b451cf-7b79-807d-aff7-e9be1eb8b9e3" class="">
</p><p id="22b451cf-7b79-8061-ac6a-ec4fe2338fa2" class="">1. <strong>No Backprop-Free Variant (실제 inference 환경 제한)</strong></p><p id="22b451cf-7b79-801a-a70d-e70ab1b2476e" class="">TLM은 backprop이 필요함 → 대부분의 실제 LLM 배포 환경(API, closed-weight)에서는 적용 불가</p><p id="22b451cf-7b79-8010-8c09-ea6f99cf8c7b" class="">Future Work: Backprop-free TTL, e.g. prompt-based or derivative-free adaptation </p><hr id="22b451cf-7b79-80ef-8610-eee13e4f5759"/><p id="230451cf-7b79-80bd-9469-cad5f1ab3af1" class="">2. <strong>Limited Effect on Reasoning Tasks</strong></p><p id="22b451cf-7b79-801c-bf47-e819df3b61c2" class="">GSM8K, MetaMath 등 reasoning benchmark에서 성능 향상폭이 작음</p><p id="22b451cf-7b79-8057-9db1-c26367f71d32" class="">→ Perplexity minimization이 <strong>표현 적응에는 강하지만</strong>, 논리적 추론엔 약함</p><p id="22b451cf-7b79-8045-abde-c184a730af21" class="">Future Work: TTL for logic and chain-of-thought reasoning</p><hr id="22b451cf-7b79-8061-be94-f6a8d0aa5e3d"/><p id="230451cf-7b79-80ff-bd68-d2d1d133383a" class="">3. <strong>Domain-Specific Overfitting / Forgetting Risk</strong></p><p id="22b451cf-7b79-80e1-8430-df635544aa78" class="">LoRA 사용해도, 장기적으로 특정 도메인에 반복 적응 시 원래 능력(logic, general knowledge) 저하 가능성 존재</p><p id="22b451cf-7b79-802c-b267-e8113cf7ab42" class="">Future Work: Continual TTL with forgetting mitigation</p><hr id="22b451cf-7b79-801e-8900-f3cce05e1fa8"/><p id="230451cf-7b79-8011-830a-c80f01a8af6c" class="">4. <strong>Hyperparameter Sensitivity (e.g., P₀ threshold)</strong></p><p id="22b451cf-7b79-802a-a474-c092c4db4445" class="">샘플 선택 기준(P₀ = e³)이나 λ 값에 민감</p><p id="230451cf-7b79-8077-aaf6-fae5bd1418d7" class="">도메인/모델에 따라 튜닝 필요 → 실용화에 방해될 수 있음</p><p id="22b451cf-7b79-80c1-b26a-c51bbb57ab09" class="">Future Work: Auto-tuning or adaptive sampling strategies</p><hr id="22b451cf-7b79-8085-9049-e5f8611f5805"/><p id="230451cf-7b79-8037-addd-fbbff997106a" class="">5. <strong>Session-Aware / Multi-Turn TTL 미지원</strong></p><p id="22b451cf-7b79-806f-b626-fa65321375a9" class="">현재는 입력 단위로만 TTL 작동. 대화형 시스템처럼 <strong>context가 누적되는 환경에서는 적용되지 않음</strong></p><p id="22b451cf-7b79-80dc-8bb6-fdaeb04f56d0" class="">Future Work: Session-level TTL for conversational agents</p><p id="230451cf-7b79-80f4-90b0-fc7273a41ff8" class="">
</p><p id="230451cf-7b79-8002-8927-c3435e22ea58" class="">
</p><p id="230451cf-7b79-8049-a185-ef40d63c6b8c" class="">
</p><hr id="22b451cf-7b79-809e-a702-ea435479b5be"/><p id="230451cf-7b79-801a-9064-dc7c30596476" class="">
</p><h2 id="230451cf-7b79-80f1-bade-d457742be4e9" class="">Q&amp;A</h2><p id="22b451cf-7b79-8006-93bf-d8f97157577e" class="">
</p><p id="22b451cf-7b79-80bb-8ace-c2b9af40ab26" class="">Q. LLM에서 Test-Time 학습 최초인가?</p><p id="22b451cf-7b79-8038-b5d1-fcb3a2c24df3" class="">
</p><p id="22b451cf-7b79-8017-9a07-f4114b25afe3" class="">다음과 같은 논문들은 있었음.</p><p id="22b451cf-7b79-80d2-bf20-e18ba785dfd6" class=""><a href="https://arxiv.org/abs/2410.08020">https://arxiv.org/abs/2410.08020</a></p><p id="22b451cf-7b79-8019-b73d-e36ccebfc17b" class="">LLM을 테스트 시점에 prompt‑specific fine‑tuning 하는 방법을 제안했고,</p><p id="22b451cf-7b79-8029-be9d-c9a9010a2429" class="">실험을 통해 test‑time에도 LLM을 업데이트할 수 있다는 점을 보여줌</p><p id="22b451cf-7b79-8099-ae26-ea066315f9b4" class="">다만, 속도가 느리고 계산 비용이 크다는 단점</p><p id="22b451cf-7b79-80b0-867a-eab05a0f2907" class="">→ 가능은 했지만 실용에서 멀었음</p><p id="22b451cf-7b79-8000-ac31-d0b200a731de" class="">
</p><p id="22b451cf-7b79-80b9-882a-d2fdc8380ad3" class=""><strong>Prompt tuning 빼면 TLM이 LLM에서 Test-Time 학습을 최초로 실용화한 논문</strong></p><p id="22b451cf-7b79-8003-bdf3-c7d201fe01ab" class="">위 Table 5 를 보면 이미 Tent나 EATA도 한것처럼 보이지만, 오히려 기존 LLM을 파괴한 성능이 나옴.</p><p id="230451cf-7b79-80c5-99c3-d03b60476406" class="">
</p><hr id="230451cf-7b79-804e-9e16-e8fe0becd8cb"/><p id="230451cf-7b79-80a7-a779-ccbb58d50e54" class="">
</p><p id="230451cf-7b79-8098-81b2-c60f771eab4f" class="">
</p><p id="230451cf-7b79-80da-a175-f7047a6a9596" class="">Q. Output 내기 전에 학습하는 것인가?</p><p id="230451cf-7b79-809b-8d00-d606399e66eb" class="">P(y|x)을 기준으로 학습 못한다고 했는데, 왜? 어차피 output은 나오는거 아닌가?</p><p id="230451cf-7b79-8073-8e65-ec54ae8191d1" class="">
</p><h3 id="230451cf-7b79-805a-ba5f-e3659752912e" class="">왜 y를 안쓰는가?</h3><p id="230451cf-7b79-801b-8108-d24201269250" class="">모델이 생성한 ŷ는 <strong>정답이 아님</strong> → ground truth 없음</p><p id="230451cf-7b79-805f-a491-f1e51ecd48c4" class=""><code>P(ŷ | x)</code>를 줄이면 <strong>잘못된 출력을 더 확신하게 만드는 결과</strong>가 될 수 있음</p><p id="230451cf-7b79-80f6-b176-e5f66e58d963" class="">
</p><p id="230451cf-7b79-80fd-9c1f-dd45cc1ed5a1" class=""><strong>예시</strong></p><ul id="230451cf-7b79-8099-a5ce-cb0443e06efd" class="bulleted-list"><li style="list-style-type:disc">“사과는 빨갛다”가 정답인데</li></ul><ul id="230451cf-7b79-8040-ae7b-f177df2daf6b" class="bulleted-list"><li style="list-style-type:disc">모델이 “사과는 바나나다”라고 출력했을 경우</li></ul><ul id="230451cf-7b79-80fe-8ad2-fd310b7a9636" class="bulleted-list"><li style="list-style-type:disc">이걸 기준으로 loss를 줄이면 오히려 <strong>틀린 출력에 더 확신을 주게 됨</strong></li></ul><p id="230451cf-7b79-8094-8080-dc17938a73a4" class="">
</p><h3 id="230451cf-7b79-805d-888c-c4b7e857d057" class="">순서</h3><ol type="1" id="230451cf-7b79-8071-8b2d-f9acc0fb3404" class="numbered-list" start="1"><li>입력 <code>x</code> 들어옴</li></ol><ol type="1" id="230451cf-7b79-8049-baf8-f6fe476ec6e9" class="numbered-list" start="2"><li>모델이 현재 파라미터(θ + Δθ)로 출력 <code>ŷ</code> 생성</li></ol><ol type="1" id="230451cf-7b79-80e6-8bcf-d566bb9946e5" class="numbered-list" start="3"><li><code>x</code>에 대한 perplexity 계산</li></ol><ol type="1" id="230451cf-7b79-807f-9ac5-e296656e5cd1" class="numbered-list" start="4"><li><code>P(x)</code>가 기준보다 크면 → backprop으로 LoRA 파라미터 업데이트</li></ol><ol type="1" id="230451cf-7b79-8067-8f0d-d00b0eb46fae" class="numbered-list" start="5"><li>→ 이 업데이트는 다음 입력부터 반영됨</li></ol><p id="230451cf-7b79-80fb-949c-e5d30286f50a" class="">
</p><h3 id="230451cf-7b79-807d-9797-c6d03aa4c71f" class="">정리</h3><blockquote id="230451cf-7b79-80c6-a7f1-e44b27506cf6" class="">Although the true target y is unavailable at test time, we show that minimizing P(x) leads to update directions that are often aligned with those from minimizing P(y|x).</blockquote><p id="230451cf-7b79-80d3-aacb-cdfe780593cc" class="">Test-time에 label <code>y</code>가 없어서 그 샘플의 성능을 직접 평가할 수 없음</p><p id="230451cf-7b79-8055-9b38-f57ddc2d5922" class="">→ 대신, 그 샘플을 기반으로 전체 파라미터를 업데이트해서 미래의 예측력을 높임</p><p id="230451cf-7b79-801a-8e52-da346235fef3" class="">→ TLM은 <strong><span style="border-bottom:0.05em solid">online self-supervised continual learning</span></strong>에 가까움</p><p id="230451cf-7b79-80a3-85b2-f46450230e1f" class="">
</p></div>