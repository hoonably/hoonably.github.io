# Notionì—ì„œ exportí•œ html íŒŒì¼ì„ Jekyll ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸

# ì‚¬ìš©ë²•
# 1. Notionì—ì„œ exportí•œ html íŒŒì¼ê³¼ ì´ë¯¸ì§€ í´ë”ê°€ ë“¤ì–´ìˆëŠ” zip íŒŒì¼ì„ ì´ ìŠ¤í¬ë¦½íŠ¸ì™€ ê°™ì€ í´ë”ì— ë„£ìŠµë‹ˆë‹¤.
# 2. ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.
# 3. ì¹´í…Œê³ ë¦¬ë¥¼ ì„ íƒí•©ë‹ˆë‹¤.
# 4. ë³€í™˜ëœ Markdown íŒŒì¼ì´ _posts í´ë”ì— ìƒì„±ë©ë‹ˆë‹¤.
# 5. í•´ì œëë˜ í´ë”ëŠ” ì‚¬ë¼ì§€ê³ , zip íŒŒì¼ì€ ë‚¨ì•„ìˆìŠµë‹ˆë‹¤.
# 6. í™•ì¸ í›„ zip íŒŒì¼ì„ ì§ì ‘ ì‚­ì œí•©ë‹ˆë‹¤.

import os
import re
from datetime import datetime
from urllib.parse import unquote, quote
import shutil
import zipfile
from PIL import Image
from pillow_heif import register_heif_opener
from bs4 import BeautifulSoup, NavigableString

current_time = ""  # í˜„ì¬ ì‹œê°„ (YYYY-MM-DD HH:MM:SS)
current_date = ""  # ë‚ ì§œ (YYYY-MM-DD)
old_filename = ""  # ê¸°ì¡´ html íŒŒì¼ëª… ()
new_filename = ""  # ë§ˆí¬ë‹¤ìš´ íŒŒì¼ëª…ê³¼ í´ë”ëª… (YYYY-MM-DD-Data-Structure)

import unicodedata

def safe_filename(filename):
    filename = unicodedata.normalize("NFKD", filename)
    return filename.encode("ascii", "ignore").decode("ascii")


def merge_paragraphs_inside_callouts(html: str) -> str:
    # ì½œì•„ì›ƒ ë‚´ë¶€ <p>ë“¤ì„ <br>ë¡œ ì—°ê²°í•˜ì—¬ í•œ ë‹¨ë½ì²˜ëŸ¼ ë§Œë“¤ê¸°
    pattern = re.compile(
        r'(<figure[^>]*class="[^"]*callout[^"]*"[^>]*>.*?<div[^>]*style="width:100%">)(.*?)(</div>\s*</figure>)',
        re.DOTALL
    )

    # <ul>ê³¼ </ul> ë¶ˆë¦¿ ë¦¬ìŠ¤íŠ¸ ì œê±°
    html = re.sub(r'<ul[^>]*?>', '', html)
    html = re.sub(r'</ul>', '', html)

    # <strong> ì•ì— &nbsp; ì‚½ì…
    html = re.sub(r'<strong>', '&nbsp;<strong>', html)

    def replacer(match):
        prefix = match.group(1)
        inner = match.group(2)
        suffix = match.group(3)

        # <p>...</p> â†’ í…ìŠ¤íŠ¸ ì¶”ì¶œ í›„ <br>ë¡œ ì—°ê²°
        merged = re.sub(r'</p>\s*<p[^>]*>', '<br>', inner)
        merged = re.sub(r'<p[^>]*>', '', merged)
        merged = re.sub(r'</p>', '', merged)

        return f"{prefix}{merged}{suffix}"

    return pattern.sub(replacer, html)


def normalize_lang(lang: str) -> str:
    """language-XXXì—ì„œ ë½‘ì€ ì–¸ì–´ëª…ì„ ì†Œë¬¸ìí™”í•˜ê³  í”í•œ ë³„ì¹­ì„ ì •ê·œí™”."""
    s = lang.lower()
    mapping = {
        'py': 'python',
        'python3': 'python',
        'c#': 'csharp',
        'c++': 'cpp',
        'js': 'javascript',
        'ts': 'typescript',
        'sh': 'bash',
        'plaintext': '',
        'none': '',
        'text': '',
    }
    return mapping.get(s, s)

def convert_prism_codeblocks_to_md(html_content: str) -> str:
    soup = BeautifulSoup(html_content, 'html.parser')

    # 0) Prism ìŠ¤í¬ë¦½íŠ¸/ìŠ¤íƒ€ì¼ ì œê±°(ì›í•˜ë©´ ìœ ì§€í•´ë„ ë¨)
    for tag in soup.find_all(['script', 'link']):
        src = tag.get('src', '') or tag.get('href', '')
        if 'prism' in src:
            tag.decompose()

    # 1) <pre><code class="language-...">...</code></pre> â†’ ```lang ... ```
    for pre in soup.find_all('pre'):
        code = pre.find('code')
        if not code:
            continue

        # class ì†ì„±ì—ì„œ language-xxx ì¶”ì¶œ(ëŒ€/ì†Œë¬¸ì í˜¼í•© ëŒ€ì‘)
        classes = code.get('class', [])
        class_str = ' '.join(classes)
        m = re.search(r'language-([A-Za-z0-9#+._-]+)', class_str, flags=re.I)
        lang = normalize_lang(m.group(1)) if m else ''

        # ì½”ë“œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (BSê°€ ì—”í‹°í‹° ë””ì½”ë“œ/ê°œí–‰ ì²˜ë¦¬)
        code_text = code.get_text()

        md_block = f"\n\n```{lang}\n{code_text}\n```\n"
        pre.replace_with(NavigableString(md_block))

    # soup ì „ì²´ë¥¼ í…ìŠ¤íŠ¸ë¡œ(ë‹¤ë¥¸ HTMLë„ í•¨ê»˜ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ë°”ê¿”ì•¼ í•œë‹¤ë©´ ë³„ë„ íŒŒì´í”„ë¼ì¸ì—ì„œ ì²˜ë¦¬)
    return str(soup)

# html íŒŒì¼ ë‚´ì— ìˆëŠ” src, href ì†ì„±ì˜ ê²½ë¡œë¥¼ ë³€ê²½í•˜ëŠ” í•¨ìˆ˜
def rewrite_image_paths_soup(html: str, old_filename: str, new_filename: str) -> str:
    soup = BeautifulSoup(html, "html.parser")

    old_paths = [old_filename, quote(old_filename), quote(old_filename).replace("%2B", "+")]

    for tag in soup.find_all(["img", "a"]):
        for attr in ["src", "href"]:
            if tag.has_attr(attr):
                for old in old_paths:
                    if tag[attr].startswith(old) or f"./{old}" in tag[attr]:
                        tag[attr] = tag[attr].replace(old, f"/files/{new_filename}")

    # í™•ì¥ì êµì²´
    for img in soup.find_all("img"):
        for ext in [".png", ".jpg", ".jpeg"]:
            if img["src"].endswith(ext):
                img["src"] = img["src"].replace(ext, ".webp")

    return str(soup)


def convert_figure_images(html: str) -> str:
    soup = BeautifulSoup(html, "html.parser")

    for figure in soup.find_all("figure", class_="image"):
        a_tag = figure.find("a")
        img_tag = a_tag.find("img") if a_tag else None
        if img_tag is None:
            continue

        # ìƒˆ img íƒœê·¸ ìƒì„±
        new_img = soup.new_tag("img")

        # ê¸°ì¡´ img ì†ì„± ë³µì‚¬
        for attr, value in img_tag.attrs.items():
            new_img[attr] = value

        # al-folio í™•ëŒ€ìš© ì†ì„± ì¶”ê°€
        new_img["class"] = "img-fluid rounded z-depth-1"
        new_img["data-zoomable"] = ""
        new_img["loading"] = "eager"
        new_img["onerror"] = "this.onerror=null; $('.responsive-img-srcset').remove();"

        # <picture>ë¡œ ê°ì‹¸ê¸°
        picture_tag = soup.new_tag("picture")
        picture_tag.append(new_img)

        # ê¸°ì¡´ <a> â†’ <picture>ë¡œ ëŒ€ì²´
        a_tag.replace_with(picture_tag)

    return str(soup)

# ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ìˆ˜ì • ë° ìƒì„±í•˜ëŠ” í•¨ìˆ˜
def write_markdown_file(filepath, html_content):
    global new_filename  # ì „ì—­ë³€ìˆ˜ ë³€ê²½í•´ì•¼í•˜ë¯€ë¡œ

    # ì œëª© ì¶”ì¶œ
    title = html_content.split("<title>")[1].split("</title>")[0].strip()


    # 1) <div class="page-body"> í¬í•¨í•´ì„œ ê·¸ ì „ë¶€ ì œê±°
    html_content = re.sub(
        r'(?is).*?<div class="page-body">\s*',  # DOTALL + IGNORECASE
        '',
        html_content,
        count=1
    )

    # 2) </article>ë¶€í„° ëê¹Œì§€ ì œê±°í•˜ë©´ì„œ, ë’¤ì— ë°”ë¡œ ë”°ë¼ì˜¤ëŠ” </div> í•˜ë‚˜ë„ í•¨ê»˜ ì œê±°
    html_content = re.sub(
        r'(?is)</article>\s*(?:</div>\s*)?$',   # ë’¤ì— </div> í•˜ë‚˜ëŠ” ì„ íƒì ìœ¼ë¡œ í•¨ê»˜ ì œê±°
        '',
        html_content,
        count=1
    )

    # <details> íƒœê·¸ ìˆ˜ì • (ê¸°ë³¸ì ìœ¼ë¡œ ì—´ë ¤ìˆëŠ” ìƒíƒœê°€ ì•„ë‹ˆë„ë¡)
    html_content = html_content.replace("<details open=\"\">", "<details>")
    html_content = html_content.replace("<details open>", "<details>")

    # <figure> íƒœê·¸ë‚´ ì¤„ë°”ê¿ˆ ì¤‘ë³µ ì œê±°
    html_content = merge_paragraphs_inside_callouts(html_content)

    # codeblock mdë¡œ ë³€í™˜
    html_content = convert_prism_codeblocks_to_md(html_content)


    print(f"â­ï¸ {title}.html ë³€í™˜ì‘ì—…ì„ ì‹œì‘í•©ë‹ˆë‹¤.")

    # .html íŒŒì¼ëª…ê³¼ ì´ë¯¸ì§€ ë“±ì´ ë“¤ì–´ìˆëŠ” í´ë”ëª… ì‚¬ìš©ìê°€ ì§€ì •
    new_filename = input("íŒŒì¼ëª…ì„ ì˜ì–´ë¡œ ì…ë ¥í•´ì£¼ì„¸ìš” (ê³µë°±ì€ '-'ìœ¼ë¡œ, ëŒ€ë¬¸ìëŠ” ì†Œë¬¸ìë¡œ ìë™ ë³€ê²½ë©ë‹ˆë‹¤.): ").strip()

    # í—ˆìš©: ì•ŒíŒŒë²³(a-zA-Z), ìˆ«ì(0-9), ê³µë°±, í•˜ì´í”ˆ(-)ë§Œ â†’ ê·¸ ì™¸ëŠ” ëª¨ë‘ ê±°ë¶€
    while not new_filename or not re.fullmatch(r"[a-zA-Z0-9 \-]+", new_filename):
        if not new_filename:
            print("âŒ ë¹„ì›Œë‘˜ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:
            print("âŒ ì˜ì–´, ìˆ«ì, ê³µë°±, í•˜ì´í”ˆ(-)ë§Œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        new_filename = input("ë‹¤ì‹œ ì…ë ¥í•´ì£¼ì„¸ìš”: ").strip()
    new_filename = new_filename.lower()  # ëŒ€ë¬¸ìë¥¼ ì†Œë¬¸ìë¡œ ë³€ê²½
    new_filename = new_filename.replace(" ", "-")  # ê³µë°±ì„ '-'ë¡œ ë³€ê²½
    new_filename = f"{current_date}-{new_filename}"  # ë‚ ì§œ ì¶”ê°€

    # â­ï¸ íƒœê·¸ ì…ë ¥ (ì—¬ëŸ¬ ê°œ ê°€ëŠ¥)
    raw_tags = input("íƒœê·¸ë¥¼ ë„ì–´ì“°ê¸°ë¡œ ì…ë ¥í•´ì£¼ì„¸ìš” (CS, AI, PS ...): ").strip()
    tags = [tag.strip() for tag in raw_tags.split() if tag.strip()]
    tag_str = ", ".join(tags) if tags else ""

    # â­ï¸ ì¹´í…Œê³ ë¦¬ ì…ë ¥ (í•˜ë‚˜ë§Œ)
    category = input("ì¹´í…Œê³ ë¦¬ë¥¼ í•˜ë‚˜ ì…ë ¥í•´ì£¼ì„¸ìš” (Talk, Tip, Study, Paper): ").strip()

    # YAML í”„ë¡ íŠ¸ ë§¤í„° ìƒì„±
    yaml_front_matter = f"""---
layout: notion
title: "{title}"
description:
date: {current_time} +09:00
tags: {tag_str}
categories: {category}
giscus_comments: true
related_posts: false

featured: false
pretty_table: true

toc:
  beginning: false  # ë§¨ ì•ì— ëª©ì°¨
  sidebar: left  # ëª©ì°¨ê°€ ì‚¬ì´ë“œë°” ì™¼ìª½ì— ë¶™ì–´ìˆìŒ
---
"""

    # ì´ë¯¸ì§€ ê²½ë¡œ ìˆ˜ì •
    html_content = rewrite_image_paths_soup(html_content, old_filename, new_filename)
    html_content = convert_figure_images(html_content)


    # â­ï¸ .md ìˆ˜ì •ë³¸ ìƒì„± í›„ ì €ì¥
    final_content = yaml_front_matter + html_content
    script_dir = os.path.dirname(os.path.abspath(__file__))
    posts_dir = os.path.join(os.path.dirname(script_dir), "_posts")
    os.makedirs(posts_dir, exist_ok=True)
    new_filepath = os.path.join(posts_dir, f"{new_filename}.md")
    with open(new_filepath, 'w', encoding='utf-8') as file:
        file.write(final_content)
    print(f"â­ï¸ ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ìƒì„± ì™„ë£Œ: {new_filepath}")

# ì´ë¯¸ì§€ íŒŒì¼ì„ webpë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜
def convert_to_webp(input_path, output_path, quality=80):
    try:
        img = Image.open(input_path)
        ext = os.path.splitext(input_path)[1].lower()

        if ext in [".jpg", ".jpeg", ".heic"]:
            img = img.convert("RGB")   # ë¶ˆíˆ¬ëª…í•œ í¬ë§·
        elif ext == ".png":
            img = img.convert("RGBA")  # PNGëŠ” íˆ¬ëª…ë„ ìœ ì§€

        img.save(output_path, "webp", quality=quality)
        os.remove(input_path)

    except Exception as e:
        print(f"âŒ ì´ë¯¸ì§€ ë³€í™˜ ì‹¤íŒ¨: {input_path}\nì—ëŸ¬: {e}")



# ì´ë¯¸ì§€ê°€ ë“¤ì–´ìˆëŠ” í´ë”ë¥¼ "files/" ì•ˆìœ¼ë¡œ ë³µì‚¬í•˜ëŠ” í•¨ìˆ˜
def copy_folder(html_path):
    """
    html_path: ì›ë³¸ html ê²½ë¡œ
    new_filename: ì˜ˆì‹œ - '2025-04-04-MLOps.md'
    """

    # ì›ë³¸ ì´ë¯¸ì§€ í´ë”: html íŒŒì¼ ì˜†ì— ìˆëŠ” ë™ì¼ ì´ë¦„ í´ë”
    html_dir = os.path.dirname(html_path)
    filename_without_ext = os.path.splitext(os.path.basename(html_path))[0]
    # ë§ˆì§€ë§‰ ê³µë°± ì´í›„ í•´ì‹œ ì œê±°
    html_filename = filename_without_ext.rsplit(' ', 1)[0] if ' ' in filename_without_ext else filename_without_ext
    original_image_folder = os.path.join(html_dir, html_filename)

    if not os.path.exists(original_image_folder):
        print(f"ğŸŒ‰ ì´ë¯¸ì§€ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return

    # íƒ€ê²Ÿ ê²½ë¡œ: files/{new_filename_without_ext}/
    script_dir = os.path.dirname(os.path.abspath(__file__))
    root_dir = os.path.dirname(script_dir)
    folder_name = os.path.splitext(new_filename)[0]  # .md ì œê±°
    target_folder = os.path.join(root_dir, "files", folder_name)
    os.makedirs(target_folder, exist_ok=True)

    # ì´ë¯¸ì§€ ë³µì‚¬
    for item in os.listdir(original_image_folder):
        src_path = os.path.join(original_image_folder, item)
        dst_path = os.path.join(target_folder, item)
        if os.path.isfile(src_path):
            base, _ = os.path.splitext(item)
            dst_filename = base + ".webp"
            dst_path = os.path.join(target_folder, dst_filename)
            convert_to_webp(src_path, dst_path)

    print(f"â­ï¸ ì´ë¯¸ì§€ ë³µì‚¬ ì™„ë£Œ â†’ {target_folder}")

def process_html_file(filepath):
    global current_time, current_date

    while True:
        raw_date = input(f"ğŸ“… [{os.path.basename(filepath)}] ê²Œì‹œ ë‚ ì§œë¥¼ ì…ë ¥í•˜ì„¸ìš” (í˜•ì‹: YYMMDD, ì—”í„° ì‹œ ì˜¤ëŠ˜ ë‚ ì§œ ì‚¬ìš©): ").strip()

        if raw_date == "":
            dt = datetime.now()
            current_date = dt.strftime("%Y-%m-%d")
            break
        if not re.fullmatch(r"\d{6}", raw_date):
            print("âŒ ë‚ ì§œ í˜•ì‹ì´ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤. YYMMDD í˜•ì‹ìœ¼ë¡œ 6ìë¦¬ ìˆ«ìë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”. (ì˜ˆ: 250206)")
            continue
        try:
            # "25" â†’ "2025"
            full_date = "20" + raw_date
            dt = datetime.strptime(full_date, "%Y%m%d")
            current_date = dt.strftime("%Y-%m-%d")
            break
        except ValueError:
            print("âŒ ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ë‚ ì§œì…ë‹ˆë‹¤.")


    # âœ… ì‚¬ìš©ì ì…ë ¥ ë‚ ì§œ + í˜„ì¬ ì‹œê° ì¡°í•©ìœ¼ë¡œ date ê³ ì •
    current_time = f"{current_date} {datetime.now().strftime('%H:%M:%S')}"

    # íŒŒì¼ ì½ê¸°
    with open(filepath, 'r', encoding='utf-8') as file:
        html_content = file.read()

    # ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ìƒì„±
    write_markdown_file(filepath, html_content)

    # ì´ë¯¸ì§€ ë“¤ì–´ìˆëŠ” í´ë” ì˜®ê¸°ê¸°
    copy_folder(filepath)

    # â­ï¸ ë³€í™˜ ì™„ë£Œ ë©”ì‹œì§€
    print(f"â­ï¸ ëª¨ë“  ì‘ì—… ì™„ë£Œ â†’ {new_filename}\n")


if __name__ == "__main__":
    script_dir = os.path.dirname(os.path.abspath(__file__))

    for filename in os.listdir(script_dir):
        if filename.endswith(".zip"):
            zip_path = os.path.join(script_dir, filename)
            extract_dir = os.path.join(script_dir, os.path.splitext(filename)[0])

            # ì••ì¶• í•´ì œ
            with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                file_list = zip_ref.namelist()
                
                # zip ë‚´ë¶€ì— zip íŒŒì¼ í•˜ë‚˜ë§Œ ìˆëŠ” ê²½ìš° (Notion export íŒ¨í„´)
                if len(file_list) == 1 and file_list[0].lower().endswith('.zip'):
                    # ë‚´ë¶€ zipì„ script_dirì— ì„ì‹œ ì¶”ì¶œ
                    zip_ref.extractall(script_dir)
                    inner_zip_path = os.path.join(script_dir, file_list[0])
                    
                    # ë‚´ë¶€ zipì„ extract_dirì— í’€ê¸°
                    with zipfile.ZipFile(inner_zip_path, 'r') as inner_zip:
                        inner_zip.extractall(extract_dir)
                    
                    # ì„ì‹œ ë‚´ë¶€ zip íŒŒì¼ ì‚­ì œ
                    os.remove(inner_zip_path)
                    print(f"â­ï¸ ì¤‘ì²© zip ì••ì¶• í•´ì œ ì™„ë£Œ â†’ {extract_dir}")
                else:
                    # ì¼ë°˜ì ì¸ ì••ì¶• í•´ì œ
                    zip_ref.extractall(extract_dir)
                    print(f"â­ï¸ ì••ì¶• í•´ì œ ì™„ë£Œ â†’ {extract_dir}")

            # .html íŒŒì¼ ì°¾ê¸°
            html_file = None
            for root, _, files in os.walk(extract_dir):
                for f in files:
                    if f.endswith(".html"):
                        html_file = os.path.join(root, f)
                        # ë§ˆì§€ë§‰ ê³µë°± ì´í›„ í•´ì‹œ ì œê±° (ì˜ˆ: "Title 2a2451cf.html" â†’ "Title")
                        filename_without_ext = os.path.splitext(f)[0]
                        old_filename = filename_without_ext.rsplit(' ', 1)[0] if ' ' in filename_without_ext else filename_without_ext
                        break

            if html_file:
                process_html_file(html_file)

            # í•´ì œëœ í´ë” ì‚­ì œ
            shutil.rmtree(extract_dir)

            # zip íŒŒì¼ ì‚­ì œ
            # os.remove(zip_path)

