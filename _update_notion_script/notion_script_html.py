# Notionì—ì„œ exportí•œ html íŒŒì¼ì„ Jekyll ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸

# ì‚¬ìš©ë²•
# 1. Notionì—ì„œ exportí•œ html íŒŒì¼ê³¼ ì´ë¯¸ì§€ í´ë”ê°€ ë“¤ì–´ìˆëŠ” zip íŒŒì¼ì„ ì´ ìŠ¤í¬ë¦½íŠ¸ì™€ ê°™ì€ í´ë”ì— ë„£ìŠµë‹ˆë‹¤.
# 2. ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.
# 3. ì¹´í…Œê³ ë¦¬ë¥¼ ì„ íƒí•©ë‹ˆë‹¤.
# 4. ë³€í™˜ëœ Markdown íŒŒì¼ì´ _posts í´ë”ì— ìƒì„±ë©ë‹ˆë‹¤.
# 5. í•´ì œëë˜ í´ë”ëŠ” ì‚¬ë¼ì§€ê³ , zip íŒŒì¼ì€ ë‚¨ì•„ìˆìŠµë‹ˆë‹¤.
# 6. í™•ì¸ í›„ zip íŒŒì¼ì„ ì§ì ‘ ì‚­ì œí•©ë‹ˆë‹¤.

import os
import re
from datetime import datetime
from urllib.parse import unquote, quote
import shutil
import zipfile
from PIL import Image
from bs4 import BeautifulSoup

current_time = ""  # í˜„ì¬ ì‹œê°„ (YYYY-MM-DD HH:MM:SS)
current_date = ""  # ë‚ ì§œ (YYYY-MM-DD)
old_filename = ""  # ê¸°ì¡´ html íŒŒì¼ëª… ()
new_filename = ""  # ë§ˆí¬ë‹¤ìš´ íŒŒì¼ëª…ê³¼ í´ë”ëª… (YYYY-MM-DD-Data-Structure)

import unicodedata

def safe_filename(filename):
    filename = unicodedata.normalize("NFKD", filename)
    return filename.encode("ascii", "ignore").decode("ascii")

def merge_paragraphs_inside_callouts(html: str) -> str:
    soup = BeautifulSoup(html, "html.parser")

    for fig in soup.find_all("figure", class_=lambda c: c and "callout" in c):
        div = fig.find("div", style=lambda s: s and "width:100%" in s)
        if not div:
            continue

        # ì½œì•„ì›ƒ ë‚´ë¶€ <p>ë“¤ì„ <br>ë¡œ ì—°ê²°í•˜ì—¬ í•œ ë‹¨ë½ì²˜ëŸ¼ ë§Œë“¤ê¸°
        parts = []
        for p in div.find_all("p"):
            parts.append("".join(str(x) for x in p.contents))
        div.clear()
        div.append(BeautifulSoup("<br>".join(parts), "html.parser"))

    return str(soup)

# html íŒŒì¼ ë‚´ì— ìˆëŠ” src, href ì†ì„±ì˜ ê²½ë¡œë¥¼ ë³€ê²½í•˜ëŠ” í•¨ìˆ˜
def rewrite_image_paths_soup(html: str, old_filename: str, new_filename: str) -> str:
    soup = BeautifulSoup(html, "html.parser")

    old_paths = [old_filename, quote(old_filename), quote(old_filename).replace("%2B", "+")]

    for tag in soup.find_all(["img", "a"]):
        for attr in ["src", "href"]:
            if tag.has_attr(attr):
                for old in old_paths:
                    if tag[attr].startswith(old) or f"./{old}" in tag[attr]:
                        tag[attr] = tag[attr].replace(old, f"/files/{new_filename}")

    # í™•ì¥ì êµì²´
    for img in soup.find_all("img"):
        for ext in [".png", ".jpg", ".jpeg"]:
            if img["src"].endswith(ext):
                img["src"] = img["src"].replace(ext, ".webp")

    return str(soup)



def convert_figure_images(html: str) -> str:
    soup = BeautifulSoup(html, "html.parser")

    for figure in soup.find_all("figure", class_="image"):
        a_tag = figure.find("a")
        img_tag = a_tag.find("img") if a_tag else None
        if img_tag is None:
            continue

        # ìƒˆ img íƒœê·¸ ìƒì„±
        new_img = soup.new_tag("img")

        # ê¸°ì¡´ img ì†ì„± ë³µì‚¬
        for attr, value in img_tag.attrs.items():
            new_img[attr] = value

        # al-folio í™•ëŒ€ìš© ì†ì„± ì¶”ê°€
        new_img["class"] = "img-fluid rounded z-depth-1"
        new_img["data-zoomable"] = ""
        new_img["loading"] = "eager"
        new_img["onerror"] = "this.onerror=null; $('.responsive-img-srcset').remove();"

        # <picture>ë¡œ ê°ì‹¸ê¸°
        picture_tag = soup.new_tag("picture")
        picture_tag.append(new_img)

        # ê¸°ì¡´ <a> â†’ <picture>ë¡œ ëŒ€ì²´
        a_tag.replace_with(picture_tag)

    return str(soup)

# ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ìˆ˜ì • ë° ìƒì„±í•˜ëŠ” í•¨ìˆ˜
def write_markdown_file(filepath, html_content):
    global new_filename  # ì „ì—­ë³€ìˆ˜ ë³€ê²½í•´ì•¼í•˜ë¯€ë¡œ

    # ì œëª© ì¶”ì¶œ
    title = html_content.split("<title>")[1].split("</title>")[0].strip()

    # <div class="page-body"> ì´ì „ ë‚´ìš© ì œê±°
    marker = '<div class="page-body">'
    marker_index = html_content.find(marker)
    if marker_index != -1:
        html_content = html_content[marker_index:]

    # ë§ˆì§€ë§‰ ì¤„ </article> ì´í›„ ì œê±°
    end_marker = '</article>'
    end_index = html_content.find(end_marker)
    if end_index != -1:
        html_content = html_content[:end_index]

    # <details> íƒœê·¸ ìˆ˜ì • (ê¸°ë³¸ì ìœ¼ë¡œ ì—´ë ¤ìˆëŠ” ìƒíƒœê°€ ì•„ë‹ˆë„ë¡)
    html_content = html_content.replace("<details open=\"\">", "<details>")
    html_content = html_content.replace("<details open>", "<details>")

    # <figure> íƒœê·¸ë‚´ ì¤„ë°”ê¿ˆ ì¤‘ë³µ ì œê±°
    html_content = merge_paragraphs_inside_callouts(html_content)


    print(f"â­ï¸ {title}.html ë³€í™˜ì‘ì—…ì„ ì‹œì‘í•©ë‹ˆë‹¤.")

    # .html íŒŒì¼ëª…ê³¼ ì´ë¯¸ì§€ ë“±ì´ ë“¤ì–´ìˆëŠ” í´ë”ëª… ì‚¬ìš©ìê°€ ì§€ì •
    new_filename = input("íŒŒì¼ëª…ì„ ì˜ì–´ë¡œ ì…ë ¥í•´ì£¼ì„¸ìš” (ê³µë°±ì€ '-'ìœ¼ë¡œ ìë™ ë³€ê²½ë©ë‹ˆë‹¤): ").strip()

    # í—ˆìš©: ì•ŒíŒŒë²³(a-zA-Z), ìˆ«ì(0-9), ê³µë°±, í•˜ì´í”ˆ(-)ë§Œ â†’ ê·¸ ì™¸ëŠ” ëª¨ë‘ ê±°ë¶€
    while not new_filename or not re.fullmatch(r"[a-zA-Z0-9 \-]+", new_filename):
        if not new_filename:
            print("âŒ ë¹„ì›Œë‘˜ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:
            print("âŒ ì˜ì–´, ìˆ«ì, ê³µë°±, í•˜ì´í”ˆ(-)ë§Œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        new_filename = input("ë‹¤ì‹œ ì…ë ¥í•´ì£¼ì„¸ìš”: ").strip()
    new_filename = new_filename.replace(" ", "-")  # ê³µë°±ì„ '-'ë¡œ ë³€ê²½
    new_filename = f"{current_date}-{new_filename}"  # ë‚ ì§œ ì¶”ê°€

    # â­ï¸ íƒœê·¸ ì…ë ¥ (ì—¬ëŸ¬ ê°œ ê°€ëŠ¥)
    raw_tags = input("íƒœê·¸ë¥¼ ë„ì–´ì“°ê¸°ë¡œ ì…ë ¥í•´ì£¼ì„¸ìš” (CS, AI, PS ...): ").strip()
    tags = [tag.strip() for tag in raw_tags.split() if tag.strip()]
    tag_str = ", ".join(tags) if tags else ""

    # â­ï¸ ì¹´í…Œê³ ë¦¬ ì…ë ¥ (í•˜ë‚˜ë§Œ)
    category = input("ì¹´í…Œê³ ë¦¬ë¥¼ í•˜ë‚˜ ì…ë ¥í•´ì£¼ì„¸ìš” (Talk, Tip, Study, Paper): ").strip()

    # YAML í”„ë¡ íŠ¸ ë§¤í„° ìƒì„±
    yaml_front_matter = f"""---
layout: notion
title: "{title}"
description:
date: {current_time} +09:00
tags: {tag_str}
categories: {category}
giscus_comments: true
related_posts: false

featured: false
pretty_table: true

toc:
  beginning: false  # ë§¨ ì•ì— ëª©ì°¨
  sidebar: left  # ëª©ì°¨ê°€ ì‚¬ì´ë“œë°” ì™¼ìª½ì— ë¶™ì–´ìˆìŒ
---
"""

    # ì´ë¯¸ì§€ ê²½ë¡œ ìˆ˜ì •
    html_content = rewrite_image_paths_soup(html_content, old_filename, new_filename)
    html_content = convert_figure_images(html_content)


    # â­ï¸ .md ìˆ˜ì •ë³¸ ìƒì„± í›„ ì €ì¥
    final_content = yaml_front_matter + html_content
    script_dir = os.path.dirname(os.path.abspath(__file__))
    posts_dir = os.path.join(os.path.dirname(script_dir), "_posts")
    os.makedirs(posts_dir, exist_ok=True)
    new_filepath = os.path.join(posts_dir, f"{new_filename}.md")
    with open(new_filepath, 'w', encoding='utf-8') as file:
        file.write(final_content)
    print(f"â­ï¸ ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ìƒì„± ì™„ë£Œ: {new_filepath}")

# ì´ë¯¸ì§€ íŒŒì¼ì„ webpë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜
def convert_to_webp(input_path, output_path, quality=80):
    try:
        img = Image.open(input_path)

        ext = os.path.splitext(input_path)[1].lower()
        if ext in [".jpg", ".jpeg"]:
            img = img.convert("RGB")   # JPG/JPEG â†’ RGB (ë¶ˆíˆ¬ëª…)
        elif ext == ".png":
            img = img.convert("RGBA")  # PNG â†’ RGBA (íˆ¬ëª…ë„ ìœ ì§€)

        img.save(output_path, "webp", quality=quality)

        # ë³€í™˜ ì„±ê³µí•œ ê²½ìš° ì›ë³¸ ì‚­ì œ
        os.remove(input_path)

    except Exception as e:
        print(f"âŒ ì´ë¯¸ì§€ ë³€í™˜ ì‹¤íŒ¨: {input_path} â†’ {output_path}\nì—ëŸ¬: {e}")



# ì´ë¯¸ì§€ê°€ ë“¤ì–´ìˆëŠ” í´ë”ë¥¼ "files/" ì•ˆìœ¼ë¡œ ë³µì‚¬í•˜ëŠ” í•¨ìˆ˜
def copy_folder(html_path):
    """
    html_path: ì›ë³¸ html ê²½ë¡œ
    new_filename: ì˜ˆì‹œ - '2025-04-04-MLOps.md'
    """

    # ì›ë³¸ ì´ë¯¸ì§€ í´ë”: html íŒŒì¼ ì˜†ì— ìˆëŠ” ë™ì¼ ì´ë¦„ í´ë”
    html_dir = os.path.dirname(html_path)
    html_filename = os.path.splitext(os.path.basename(html_path))[0]
    original_image_folder = os.path.join(html_dir, html_filename)

    if not os.path.exists(original_image_folder):
        print(f"ğŸŒ‰ ì´ë¯¸ì§€ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return

    # íƒ€ê²Ÿ ê²½ë¡œ: files/{new_filename_without_ext}/
    script_dir = os.path.dirname(os.path.abspath(__file__))
    root_dir = os.path.dirname(script_dir)
    folder_name = os.path.splitext(new_filename)[0]  # .md ì œê±°
    target_folder = os.path.join(root_dir, "files", folder_name)
    os.makedirs(target_folder, exist_ok=True)

    # ì´ë¯¸ì§€ ë³µì‚¬
    for item in os.listdir(original_image_folder):
        src_path = os.path.join(original_image_folder, item)
        dst_path = os.path.join(target_folder, item)
        if os.path.isfile(src_path):
            base, _ = os.path.splitext(item)
            dst_filename = base + ".webp"
            dst_path = os.path.join(target_folder, dst_filename)
            convert_to_webp(src_path, dst_path)

    print(f"â­ï¸ ì´ë¯¸ì§€ ë³µì‚¬ ì™„ë£Œ â†’ {target_folder}")

def process_html_file(filepath):
    global current_time, current_date

    while True:
        raw_date = input(f"ğŸ“… [{os.path.basename(filepath)}] ê²Œì‹œ ë‚ ì§œë¥¼ ì…ë ¥í•˜ì„¸ìš” (í˜•ì‹: YYMMDD, ì—”í„° ì‹œ ì˜¤ëŠ˜ ë‚ ì§œ ì‚¬ìš©): ").strip()

        if raw_date == "":
            dt = datetime.now()
            current_date = dt.strftime("%Y-%m-%d")
            break
        if not re.fullmatch(r"\d{6}", raw_date):
            print("âŒ ë‚ ì§œ í˜•ì‹ì´ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤. YYMMDD í˜•ì‹ìœ¼ë¡œ 6ìë¦¬ ìˆ«ìë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”. (ì˜ˆ: 250206)")
            continue
        try:
            # "25" â†’ "2025"
            full_date = "20" + raw_date
            dt = datetime.strptime(full_date, "%Y%m%d")
            current_date = dt.strftime("%Y-%m-%d")
            break
        except ValueError:
            print("âŒ ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ë‚ ì§œì…ë‹ˆë‹¤.")


    # âœ… ì‚¬ìš©ì ì…ë ¥ ë‚ ì§œ + í˜„ì¬ ì‹œê° ì¡°í•©ìœ¼ë¡œ date ê³ ì •
    current_time = f"{current_date} {datetime.now().strftime('%H:%M:%S')}"



    # íŒŒì¼ ì½ê¸°
    with open(filepath, 'r', encoding='utf-8') as file:
        html_content = file.read()

    # ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ìƒì„±
    write_markdown_file(filepath, html_content)

    # ì´ë¯¸ì§€ ë“¤ì–´ìˆëŠ” í´ë” ì˜®ê¸°ê¸°
    copy_folder(filepath)

    # â­ï¸ ë³€í™˜ ì™„ë£Œ ë©”ì‹œì§€
    print(f"â­ï¸ ëª¨ë“  ì‘ì—… ì™„ë£Œ â†’ {new_filename}\n")


if __name__ == "__main__":
    script_dir = os.path.dirname(os.path.abspath(__file__))

    for filename in os.listdir(script_dir):
        if filename.endswith(".zip"):
            zip_path = os.path.join(script_dir, filename)
            extract_dir = os.path.join(script_dir, os.path.splitext(filename)[0])

            # ì••ì¶• í•´ì œ
            with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                zip_ref.extractall(extract_dir)

            # .html íŒŒì¼ ì°¾ê¸°
            html_file = None
            for root, _, files in os.walk(extract_dir):
                for f in files:
                    if f.endswith(".html"):
                        html_file = os.path.join(root, f)
                        old_filename = os.path.splitext(f)[0]
                        break

            if html_file:
                process_html_file(html_file)

            # í•´ì œëœ í´ë” ì‚­ì œ
            shutil.rmtree(extract_dir)

            # zip íŒŒì¼ ì‚­ì œ
            # os.remove(zip_path)

