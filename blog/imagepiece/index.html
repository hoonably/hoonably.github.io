<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta name="google-site-verification" content=""> <meta http-equiv="Permissions-Policy" content="interest-cohort=()"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> ImagePiece: Content-aware Re-tokenization for Efficient Image Recognition </title> <meta name="author" content="Jeonghoon Park"> <meta name="description" content="Undergraduate student at UNIST (CSE), interested in AI, optimization, and systems programming. "> <meta name="keywords" content="UNIST, computer science, undergraduate, on-device AI, optimization, problem solving"> <meta http-equiv="Cache-Control" content="no-cache, no-store, must-revalidate"> <meta http-equiv="Pragma" content="no-cache"> <meta http-equiv="Expires" content="0"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-table@1.22.4/dist/bootstrap-table.min.css" integrity="sha256-uRX+PiRTR4ysKFRCykT8HLuRCub26LgXJZym3Yeom1c=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link defer href="/assets/css/bootstrap-toc.min.css?6f5af0bb9aab25d79b2448143cbeaa88" rel="stylesheet"> <link rel="shortcut icon" href="/assets/img/profile/profile.webp?b5bec9d555338d1029578e54703400f7"> <link rel="stylesheet" href="/assets/css/pretendard-subset.css"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://jeonghoonpark.com/blog/imagepiece/"> <script src="/assets/js/theme.js?c06f90403cefcf6ac822b3d318259fcc"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-dark.css?7f7b80282ea53f5dd6b976ff3d9857f9" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Jeonghoon Park </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link" style="white-space: nowrap;">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="row"> <div class="col-sm-3"> <nav id="toc-sidebar" class="sticky-top"></nav> </div> <div class="col-sm-9"> <div class="pagein"> <div class="post"> <header class="post-header"> <h1 class="post-title">ImagePiece: Content-aware Re-tokenization for Efficient Image Recognition</h1> <p class="post-meta"> Created on November 10, 2025 </p> <p class="post-tags"> <a href="/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/tag/ai"> <i class="fa-solid fa-hashtag fa-sm"></i> AI</a>   ·   <a href="/blog/category/paper"> <i class="fa-solid fa-tag fa-sm"></i> Paper</a> </p> </header> <article class="post-content"> <div id="markdown-content" class="notion"> <table class="simple-table" id="2a2451cf-7b79-80ec-a0f0-fdf31d8e2359"><tbody> <tr id="2a2451cf-7b79-80a3-bcc3-e983c2e00493"> <th class="simple-table-header-color simple-table-header" id="MApI" style="width:125.5px">ArXiv</th> <td class="" id="L|H:" style="width:580.5px"><a href="http://arxiv.org/abs/2412.16491" rel="external nofollow noopener" target="_blank">http://arxiv.org/abs/2412.16491</a></td> </tr> <tr id="2a2451cf-7b79-801b-b438-f4eb35d42239"> <th class="simple-table-header-color simple-table-header" id="MApI" style="width:125.5px">Authors</th> <td class="" id="L|H:" style="width:580.5px">Seungdong Yoa, Seungjun Lee, Hyeseung Cho, Bumsoo Kim, Woohyung Lim</td> </tr> <tr id="2a2451cf-7b79-80fc-9ab3-f8a7ecc18eaf"> <th class="simple-table-header-color simple-table-header" id="MApI" style="width:125.5px">Affiliation</th> <td class="" id="L|H:" style="width:580.5px">LG AI Research, Chung-ang University</td> </tr> </tbody></table> <figure class="block-color-teal_background callout" id="2a2451cf-7b79-80aa-8a9a-e46637cba880" style="white-space:pre-wrap;display:flex"><div style="font-size:1.5em"><span class="icon">💡</span></div> <div style="width:100%"> <strong>Key Differentiator</strong><br>Attention 점수가 낮은 Non-sementic한 Token끼리만 Merging<br>→ 최대한 Token Merging에서 의미있는 것들이 Merge되지 않도록 Token Reduction</div></figure> <figure class="block-color-gray_background callout" id="2a2451cf-7b79-801b-b390-d52f37784a2b" style="white-space:pre-wrap;display:flex"><div style="font-size:1.5em"><span class="icon">🤷</span></div> <div style="width:100%"> <strong>Why I chose this paper?</strong><li style="list-style-type:disc">우리나라 기업이 내는 논문을 읽고싶었다.</li> <li style="list-style-type:disc">내가 최근에 제출했던 Efficient GUI Grounding 논문의 후속연구를 Token 기반으로 확장하고 싶었다.</li> </div></figure> <p class="" id="2a2451cf-7b79-8029-bb5f-dd54af88026a"> </p> <p class="" id="2a2451cf-7b79-806c-b14b-dd3fc3fdeb4e"> </p> <h1 class="" id="2a2451cf-7b79-8011-9653-d84273fafe9e">Abstract</h1> <p class="" id="2a4451cf-7b79-800f-816c-dcbc4a8c7cbd">Vision Transformer는 모든 패치를 토큰으로 처리하기 때문에 계산량이 큼</p> <p class="" id="2a4451cf-7b79-806c-9694-f9f8f6071aa7">→ 기존 연구들은 토큰을 제거(pruning) 하거나 합치기(merging)</p> <p class="" id="2a4451cf-7b79-8057-b2a8-d30b426ebe78">→ 각 토큰이 의미를 충분히 담고 있지 않아서 의미 없는 토큰을 단순히 제거하거나 섞으면 오히려 정보 손실이 큼</p> <p class="" id="2a4451cf-7b79-807a-b27b-e5f7dff5866e"> </p> <p class="" id="2a4451cf-7b79-8021-b3b2-e77c361a6746">이 논문은 ‘ImagePiece’ 라는 새로운 재토크나이제이션(re-tokenization) 방식을 제안</p> <p class="" id="2a4451cf-7b79-8015-a448-fb6befff9029"><a href="https://wikidocs.net/166826" rel="external nofollow noopener" target="_blank">https://wikidocs.net/166826</a></p> <p class="" id="2a4451cf-7b79-80f8-9da0-c4c7b79ccd8e">WordPiece tokenizer처럼 이미지 안의 의미 없는 작은 패치들을 합쳐서 의미 있는 단위가 될 때까지 묶는 방식</p> <p class="" id="2a4451cf-7b79-8018-9ab2-f610e3bb789f"> </p> <li style="list-style-type:disc">local coherence 모듈: 인접한 패치들의 유사성을 높여, 서로 의미를 형성하도록 도움</li> <li style="list-style-type:disc">이렇게 만들어진 새로운 “의미 있는 토큰”만 Transformer에 남기고, 끝까지 의미가 없는 토큰은 버린다.</li> <p class="" id="2a2451cf-7b79-803c-ace2-e5464bfbb790"> </p> <p class="" id="2a4451cf-7b79-8065-9492-e5bb4ac63047">결과</p> <li style="list-style-type:disc">DeiT-S 모델 기준 추론 속도 54% 향상 (약 1.5배 빠름)</li> <li style="list-style-type:disc">동시에 ImageNet 정확도 0.39% 향상</li> <li style="list-style-type:disc">극단적인 속도 조건(251% 가속)에서도 기존 방식보다 정확도가 8% 이상 높음</li> <p class="" id="2a4451cf-7b79-8009-8fe8-f0e5ca3c7eef"> </p> <p class="" id="2a4451cf-7b79-806c-af8b-dd01fcbcc760"> </p> <hr id="2a4451cf-7b79-806b-b912-c64daedd5ed6"> <h1 class="" id="2a6451cf-7b79-808e-b15f-d37b828a9af5">Preliminary</h1> <h3 class="" id="2a4451cf-7b79-8004-894f-f3082bce7f01">Vision Transformer(ViT)</h3> <li style="list-style-type:disc">Transformer는 원래 NLP용 모델이지만,<p class="" id="2a4451cf-7b79-8098-beed-d17765941491">이미지에도 적용되면서 Vision Transformer(ViT) 가 등장 (Dosovitskiy et al., 2021)</p> </li> <li style="list-style-type:disc">이미지를 정사각형 패치(p×p) 로 나누고, 각 패치를 하나의 토큰(token) 으로 변환해 Transformer에 입력</li> <li style="list-style-type:disc">224×224 이미지, 패치 크기 16×16 → <style>@import url('https://cdn.jsdelivr.net/npm/katex@0.16.25/dist/katex-swap.min.css')</style> <span class="notion-text-equation-token" contenteditable="false" data-token-index="0" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mn>224</mn><mi mathvariant="normal">/</mi><mn>16</mn><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mo>=</mo><msup><mn>14</mn><mn>2</mn></msup><mo>=</mo><mn>196</mn></mrow><annotation encoding="application/x-tex">(224/16)^2 = 14^2 = 196</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:1.0641em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">224/16</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord">1</span><span class="mord"><span class="mord">4</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">196</span></span></span></span></span><span>﻿</span></span> 개의 토큰 생성<p class="" id="2a6451cf-7b79-808e-8b6f-f26c7357b8e5">여기에 [CLS] 토큰을 추가해 총 197개의 토큰이 Transformer 입력</p> <p class="" id="2a6451cf-7b79-80a9-a548-d2e6b2bb1e3d"> </p> </li> <li><details><summary>Token Importance (토큰 중요도 평가)</summary><li style="list-style-type:disc">ViT 내부에서는 [CLS] 토큰이  <strong>전체 이미지의 전역 정보를 요약</strong>하는 역할을 함.</li> <li style="list-style-type:disc">각 토큰의 중요도는  <strong>[CLS] 토큰이 해당 토큰에 얼마나 주의를 두는가(attention)</strong> 로 측정</li> <figure class="equation" id="2a6451cf-7b79-80c5-967e-c0bc64c600e6"><style>@import url('https://cdn.jsdelivr.net/npm/katex@0.16.25/dist/katex-swap.min.css')</style> <div class="equation-container"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>A</mi><mtext>class</mtext></msub><mo>=</mo><mtext>Softmax</mtext><mrow><mo fence="true">(</mo><mfrac><mrow><msub><mi>Q</mi><mtext>class</mtext></msub><msup><mi>K</mi><mi mathvariant="normal">⊤</mi></msup></mrow><msqrt><mi>D</mi></msqrt></mfrac><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex"> A_\text{class} = \text{Softmax}\left( \frac{Q_\text{class} K^\top}{\sqrt{D}} \right)</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord text mtight"><span class="mord mtight">class</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.4761em;vertical-align:-0.95em;"></span><span class="mord text"><span class="mord">Softmax</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size3">(</span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.5261em;"><span style="top:-2.1833em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9267em;"><span class="svg-align" style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord" style="padding-left:0.833em;"><span class="mord mathnormal" style="margin-right:0.02778em;">D</span></span></span><span style="top:-2.8867em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail" style="min-width:0.853em;height:1.08em;"><svg height="1.08em" preserveaspectratio="xMinYMin slice" viewbox="0 0 400000 1080" width="400em" xmlns="http://www.w3.org/2000/svg"><path d="M95,702 c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14 c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54 c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10 s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429 c69,-144,104.5,-217.7,106.5,-221 l0 -0 c5.3,-9.3,12,-14,20,-14 H400000v40H845.2724 s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7 c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z M834 80h400000v40h-400000z"></path></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1133em;"><span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord text mtight"><span class="mord mtight">class</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">⊤</span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.93em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size3">)</span></span></span></span></span></span></span></div></figure><figure class="equation" id="2a6451cf-7b79-8043-9026-c290d663b324"><style>@import url('https://cdn.jsdelivr.net/npm/katex@0.16.25/dist/katex-swap.min.css')</style> <div class="equation-container"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mtext>class</mtext></msub><mo>=</mo><msub><mi>A</mi><mtext>class</mtext></msub><mi>V</mi></mrow><annotation encoding="application/x-tex">x_\text{class} = A_\text{class} V</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord text mtight"><span class="mord mtight">class</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord text mtight"><span class="mord mtight">class</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span></span></span></span></span></div></figure><li style="list-style-type:disc"> <style>@import url('https://cdn.jsdelivr.net/npm/katex@0.16.25/dist/katex-swap.min.css')</style> <span class="notion-text-equation-token" contenteditable="false" data-token-index="0" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Q</mi><mtext>class</mtext></msub></mrow><annotation encoding="application/x-tex">Q_\text{class}</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord text mtight"><span class="mord mtight">class</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span> : [CLS] 토큰의 query 벡터</li> <li style="list-style-type:disc"> <style>@import url('https://cdn.jsdelivr.net/npm/katex@0.16.25/dist/katex-swap.min.css')</style> <span class="notion-text-equation-token" contenteditable="false" data-token-index="0" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi><mo separator="true">,</mo><mi>V</mi></mrow><annotation encoding="application/x-tex">K, V</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span></span></span></span></span><span>﻿</span></span>: 전체 토큰의 key, value 행렬</li> <li style="list-style-type:disc"> <style>@import url('https://cdn.jsdelivr.net/npm/katex@0.16.25/dist/katex-swap.min.css')</style> <span class="notion-text-equation-token" contenteditable="false" data-token-index="0" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>A</mi><mtext>class</mtext></msub></mrow><annotation encoding="application/x-tex">A_\text{class}</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord text mtight"><span class="mord mtight">class</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span>: 각 토큰이 [CLS]에 의해 얼마나 중요하게 여겨지는지 나타내는  <strong>attention score</strong> </li> <p class="" id="2a6451cf-7b79-80b1-ac7f-c41a5edd322a">→ 이  <strong>attention score</strong> 값이 높을수록, 그 토큰은 전체 이미지 의미를 구성하는 데 더 중요함을 의미.</p></details></li> <p class="" id="2a6451cf-7b79-80ba-83e9-f52bdbb3973d"> </p> <li style="list-style-type:disc">각 토큰은 패치 임베딩(embedding) + 위치 임베딩(positional embedding) 을 포함하여<p class="" id="2a6451cf-7b79-801a-ba61-fe6d36f55537">Self-Attention으로 전역 정보를 학습함.</p> </li> <li style="list-style-type:disc">즉, NLP에서의 “단어 토큰” → ViT에서는 “이미지 패치 토큰”</li> <p class="" id="2a4451cf-7b79-80ce-8643-e9035a978e36">그러나 두 분야는 토큰의 의미(semantic structure) 측면에서 큰 차이가 있음</p> <table class="simple-table" id="2a4451cf-7b79-8021-bcfb-d5299a18b2fa"> <thead class="simple-table-header"><tr id="2a4451cf-7b79-8046-8ad4-f41e04be5cea"> <th class="simple-table-header-color simple-table-header" id="TB:Q" style="width:235.66666666666666px">구분</th> <th class="simple-table-header-color simple-table-header" id="sGZu" style="width:235.66666666666666px">NLP (WordPiece 등)</th> <th class="simple-table-header-color simple-table-header" id="cM{;" style="width:235.66666666666666px">ViT (Patch Token)</th> </tr></thead> <tbody> <tr id="2a4451cf-7b79-807a-8c33-e24574bbfce6"> <td class="" id="TB:Q" style="width:235.66666666666666px"> <strong>입력 단위</strong> </td> <td class="" id="sGZu" style="width:235.66666666666666px">단어 또는 의미 있는 서브워드</td> <td class="" id="cM{;" style="width:235.66666666666666px">16×16 픽셀 패치</td> </tr> <tr id="2a4451cf-7b79-80ae-9e39-ef61a57567f3"> <td class="" id="TB:Q" style="width:235.66666666666666px"> <strong>토큰 의미</strong> </td> <td class="" id="sGZu" style="width:235.66666666666666px">대부분 의미 있음</td> <td class="" id="cM{;" style="width:235.66666666666666px">많은 패치는 배경 등, 의미 없음</td> </tr> <tr id="2a4451cf-7b79-805f-ba42-c454ecfe1c81"> <td class="" id="TB:Q" style="width:235.66666666666666px"> <strong>결과적 문제</strong> </td> <td class="" id="sGZu" style="width:235.66666666666666px">없음</td> <td class="" id="cM{;" style="width:235.66666666666666px">정보가 희박하고 중복 많음</td> </tr> </tbody> </table> <p class="" id="2a4451cf-7b79-802a-a75e-d421a7dac6d1">👉 ViT의 효율성 문제는 “의미 없는 토큰이 너무 많음” 에서 비롯됨.</p> <p class="" id="2a6451cf-7b79-8054-9f36-da64196aa3f8">ViT = O(N²)</p> <p class="" id="2a6451cf-7b79-8002-bc12-fc86a7bbc4b1"> </p> <hr id="2a4451cf-7b79-801b-84a3-e9d439ae133a"> <h1 class="" id="2a4451cf-7b79-8064-b1e2-e744e300be5f">Related Work (Efficient Transformer)</h1> <h3 class="" id="2a6451cf-7b79-8027-a97a-df359c606878">(1) Efficient Attention</h3> <p class="" id="2a4451cf-7b79-8034-bc55-ea795a964894">Self-Attention의 연산량 자체를 줄이는 접근.</p> <p class="" id="2a4451cf-7b79-80f5-842d-c761706926fa">Attention을 근사하거나 병렬 최적화로 속도 향상.</p> <li style="list-style-type:disc">Linformer (Wang et al., 2020)</li> <li style="list-style-type:disc">Performer (Choromanski et al., 2020)</li> <li style="list-style-type:disc">FlashAttention (Dao et al., 2022)</li> <p class="" id="2a4451cf-7b79-80c6-b9d5-ead210596826">→ Attention 레벨의 최적화로 계산만 줄이고, 토큰 자체의 의미 문제는 해결하지 못함.</p> <h3 class="" id="2a4451cf-7b79-806e-b6fe-d2e33e6b1ec5">(2) Token Pruning (토큰 제거)</h3> <p class="" id="2a4451cf-7b79-80a0-9f76-c3cb6eb11765">비중요 토큰을 attention score 기준으로 제거.</p> <li style="list-style-type:disc">DynamicViT (Rao et al., 2021): 학습된 projection layer로 토큰을 점진적으로 버림.</li> <li style="list-style-type:disc">EViT (Liang et al., 2022): class token에 대한 attention을 기준으로 하위 토큰 삭제.</li> <li style="list-style-type:disc">SPViT (Kong et al., 2022): soft selector로 중요도 계산 후 pruning.</li> <p class="" id="2a4451cf-7b79-8035-95bc-ef70131ca07d">→ 의미가 완전히 드러나지 않은 토큰(예: 버스의 일부 조각)을 너무 빨리 제거함 → 정보 손실 발생.</p> <h3 class="" id="2a4451cf-7b79-802f-b1b9-f52f77718578">(3) Token Merging (토큰 병합)</h3> <p class="" id="2a4451cf-7b79-80a0-b97f-c30f80f01086">비슷한 특징을 가진 토큰들을 결합(merge) 하여 수를 줄임.</p> <li style="list-style-type:disc">ToMe (Bolya et al., 2023): bipartite soft matching으로 가장 유사한 토큰 쌍 병합.</li> <li style="list-style-type:disc">Token Pooling (Marin et al., 2021): K-Means 기반 병합.</li> <li style="list-style-type:disc">Token Learner (Ryoo et al., 2021): MLP로 선택적 토큰 생성.</li> <p class="" id="2a4451cf-7b79-8050-a203-c32f812b22f3">→ 비슷하지만 의미가 다르거나 중요한 토큰들까지 섞임 → 결과적으로 semantic dilution (의미 희석) 발생.</p> <p class="" id="2a4451cf-7b79-803d-a862-f8ee7d983563"> </p> <p class="" id="2a4451cf-7b79-80b1-8818-e6df1352a412">이들의 공통점!</p> <p class="" id="2a4451cf-7b79-80a1-9aa6-e350750aaadb"> <strong>“토큰의 의미(semanitcs)를 고려하지 않는다”</strong></p> <p class="" id="2a4451cf-7b79-8003-a3de-ff50a53bb659"> </p> <hr id="2a4451cf-7b79-80ca-9eb5-f45cfad3ad53"> <h1 class="" id="2a4451cf-7b79-80d7-b6cb-c83084b49fe7">ImagePiece</h1> <p class="" id="2a4451cf-7b79-80c6-979d-cc46ba75d589"> </p> <figure class="image" id="2a4451cf-7b79-801f-aae6-d07bfcae7f8f"><picture><img class="img-fluid rounded z-depth-1" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" src="/files/2025-11-10-imagepiece/image.webp" style="width:628.0042114257812px"></picture></figure> <p class="" id="2a6451cf-7b79-8028-b70c-f8667d4c6679"> </p> <blockquote class="" id="2a6451cf-7b79-8038-ac27-d2f28eb665a7">ViT의 효율화는 단순히 토큰 수를 줄이는 게 아니라,<p class="" id="2a6451cf-7b79-8031-90d7-df9feb176625">“토큰이 충분히 의미를 가질 때까지 재구성(re-tokenization)” 해야 한다.</p> </blockquote> <p class="" id="2a6451cf-7b79-80ec-bb06-f01bab00e827"> </p> <h3 class="" id="2a4451cf-7b79-8054-88c7-f667a25f0c38">Step I : Token Importance Evaluation</h3> <li style="list-style-type:disc">각 토큰이 전체 이미지 의미에 얼마나 기여하는지 평가</li> <li style="list-style-type:disc">[CLS] 토큰과의 attention 값 <style>@import url('https://cdn.jsdelivr.net/npm/katex@0.16.25/dist/katex-swap.min.css')</style> <span class="notion-text-equation-token" contenteditable="false" data-token-index="0" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>A</mi><mtext>class</mtext></msub></mrow><annotation encoding="application/x-tex">A_\text{class}</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord text mtight"><span class="mord mtight">class</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span> 을 이용해 중요도 순위를 계산</li> <li style="list-style-type:disc">중요도가 낮은 bottom-k 토큰을 후보로 지정 → “non-semantic tokens”</li> <h3 class="" id="2a4451cf-7b79-80c6-b386-efe7039f6eca">Step II : Re-tokenization of Non-semantic Tokens</h3> <li style="list-style-type:disc">bottom-k 토큰들을 두 그룹(A, B)으로 나눈 뒤,<p class="" id="2a4451cf-7b79-80e7-a1fd-d1b4155784fa">가장 유사한 쌍끼리 merge</p> </li> <li style="list-style-type:disc">병합에는 bipartite soft matching을 사용</li> <li><details><summary>Bipartite soft matching (Bolya et al., 2023)</summary><p class="" id="2a6451cf-7b79-80bf-8cc2-d9c7b10c77c8">“두 그룹 사이의 최적 유사도 매칭” 을 부드럽게(softly) 계산하는 알고리즘</p> <ol class="numbered-list" id="2a6451cf-7b79-80fd-aa05-dd8bef70facd" start="1" type="1"> <li>Bipartite structure</li> <li style="list-style-type:disc">두 토큰 집합 A 와 B 가 주어졌을 때, A의 각 토큰이 B 내의 한 토큰과 연결될 확률 계산</li> </ol></details></li> <ol class="numbered-list" id="2a6451cf-7b79-8009-a94c-dce36176a031" start="2" type="1"> <li>Soft assignment</li> <li style="list-style-type:disc">각 연결의 강도 : <style>@import url('https://cdn.jsdelivr.net/npm/katex@0.16.25/dist/katex-swap.min.css')</style> <span class="notion-text-equation-token" contenteditable="false" data-token-index="0" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>=</mo><mtext>Softmax</mtext><mo stretchy="false">(</mo><msub><mi>S</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">w_{ij} = \text{Softmax}(S_{ij})</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">ij</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.0361em;vertical-align:-0.2861em;"></span><span class="mord text"><span class="mord">Softmax</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0576em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">ij</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span><span>﻿</span></span> </li> <p class="" id="2a6451cf-7b79-80b7-b8a4-f870f1a240c4">→ 하나의 A 토큰이 여러 B 토큰의 정보를 가중합 형태로 병합 가능</p> </ol> <ol class="numbered-list" id="2a6451cf-7b79-808a-8fe4-cefd199f9f4b" start="3" type="1"> <li>Information preserving merge</li> <li style="list-style-type:disc">새 토큰은 <style>@import url('https://cdn.jsdelivr.net/npm/katex@0.16.25/dist/katex-swap.min.css')</style> <span class="notion-text-equation-token" contenteditable="false" data-token-index="0" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>t</mi><mi>i</mi><mo lspace="0em" mathvariant="normal" rspace="0em">′</mo></msubsup><mo>=</mo><msub><mo>∑</mo><mi>j</mi></msub><msub><mi>w</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><msub><mi>t</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">t'_i = \sum_j w_{ij} t_j</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:1.0106em;vertical-align:-0.2587em;"></span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7519em;"><span style="top:-2.4413em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2587em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.1858em;vertical-align:-0.4358em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.162em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4358em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">ij</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span> 로 계산되어,<p class="" id="2a6451cf-7b79-80d3-86e4-f3f271f964bc">하드 매칭보다 더 연속적이고 손실이 적은 병합을 수행</p> </li> </ol> <p class="" id="2a6451cf-7b79-805e-a372-f5f645dacf9d"> </p> <h3 class="" id="2a4451cf-7b79-809a-bc0c-f92f575f7e8a">Step III : Re-evaluation and Discarding</h3> <li style="list-style-type:disc">merge된 토큰들만 attention 을 다시 계산히면서 step1, 2 반복</li> <li style="list-style-type:disc">최종적으로 여전히 의미가 없으면 → 최종적으로 삭제 (prune)</li> <p class="" id="2a6451cf-7b79-804d-8cc1-d8aea51d8c80"> </p> <h3 class="" id="2a4451cf-7b79-80e3-aa62-ed3334d09afe">Local Coherence Bias (로컬 일관성 강화 모듈)</h3> <li style="list-style-type:disc">이미지의 공간적 특성을 고려해, 인접한 패치들은 유사하게 인식되도록 bias를 추가</li> <li style="list-style-type:disc">구체적으로 4개의 3×3 conv + 1개의 1×1 conv 를 적용해 겹치는 패치 feature 를 만듦</li> <li style="list-style-type:disc">결과적으로 공간적으로 가까운 패치들은 유사도가 높아지고,<p class="" id="2a4451cf-7b79-80fc-ba48-cbc9f7bba33c">병합 과정에서 자연스럽게 같은 의미 단위로 묶임</p> <p class="" id="2a7451cf-7b79-80b1-a65c-fb0f3fdeabb7"> </p> </li> <p class="" id="2a7451cf-7b79-80ac-bc5d-c46c4c29151f"> </p> <figure class="image" id="2a4451cf-7b79-80b5-92bc-c03f7452f9b2"><picture><img class="img-fluid rounded z-depth-1" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" src="/files/2025-11-10-imagepiece/image%201.webp" style="width:628.0042114257812px"></picture></figure> <table class="simple-table" id="2a4451cf-7b79-80a7-bbaa-fc91876b8ff6"> <thead class="simple-table-header"><tr id="2a4451cf-7b79-8077-b748-e5262cbb3bc0"> <th class="simple-table-header-color simple-table-header" id="P]f?" style="width:353.5px">WordPiece (NLP)</th> <th class="simple-table-header-color simple-table-header" id="i&gt;Kf" style="width:353.5px">ImagePiece (Vision)</th> </tr></thead> <tbody> <tr id="2a4451cf-7b79-8033-b04d-c4df280b6036"> <td class="" id="P]f?" style="width:353.5px">문장을 의미 있는 단어 단위로 분해.</td> <td class="" id="i&gt;Kf" style="width:353.5px">이미지를 16×16 패치로 분할.</td> </tr> <tr id="2a4451cf-7b79-8044-a874-c59c5e727523"> <td class="" id="P]f?" style="width:353.5px">“meaningful tokens” → 각 토큰이 이미 의미를 가짐.</td> <td class="" id="i&gt;Kf" style="width:353.5px">“patch tokens” → 대부분 의미 없음(배경·하늘 등).</td> </tr> <tr id="2a4451cf-7b79-805d-a1c8-f22efefb098a"> <td class="" id="P]f?" style="width:353.5px">긴 문장을 MaxMatch(최대 일치) 로 토큰화.</td> <td class="" id="i&gt;Kf" style="width:353.5px">의미 없는 패치들을 의미가 생길 때까지 합침.</td> </tr> </tbody> </table> <blockquote class="" id="2a4451cf-7b79-80e6-87a9-c580d3d67975">WordPiece는 단어를 쪼개 의미 단위를 만들고,<p class="" id="2a4451cf-7b79-80f0-a9bf-c682b38a8791">ImagePiece는 반대로 의미 없는 조각들을 합쳐 의미 단위로 만듦</p> </blockquote> <p class="" id="2a4451cf-7b79-805b-be15-e500ffb86852">예를 들어, 파란색 패치 하나만 보면 아무 의미 없지만</p> <p class="" id="2a4451cf-7b79-8069-b38a-ef6a4f4c30e1">주변 패치들과 합치면 ‘버스’라는 의미가 생김 → 이게 re-tokenization 의 핵심</p> <p class="" id="2a4451cf-7b79-80b5-a61e-ff81f3e9f0a5"> </p> <p class="" id="2a4451cf-7b79-8068-a552-c8413cf5b0c0"> </p> <h3 class="" id="2a4451cf-7b79-804a-b521-f931d74a84e4">Compatibility with Other Methods</h3> <li style="list-style-type:disc">재토큰화가 토큰 생성 단계에서 이뤄지므로, 그 뒤의 pruning 또는 merging 모듈과 충돌하지 않음</li> <li style="list-style-type:disc">기존 Token Pruning (EViT, DynamicViT) 이나 Merging (ToMe) 방식과 결합 가능</li> <li style="list-style-type:disc">오히려 re-tokenization 덕분에 초기 layer에서 의미 없는 패치가 빨리 정리되어 전체 효율이 더 좋아짐</li> <p class="" id="2a4451cf-7b79-8037-9ef5-cf44f1f04e58"> </p> <p class="" id="2a4451cf-7b79-8062-858a-e1f2d9857bb2"> </p> <hr id="2a4451cf-7b79-8093-919a-fac1e04cfb15"> <p class="" id="2a4451cf-7b79-8047-bdf8-f4f15e47d939"> </p> <h1 class="" id="2a4451cf-7b79-803e-bed5-fa79f794e8ce">Experiment</h1> <h3 class="" id="2a6451cf-7b79-80a5-b59f-c8d35b9eb247">실험 개요</h3> <li style="list-style-type:disc">데이터셋: ImageNet-1k (1.2M train, 50k test)</li> <li style="list-style-type:disc">기반 모델: DeiT-Ti, DeiT-S (두 가지 Vision Transformer 버전)</li> <li style="list-style-type:disc">입력 크기: 224×224</li> <li style="list-style-type:disc">훈련: 300 epoch / finetuning, pretraining 없음. (DeiT 논문과 동일한 설정으로 )</li> <li style="list-style-type:disc">NVIDIA RTX 3090</li> <p class="" id="2a6451cf-7b79-80cb-a770-d8444b72328e"> </p> <h3 class="" id="2a6451cf-7b79-8098-ba3a-d2d2074e4c09">Table 1 - Token Pruning 비교 결과</h3> <figure class="image" id="2a6451cf-7b79-8038-a97a-e77a5f25a223" style="text-align:left"><picture><img class="img-fluid rounded z-depth-1" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" src="/files/2025-11-10-imagepiece/image%202.webp" style="width:576px"></picture></figure> <p class="" id="2a7451cf-7b79-80d8-b7a4-f2e86081884d">같은 keep ratio (0.7)기준으로 측정</p> <li style="list-style-type:disc">DynamicViT / EViT 은 토큰 제거 결정을  <strong>후반 layer에서</strong> 함 → 앞쪽 layer는 여전히 많은 토큰을 처리</li> <li style="list-style-type:disc">ImagePiece는 초기에 re-tokenization을 수행 →  <strong>앞 layer부터 토큰 수가 크게 줄어듦.</strong> </li> <p class="" id="2a6451cf-7b79-80b5-9192-f115f08ef88f"> </p> <h3 class="" id="2a6451cf-7b79-80f2-88c4-feddb7862fd0">Table 2 - Token Merging 비교 결과</h3> <figure class="image" id="2a6451cf-7b79-801d-b9be-c4e30b0d9939" style="text-align:left"><picture><img class="img-fluid rounded z-depth-1" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" src="/files/2025-11-10-imagepiece/image%203.webp" style="width:528px"></picture></figure> <p class="" id="2a6451cf-7b79-80d4-a1fd-c6cb04cd1856">ImagePiece는 의미 없는 토큰만 병합하기 때문에 의미 있는 정보(semantic tokens)는 그대로 유지</p> <p class="" id="2a6451cf-7b79-8049-b5d9-c401ace0c84f">→ 정확도 손실 거의 없음</p> <p class="" id="2a6451cf-7b79-8060-ba37-e8ceeea51248"> </p> <h3 class="" id="2a6451cf-7b79-8089-b862-d7c1a6cd15c9">Figure 3 - Hyper-speed Inference Experiment</h3> <p class="" id="2a6451cf-7b79-8088-94ed-cb7971fb9e9d">이 실험은 “토큰 수를 극단적으로 줄여도 성능이 유지되는가?” 를 보는 테스트</p> <p class="" id="2a6451cf-7b79-803f-bb3f-f9952b52b6d5">각 모델의 keep rate (남기는 토큰 비율)을 70%, 60%, 50%, ... 로 점점 줄여가면서 측정</p> <p class="" id="2a6451cf-7b79-8070-99b1-d8cf58ddb525">→ 극단적으로 빠른 추론 속도일때도 정확도 많이 보존</p> <figure class="image" id="2a6451cf-7b79-80e7-887b-c9a264a5516f" style="text-align:left"><picture><img class="img-fluid rounded z-depth-1" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" src="/files/2025-11-10-imagepiece/image%204.webp" style="width:336px"></picture></figure> <p class="" id="2a6451cf-7b79-8010-8528-ca6575458f5c"> <strong>같은 Acc 기준으로 비교</strong></p> <figure class="image" id="2a6451cf-7b79-800c-b94a-fd32a5d5af04" style="text-align:left"><picture><img class="img-fluid rounded z-depth-1" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" src="/files/2025-11-10-imagepiece/image%205.webp" style="width:528px"></picture></figure> <li style="list-style-type:disc">ImagePiece는 전체 토큰의 13%만 남기고도 정확도를 유지</li> <li style="list-style-type:disc">동일한 성능 기준에서 30% 이상 빠른 추론 속도를 달성</li> <li style="list-style-type:disc">“의미 없는 토큰을 더 정확히 식별해 버리기 때문”</li> <p class="" id="2a6451cf-7b79-8029-95d8-c56c78852618"> </p> <h3 class="" id="2a6451cf-7b79-8070-a562-ee9203627e7d">Table 4 - Random Masking Noise Robustness</h3> <figure class="image" id="2a6451cf-7b79-802b-8821-db791aeb46b7" style="text-align:left"><picture><img class="img-fluid rounded z-depth-1" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" src="/files/2025-11-10-imagepiece/image%206.webp" style="width:528px"></picture></figure> <p class="" id="2a6451cf-7b79-8072-8301-ddf11adfbda1">노이즈나 가려진 영역에 대한 견고성(robustness) 검증</p> <li style="list-style-type:disc">테스트 이미지에 무작위 16×16 마스크 7~50개 추가</li> <li style="list-style-type:disc">“의미 단위로 묶인 토큰이 더 견고한 global representation”</li> <p class="" id="2a6451cf-7b79-8016-9e59-f3b1daf1fc5e"> </p> <h3 class="" id="2a6451cf-7b79-8088-b409-ea775c15125e">Table 5 - Token Attentiveness 변화</h3> <p class="" id="2a6451cf-7b79-8084-86a1-e27100f164f4">“의미 없는 토큰도 병합 후 의미가 생기면 다시 중요해진다”</p> <figure class="image" id="2a6451cf-7b79-80fc-836c-fc561a3c87e1" style="text-align:left"><picture><img class="img-fluid rounded z-depth-1" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" src="/files/2025-11-10-imagepiece/image%207.webp" style="width:528px"></picture></figure> <li style="list-style-type:disc">이전 layer에서 inattentive(비중요)로 판단되었던 토큰 중 다음 layer에서 attentive(중요)로 바뀐 비율</li> <li style="list-style-type:disc">re-tokenization 덕분에 의미 없는 토큰이 의미 단위로 병합되면서 semantic importance를 회복</li> <p class="" id="2a6451cf-7b79-80a8-b0ce-d88e479634cb"> </p> <h3 class="" id="2a6451cf-7b79-80b7-acfb-f10a493bc519">Table 6 &amp; 7 - Token Similarity</h3> <p class="" id="2a6451cf-7b79-8045-80d1-e97959505c6f"> </p> <p class="" id="2a7451cf-7b79-8099-a0c5-c4631aa99204"> <strong>병합된 토큰 쌍(token pairs)</strong> 들의  <strong>feature cosine similarity</strong></p> <figure class="image" id="2a6451cf-7b79-80a4-8a7e-ebd55485248f" style="text-align:left"><picture><img class="img-fluid rounded z-depth-1" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" src="/files/2025-11-10-imagepiece/image%208.webp" style="width:480px"></picture></figure> <p class="" id="2a6451cf-7b79-805c-92ed-fead8343df16">ToMe: layer가 깊어질수록 유사도가 떨어져 정보 희석 발생,</p> <p class="" id="2a6451cf-7b79-806d-ae0d-ef47a2ce42f6">ImagePiece: 정보 일관성 보존</p> <p class="" id="2a6451cf-7b79-80ef-99a2-ed98975d6a30"> </p> <p class="" id="2a6451cf-7b79-80dc-bd2c-f35cdc0c6ba6"> <strong>첫번째 layer에서 병합된 토큰 중 “중요 토큰” 비율</strong></p> <figure class="image" id="2a6451cf-7b79-8044-b0e4-f09d7b227227" style="text-align:left"><picture><img class="img-fluid rounded z-depth-1" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" src="/files/2025-11-10-imagepiece/image%209.webp" style="width:480px"></picture></figure> <p class="" id="2a6451cf-7b79-8083-ac36-f16d19e8d5b8">→ 기존 merging 방식은 중요한 토큰을 너무 자주 병합함.</p> <p class="" id="2a6451cf-7b79-80c3-9b79-dc6d6f64151b">반면 ImagePiece는 bottom-k만 병합하므로 semantic dilution 방지.</p> <p class="" id="2a6451cf-7b79-802f-a79c-c643e5da8b77"> </p> <h3 class="" id="2a6451cf-7b79-8049-b10c-edc02b9fd99e">Table 8 - Local Coherence 효과</h3> <figure class="image" id="2a6451cf-7b79-80d9-a17b-d23c02803015" style="text-align:left"><picture><img class="img-fluid rounded z-depth-1" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" src="/files/2025-11-10-imagepiece/image%2010.webp" style="width:336px"></picture></figure> <p class="" id="2a6451cf-7b79-804a-96ab-db062177af85">→ 공간적으로 가까운 패치끼리 의미 단위로 묶인다</p> <table class="simple-table" id="2a6451cf-7b79-8093-b2b9-fec8ae0caaa2"> <thead class="simple-table-header"><tr id="2a6451cf-7b79-80ce-a6e0-c5247ce189ff"> <th class="simple-table-header-color simple-table-header" id="wom[" style="width:353.5px"></th> <th class="simple-table-header-color simple-table-header" id="PUNy" style="width:353.5px">Accuracy (%)</th> </tr></thead> <tbody> <tr id="2a6451cf-7b79-802c-abf6-d737e65588ee"> <td class="" id="wom[" style="width:353.5px">ImagePiece (no local bias)</td> <td class="" id="PUNy" style="width:353.5px">79.81</td> </tr> <tr id="2a6451cf-7b79-80e6-878c-c07d95d68e04"> <td class="" id="wom[" style="width:353.5px"> <strong>Full ImagePiece (with local coherence)</strong> </td> <td class="" id="PUNy" style="width:353.5px"> <strong>80.22</strong> </td> </tr> </tbody> </table> <p class="" id="2a6451cf-7b79-8008-ab93-efb6c48525d6">→ local coherence module 설계가 효과 있음.</p> <p class="" id="2a6451cf-7b79-80c0-a705-de22fcf646cb"> </p> <h3 class="" id="2a6451cf-7b79-801a-9a49-d4552e9d696c">Table 9 - Compatibility 실험</h3> <figure class="image" id="2a6451cf-7b79-80e8-979b-cd5c191259e1" style="text-align:left"><picture><img class="img-fluid rounded z-depth-1" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" src="/files/2025-11-10-imagepiece/image%2011.webp" style="width:528px"></picture></figure> <p class="" id="2a6451cf-7b79-80ed-8126-f911845e3313">기존 pruning·merging 구조에 ImagePiece를 단순 추가해도 정확도, 속도 향상</p> <p class="" id="2a6451cf-7b79-8047-9f20-c2c534a3cf70">→ 모듈형으로 삽입 가능한 확장성 높은 구조</p> <p class="" id="2a6451cf-7b79-8063-9031-ebf5228dc471"> </p> <hr id="2a2451cf-7b79-8011-9141-e9fff882e2f1"> <h1 class="" id="2a6451cf-7b79-8054-ad81-cd7195820239">Limitation &amp; Future Work</h1> <blockquote class="" id="2a6451cf-7b79-80ca-aae9-f7548b0d5922">논문에는 없지만 내가 생각해본 점들</blockquote> <h3 class="" id="2a6451cf-7b79-804a-b66e-f4668d662cfe"> <strong>Patch 크기와 구조에 민감</strong> </h3> <p class="" id="2a6451cf-7b79-80b0-bccb-c49c5e489d00">모델마다 최적의 Patch 크기가 다를 수 있는데, 패치 크기가 작거나 크다면 알고리즘이 잘 작동하지 않을 것 같다.</p> <p class="" id="2a6451cf-7b79-802a-930e-c078829c19b2">(논문에서는 16x16 사용)</p> <p class="" id="2a6451cf-7b79-8078-8fa5-f8a000780f76">→ 최근에 내가 제출한 논문에서도 이와같은 Limitation이 있었다.</p> <p class="" id="2a6451cf-7b79-8049-8f52-eb3eb1210b63"> <strong>future work</strong></p> <li style="list-style-type:disc">Feature map 해상도에 따라 병합 granularity를 자동 조절</li> <li style="list-style-type:disc">Local coherence module의 receptive field를 patch size에 맞게 조정</li> <p class="" id="2a6451cf-7b79-809a-a05e-da7ed0386399"> </p> <h3 class="" id="2a6451cf-7b79-80ac-b76f-ed6c7c50d7c1"> <strong>Semantic 기준이 attention 기반</strong> </h3> <p class="" id="2a6451cf-7b79-8069-860f-e57c51397a68">의미 정의가 attention score에만 의존</p> <p class="" id="2a6451cf-7b79-80dc-9e66-dbd61a1687bb">→ 복잡한 장면(다중 객체 이미지)에서는 토큰 병합이 부정확할 가능성 존재.</p> <p class="" id="2a6451cf-7b79-8098-8f49-cb9d2b0ab5d0"> <strong>future work</strong></p> <li style="list-style-type:disc">attention 외에도 spatial, contrastive, objectness 정보를 결합하여 토큰 의미 평가</li> <p class="" id="2a6451cf-7b79-8042-904f-d4208f56d53b"> </p> <p><span class="sans" style="font-size:14px;padding-top:2em"></span></p> </div> </article> <br><br><br><br> <div id="giscus_thread" style="max-width: 930px; margin: 0 auto;"> <script>
      let giscusTheme = determineComputedTheme();
      let giscusAttributes = {
        src: 'https://giscus.app/client.js',
        'data-repo': 'hoonably/hoonably.github.io',
        'data-repo-id': 'R_kgDOPBaE1Q',
        'data-category': 'Comments',
        'data-category-id': 'DIC_kwDOPBaE1c4Cr9sR',
        'data-mapping': 'title',
        'data-strict': '1',
        'data-reactions-enabled': '0',
        'data-emit-metadata': '0',
        'data-input-position': 'bottom',
        'data-theme': giscusTheme,
        'data-lang': 'ko',
        crossorigin: 'anonymous',
        async: '',
      };

      let giscusScript = document.createElement('script');
      Object.entries(giscusAttributes).forEach(([key, value]) => giscusScript.setAttribute(key, value));
      document.getElementById('giscus_thread').appendChild(giscusScript);
    </script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> <br><br><br><br> </div> </div> </div> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Jeonghoon Park. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script defer src="/assets/js/bootstrap-toc.min.js?c82ff4de8b0955d6ff14f5b05eed7eb6"></script> <script defer src="https://cdn.jsdelivr.net/npm/bootstrap-table@1.22.4/dist/bootstrap-table.min.js" integrity="sha256-4rppopQE9POKfukn2kEvhJ9Um25Cf6+IDVkARD0xh78=" crossorigin="anonymous"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>