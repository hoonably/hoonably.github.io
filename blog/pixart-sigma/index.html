<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> PixArt-Σ: Weak-to-Strong Training of Diffusion Transformer for 4K Text-to-Image Generation | hoonably </title> <meta name="author" content="Jeonghoon Park"> <meta name="description" content="Undergraduate student at UNIST (CSE), interested in AI, optimization, and systems programming. "> <meta name="keywords" content="UNIST, computer science, undergraduate, on-device AI, optimization, problem solving"> <meta http-equiv="Cache-Control" content="no-cache, no-store, must-revalidate"> <meta http-equiv="Pragma" content="no-cache"> <meta http-equiv="Expires" content="0"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-table@1.22.4/dist/bootstrap-table.min.css" integrity="sha256-uRX+PiRTR4ysKFRCykT8HLuRCub26LgXJZym3Yeom1c=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link defer href="/assets/css/bootstrap-toc.min.css?6f5af0bb9aab25d79b2448143cbeaa88" rel="stylesheet"> <link rel="shortcut icon" href="/assets/img/profile/profile.png?0380cd9558d19021da01ad0528213480"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://hoonably.github.io/blog/pixart-sigma/"> <script src="/assets/js/theme.js?46ad9a2b0ec61e45573c6ef53ae85f1f"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-dark.css?7f7b80282ea53f5dd6b976ff3d9857f9" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> hoonably </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="row"> <div class="col-sm-3"> <nav id="toc-sidebar" class="sticky-top"></nav> </div> <div class="col-sm-9"> <div class="pagein"> <div class="post"> <header class="post-header"> <h1 class="post-title">PixArt-Σ: Weak-to-Strong Training of Diffusion Transformer for 4K Text-to-Image Generation</h1> <p class="post-meta"> Created on February 09, 2025 </p> <p class="post-tags"> <a href="/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/tag/ai"> <i class="fa-solid fa-hashtag fa-sm"></i> AI</a>   ·   <a href="/blog/category/paper"> <i class="fa-solid fa-tag fa-sm"></i> Paper</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p>Authors: Junsong Chen, Chongjian Ge, Enze Xie, Yue Wu, Lewei Yao, Xiaozhe Ren, Zhongdao Wang, Ping Luo, Huchuan Lu, Zhenguo Li Venue &amp; Year: 24, ArXiv 날짜: 2025년 2월 9일</p> <table> <thead> <tr> <th>ArXiv</th> <th>https://arxiv.org/abs/2403.04692</th> </tr> </thead> <tbody> <tr> <td>Project Page</td> <td>https://pixart-alpha.github.io/PixArt-sigma-project/</td> </tr> <tr> <td>Github Code</td> <td>https://github.com/PixArt-alpha/PixArt-sigma</td> </tr> </tbody> </table> <p><a href="/files/2025-02-09-pixart-sigma/250213_JeonghoonPark_PixArt-__Weak-to-Strong_Training.pptx">250213<em>JeonghoonPark_PixArt-Σ</em> Weak-to-Strong_Training.pptx</a></p> <p><a href="/files/2025-02-09-pixart-sigma/250213_JeonghoonPark_PixArt-__Weak-to-Strong_Training.pdf">250213<em>JeonghoonPark_PixArt-Σ</em> Weak-to-Strong_Training.pdf</a></p> <p><a href="https://www.notion.so/PixArt-Fast-Training-of-Diffusion-Transformer-for-Photorealistic-Text-to-Image-Synthesis-198451cf7b798018891cfb85e1cd3523?pvs=21" rel="external nofollow noopener" target="_blank"><strong>PixArt-α: Fast Training of Diffusion Transformer for Photorealistic Text-to-Image Synthesis</strong></a></p> <blockquote class="block-warning"> <p>💡</p> <p><strong>Key Differentiator</strong></p> <ul> <li>기존 연구였던 PixArt-α에서 최적화를 통해 4K 초고해상도까지 가능하도록 연구</li> <li>4K를 transformer를 활용해 directly로 한번에 생성</li> </ul> </blockquote> <h1 id="2-related-work">2. Related Work</h1> <h3 id="1️⃣-pixart-α-iclr-2024-spotlight"><strong>1️⃣ PixArt-α (ICLR 2024 Spotlight)</strong></h3> <ul> <li><strong>최초의 Transformer 기반 Diffusion Model (DiT)로 1024×1024 해상도까지 생성 가능</strong></li> </ul> <h3 id="2️⃣-stable-diffusion-xl-sdxl-2023"><strong>2️⃣ Stable Diffusion XL (SDXL, 2023)</strong></h3> <ul> <li><strong>Latent Diffusion Model (LDM) 구조를 활용하여 1024×1024 이상의 고해상도 이미지 생성 가능</strong></li> </ul> <h3 id="3️⃣-gigagan-adobe-2023"><strong>3️⃣ GigaGAN (Adobe, 2023)</strong></h3> <ul> <li><strong>GAN 기반 초고해상도 이미지 생성 모델 (1024px 이상 지원)</strong></li> </ul> <h3 id="4️⃣-llava-visual-instruction-tuning-2023"><strong>4️⃣ LLaVA (Visual Instruction Tuning, 2023)</strong></h3> <ul> <li><strong>이미지-텍스트 정렬을 학습하여 이미지에 대한 설명(캡션)을 자동으로 생성하는 모델</strong></li> </ul> <h3 id="5️⃣-dalle-3-openai-2023"><strong>5️⃣ DALL·E 3 (OpenAI, 2023)</strong></h3> <ul> <li><strong>GPT-4 기반 텍스트 이해력을 활용하여 프롬프트를 더 정밀하게 반영</strong></li> </ul> <h1 id="3-framework">3. Framework</h1> <h2 id="31-data-analysis">3.1 Data Analysis</h2> <table> <thead> <tr> <th> </th> <th><strong>Data</strong></th> <th> </th> </tr> </thead> <tbody> <tr> <td>Internal-α</td> <td>14M</td> <td> </td> </tr> <tr> <td><strong>Internal-Σ</strong></td> <td><strong>33M</strong></td> <td>&gt;=1K (33M)<br>real photo 4K (8M)</td> </tr> <tr> <td>SD v1.5<br>(open-source)</td> <td>2B</td> <td> </td> </tr> </tbody> </table> <p>a 때보다 데이터가 많이 늘었고, 4K real photo도 추가함.</p> <p>하지만 SD v1.5가 2B 데이터인걸 감안하면 아주 제한적인 데이터.</p> <p>하지만 효과적으로 training함.</p> <p>이미지의 예술적 품질을 평가하는 Aesthetic Scoring Model(AES)을 사용하여 <strong>2M(200만 장)의 고품질 이미지 선별</strong>.</p> <p>→ 해상도가 높아질수록 모델의 충실도(프레셰 초점 거리(FID) [18])와 의미적 정렬(CLIP 점수)이 향상</p> <h3 id="better-text-image-alignment">Better Text-Image Alignment</h3> <p>➡ <strong>텍스트 프롬프트(설명)와 생성된 이미지가 얼마나 일치하는지</strong></p> <p><strong>즉, 사용자가 입력한 텍스트(prompt)와 모델이 생성한 이미지가 얼마나 정확하게 대응하는지를 평가하는 개념</strong></p> <hr> <p>PixArt-α 는 LLaVa를 사용하였고, PixArt-Σ는 Share-Captioner 사용</p> <table> <thead> <tr> <th>항목</th> <th>LLaVA</th> <th>Share-Captioner</th> </tr> </thead> <tbody> <tr> <td><strong>기반 모델</strong></td> <td>CLIP + LLaMA</td> <td>GPT-4V (GPT-4 with Vision)</td> </tr> <tr> <td><strong>텍스트 생성</strong></td> <td>비교적 단순</td> <td>더 길고 세밀한 설명</td> </tr> <tr> <td><strong>정확도</strong></td> <td>가끔 환각 문제 발생</td> <td>더 높은 정확도</td> </tr> <tr> <td><strong>이미지 디테일 반영</strong></td> <td>제한적 (단순 설명)</td> <td>더 정밀한 객체 및 관계 설명</td> </tr> <tr> <td><strong>캡션 품질</strong></td> <td>일반적인 설명 수준</td> <td>고품질, 구체적인 묘사 가능</td> </tr> </tbody> </table> <p>다음과 같은 환각 (Hallucinations)가 발생했었음</p> <figure> <picture> <img src="/files/2025-02-09-pixart-sigma/image.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <table> <thead> <tr> <th><strong>항목</strong></th> <th><strong>PixArt-α</strong></th> <th><strong>PixArt-Σ</strong></th> </tr> </thead> <tbody> <tr> <td><strong>텍스트 해석 길이</strong></td> <td>120 토큰</td> <td><strong>300 토큰 (2.5배 증가)</strong></td> </tr> <tr> <td><strong>캡션 생성 모델</strong></td> <td>LLaVA (단순함)</td> <td><strong>Share-Captioner (정확한 설명)</strong></td> </tr> <tr> <td><strong>CLIP Score</strong></td> <td>0.2787</td> <td><strong>0.2797 (향상됨)</strong></td> </tr> <tr> <td><strong>환각 문제 해결</strong></td> <td>일부 존재</td> <td><strong>환각 감소 (더 정밀한 캡션 사용)</strong></td> </tr> </tbody> </table> <p>➡ <strong>PixArt-Σ는 더 긴 문장을 해석하고, 더 정교한 캡션을 사용하여 텍스트-이미지 정렬 성능을 높였음</strong>.</p> <p>➡ <strong>Share-Captioner를 사용하여 텍스트와 이미지 간 정보 일치도를 개선</strong>함.</p> <h3 id="평가-데이터셋-구성-high-quality-evaluation-dataset">평가 데이터셋 구성 (High-Quality Evaluation Dataset)</h3> <ul> <li>기존 모델들이 사용하는 <strong>MSCOCO 데이터셋은 예술적 품질과 텍스트-이미지 정렬을 평가하기에 충분하지 않음</strong>.</li> <li>따라서 PixArt-Σ는 <strong>새로운 평가 데이터셋(30,000개 샘플) 구축</strong>.</li> <li>평가 항목: <ol> <li> <strong>Fréchet Inception Distance (FID)</strong> → 이미지 품질 평가</li> <li> <strong>CLIP Score</strong> → 텍스트-이미지 정렬 성능 평가</li> </ol> </li> </ul> <figure> <picture> <img src="/files/2025-02-09-pixart-sigma/image%201.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <h2 id="32-efficient-dit-design">3.2 Efficient DiT Design</h2> <h3 id="key-value-kv-token-compression-기법"><strong>Key-Value (KV) Token Compression 기법</strong></h3> <p><strong>🔹 기존 Attention 연산 문제</strong></p> <ul> <li>Self-Attention은 <strong>Query(Q), Key(K), Value(V)의 곱을 계산</strong>하는 방식이므로,토큰 개수가 많아질수록 <strong>연산량이 O(N²)으로 증가</strong>함.</li> <li> <strong>해결 방법</strong>: Key와 Value 토큰을 압축하여 연산량을 줄임.</li> </ul> <p><strong>🔹 PixArt-Σ의 KV Token Compression 방식</strong></p> <figure> <picture> <img src="/files/2025-02-09-pixart-sigma/image%202.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <ul> <li> <strong>PixArt-Σ (토큰 압축 적용)</strong>: <ul> <li>Key(K)와 Value(V)를 <strong>Stride 2의 Group Convolution</strong>을 사용해 압축</li> <li>이를 통해 토큰 개수를 <strong>N → N/R^2 으로 줄임</strong> </li> <li>정확도가 크게 떨어지지 않는 선에서 R을 조정 (1~4)하기</li> <li>최종적으로 <strong>연산량을 기존 대비 약 34% 절감</strong> </li> </ul> </li> </ul> <p><strong>핵심 효과</strong></p> <ul> <li> <strong>4K 해상도 이미지 생성 속도 향상</strong> (연산량 감소)</li> <li><strong>메모리 사용량 감소 → 더 작은 GPU에서도 실행 가능</strong></li> <li> <strong>기존 PixArt-α 모델에서 자연스럽게 업그레이드 가능</strong> (기존 모델의 가중치를 활용)</li> </ul> <figure> <picture> <img src="/files/2025-02-09-pixart-sigma/image%203.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <figure> <picture> <img src="/files/2025-02-09-pixart-sigma/image%204.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <h2 id="33-weak-to-strong-training-strategy">3.3 Weak-to-Strong Training Strategy</h2> <p>PixArt-Σ의 Weak-to-Strong Training은 <strong>기존 모델의 가중치를 활용하여 빠르게 적응하도록 설계됨</strong>.</p> <p>이 과정에서 <strong>3단계의 학습 전략</strong>이 적용됨.</p> <h3 id="1-vae-적응-vae-adaptation"><strong>(1) VAE 적응 (VAE Adaptation)</strong></h3> <ul> <li>PixArt-α에서 사용하던 기존 VAE를 <strong>Stable Diffusion XL(SDXL)의 VAE로 교체</strong> </li> <li> <strong>VAE 교체 후 빠른 적응을 위해 2K Training Steps 만에 수렴하도록 학습 전략 적용</strong>.</li> <li>새로운 VAE 적용 후에도 <strong>기존 모델의 가중치를 재사용하여 빠르게 학습 가능</strong>.</li> </ul> <figure> <picture> <img src="/files/2025-02-09-pixart-sigma/image%205.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <h3 id="2-해상도-업그레이드-resolution-upscaling"><strong>(2) 해상도 업그레이드 (Resolution Upscaling)</strong></h3> <ul> <li> <p>256px → 512px → 1024px → 4K로 점진적으로 해상도를 증가시키며 학습.</p> </li> <li> <strong>PE Interpolation</strong>(위치 임베딩 보간법)을 적용하여, 기존 해상도의 가중치를 새 해상도에서도 자연스럽게 사용 가능하도록 조정. <ul> <li>보간법 (Interpolation)은 <strong>알려진 값을 기반으로 값을 계산하는 프로세스</strong> </li> <li>Transformer 기반 모델(예: DiT, ViT 등)은 <strong>입력 이미지의 각 위치 정보를 표현하기 위해 위치 임베딩을 사용</strong>.</li> <li>모델이 256×256에서 학습되었다면, <strong>256×256 해상도에 최적화된 위치 임베딩을 학습함</strong>.</li> <li>하지만 해상도를 1024×1024로 증가시키면, <strong>기존 256×256 위치 임베딩과 구조가 달라져 모델 성능이 급격히 저하됨</strong>.</li> <li>기존 위치 임베딩을 1024×1024 크기로 보간(interpolation)</li> <li>즉, 256개의 값을 1024개로 확장하는 과정에서 자연스럽게 매끄러운 값으로 변환됨.</li> <li>이를 통해 새로운 해상도에서도 기존 모델의 공간 정보가 유지됨.</li> </ul> </li> <li> <strong>단 1000 Training Steps만으로도 해상도 증가에 적응 가능</strong>.</li> </ul> <figure> <picture> <img src="/files/2025-02-09-pixart-sigma/image%206.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <h3 id="3-kv-token-compression-도입-연산-최적화"><strong>(3) KV Token Compression 도입 (연산 최적화)</strong></h3> <ul> <li>PixArt-Σ 모델은 KV Token Compression을 적용했음</li> <li>하지만 <strong>기존 모델과 구조가 달라서 성능 저하 위험이 있음</strong>.</li> <li>PixArt-Σ에서는 <strong>기존 모델에서 자연스럽게 적응하도록 “Conv Avg Init.” 전략 적용</strong>.</li> </ul> <h3 id="평균-연산averaging-기반-초기화"><strong>평균 연산(Averaging) 기반 초기화</strong></h3> <ul> <li> <strong>Conv Avg Init은 가중치 값을 <code class="language-plaintext highlighter-rouge">1/R²</code>로 설정하여, 기존 정보를 최대한 유지하면서 부드럽게 전환함</strong>.</li> <li> <p><strong>즉, 단순히 압축하는 것이 아니라 기존 공간 정보를 최대한 보존하는 방식</strong>.</p> </li> <li>초기에는 압축 없이 학습 후, <strong>학습이 안정화되면 KV Compression을 적용하여 연산량 감소</strong>.</li> <li> <strong>4K 이미지 생성 시 연산량 34% 절감</strong>.</li> </ul> <p><strong>결과적으로, 기존 PixArt-α 대비 적은 연산량과 빠른 학습으로 4K 이미지 생성이 가능해짐.</strong></p> <figure> <picture> <img src="/files/2025-02-09-pixart-sigma/image%207.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <h1 id="4-experiment">4. Experiment</h1> <h2 id="41-implementation-details-구현-세부사항">4.1 Implementation Details (구현 세부사항)</h2> <h3 id="1-모델-구성"><strong>1. 모델 구성</strong></h3> <p><strong>텍스트 인코더</strong></p> <ul> <li> <strong>Flan-T5-XXL 사용</strong> (Imagen 및 PixArt-α와 동일)</li> <li>기존 모델에서 <strong>120개 토큰</strong>을 사용하던 것을 <strong>300개 토큰까지 확장</strong>하여 더 정밀한 텍스트-이미지 정렬 가능.</li> </ul> <p><strong>VAE (Variational Autoencoder) 적용</strong></p> <ul> <li><strong>Stable Diffusion XL(SDXL)의 VAE 사용</strong></li> <li> <strong>더 높은 품질의 이미지 디코딩 가능</strong> → 세밀한 디테일 보존</li> </ul> <p><strong>기반 모델</strong></p> <ul> <li><strong>PixArt-α를 베이스 모델로 사용</strong></li> <li><strong>256px 사전 학습된 체크포인트를 활용하여 4K까지 확장</strong></li> </ul> <p><strong>KV Token Compression 적용</strong></p> <ul> <li><strong>연산량 34% 절감</strong></li> <li><strong>초고해상도(4K) 이미지 생성을 가능하게 함</strong></li> </ul> <hr> <h3 id="2-학습-환경-및-하드웨어"><strong>2. 학습 환경 및 하드웨어</strong></h3> <p><strong>훈련 GPU 환경</strong></p> <ul> <li><strong>1K 모델 학습: 32 V100 GPUs 사용</strong></li> <li><strong>2K &amp; 4K 모델 학습: 16 A100 GPUs 사용</strong></li> </ul> <p><strong>최적화 알고리즘</strong></p> <ul> <li> <strong>CAME Optimizer 사용</strong> (AdamW 대신)</li> <li><strong>학습률: 2e-5 (고정 Learning Rate 사용)</strong></li> <li><strong>Weight Decay: 0</strong></li> </ul> <p><strong>Position Embedding Interpolation (PE Interp.) 적용</strong></p> <ul> <li>낮은 해상도에서 학습된 모델을 고해상도로 변환할 때 <strong>위치 임베딩을 보간(interpolation)하여 적용</strong>.</li> <li>이를 통해 <strong>고해상도로 확장 시 성능 저하 없이 빠르게 적응 가능</strong>.</li> </ul> <hr> <h3 id="3-학습-데이터-및-훈련-과정"><strong>3. 학습 데이터 및 훈련 과정</strong></h3> <p><strong>훈련 데이터셋</strong></p> <ul> <li><strong>총 33M(3,300만 개)의 고해상도 이미지 사용</strong></li> <li><strong>1K 해상도 이상의 데이터만 포함</strong></li> <li><strong>4K 해상도 이미지 2.3M(230만 개) 포함</strong></li> <li><strong>Aesthetic Scoring Model(AES) 적용하여 고품질 이미지 선별</strong></li> </ul> <p><strong>훈련 과정</strong></p> <ul> <li><strong>256px → 512px → 1024px → 4K 해상도로 점진적 업스케일링 적용</strong></li> <li><strong>VAE 교체 후 2K Training Steps 내 빠르게 적응</strong></li> <li><strong>PE Interpolation을 적용하여 고해상도에서 추가 학습 비용 절감</strong></li> </ul> <p><strong>학습 비용 절감</strong></p> <ul> <li>기존 PixArt-α 대비 <strong>훈련 비용 9%만 사용하여 1K 생성 가능</strong> </li> <li><strong>KV Compression과 Weak-to-Strong Training을 결합하여 GPU 비용 절감</strong></li> </ul> <h2 id="42-실험-결과">4.2 실험 결과</h2> <h2 id="1-이미지-품질-비교-qualitative-evaluation"><strong>1. 이미지 품질 비교 (Qualitative Evaluation)</strong></h2> <p>PixArt-Σ는 <strong>포토리얼리즘(Photorealism), 디테일 수준, 스타일 다양성 측면에서 이전 모델보다 개선됨</strong>.</p> <p>아래와 같은 모델들과 비교됨:</p> <figure> <picture> <img src="/files/2025-02-09-pixart-sigma/image%208.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <h2 id="pixart-α-vs-pixart-σ">PixArt-α vs PixArt-Σ</h2> <table> <thead> <tr> <th>항목</th> <th>PixArt-α (기존)</th> <th>PixArt-Σ (개선)</th> </tr> </thead> <tbody> <tr> <td><strong>최대 해상도</strong></td> <td>1K (1024×1024)</td> <td><strong>4K (3840×2160) 지원</strong></td> </tr> <tr> <td><strong>연산량 최적화</strong></td> <td>없음</td> <td><strong>KV Token Compression 적용 (연산량 34% 감소)</strong></td> </tr> <tr> <td><strong>VAE 모델</strong></td> <td>기본 VAE</td> <td><strong>SDXL VAE로 변경 (고품질 이미지 생성 가능)</strong></td> </tr> <tr> <td><strong>학습 전략</strong></td> <td>일반 학습</td> <td><strong>Weak-to-Strong Training (기존 모델 활용하여 빠르게 학습)</strong></td> </tr> <tr> <td><strong>텍스트 길이</strong></td> <td>120 토큰</td> <td><strong>300 토큰으로 확장 (더 정밀한 텍스트-이미지 정렬 가능)</strong></td> </tr> <tr> <td><strong>훈련 비용</strong></td> <td>높음</td> <td><strong>기존 대비 GPU 비용 9%로 절감</strong></td> </tr> </tbody> </table> <h3 id="pixart-σ-vs-mobilediffusion-비교표"><strong>PixArt-Σ vs. MobileDiffusion 비교표</strong></h3> <table> <thead> <tr> <th>항목</th> <th><strong>PixArt-Σ</strong></th> <th><strong>MobileDiffusion</strong></th> <th>비교</th> </tr> </thead> <tbody> <tr> <td><strong>목표</strong></td> <td><strong>4K 초고해상도 이미지 생성</strong></td> <td><strong>모바일에서 실시간 생성 가능하도록 최적화</strong></td> <td>PixArt-Σ는 초고해상도 생성, MobileDiffusion은 On-Device 최적화</td> </tr> <tr> <td><strong>모델 구조</strong></td> <td> <strong>Diffusion Transformer (DiT)</strong> 기반</td> <td><strong>Latent Diffusion + Optimized UNet</strong></td> <td>PixArt-Σ는 Transformer 기반, MobileDiffusion은 UNet 기반</td> </tr> <tr> <td><strong>텍스트 인코더</strong></td> <td><strong>Flan-T5-XXL (300 토큰까지 가능)</strong></td> <td><strong>CLIP-ViT/L14 (텍스트-이미지 효율성 극대화)</strong></td> <td>PixArt-Σ가 더 긴 텍스트 입력 가능, MobileDiffusion은 가벼움</td> </tr> <tr> <td><strong>이미지 해상도</strong></td> <td><strong>4K (3840×2160) 직접 생성 가능</strong></td> <td><strong>512×512 (On-Device에서 빠르게 생성)</strong></td> <td>PixArt-Σ는 초고해상도, MobileDiffusion은 저해상도 최적화</td> </tr> <tr> <td><strong>KV Token Compression</strong></td> <td><strong>Self-Attention 연산량 34% 절감 (R=2, R=4 적용)</strong></td> <td>❌ 사용하지 않음</td> <td>PixArt-Σ는 4K 최적화, MobileDiffusion은 경량 모델이라 필요 없음</td> </tr> <tr> <td><strong>모델 크기</strong></td> <td><strong>0.6B 파라미터 (SDXL: 2.6B 대비 작음)</strong></td> <td><strong>386M (SD-1.5 대비 55% 축소)</strong></td> <td>MobileDiffusion이 더 작음</td> </tr> <tr> <td><strong>VAE (Autoencoder)</strong></td> <td><strong>SDXL VAE 사용 (고품질 이미지 복원 가능)</strong></td> <td><strong>경량화된 VAE 적용 (512px에서 최적화됨)</strong></td> <td>PixArt-Σ는 품질 우선, MobileDiffusion은 속도 우선</td> </tr> <tr> <td><strong>해상도 업스케일링 기법</strong></td> <td><strong>PE Interpolation (기존 모델을 고해상도로 자연스럽게 변환)</strong></td> <td><strong>512px 고정 (Upscaling 없음)</strong></td> <td>PixArt-Σ는 해상도 확장 가능, MobileDiffusion은 저해상도 고정</td> </tr> <tr> <td><strong>연산 최적화</strong></td> <td><strong>Weak-to-Strong Training (기존 모델 재사용으로 학습 비용 절감)</strong></td> <td><strong>Transformer 블록 제거 + Convolution 기반 최적화</strong></td> <td>PixArt-Σ는 기존 모델 활용, MobileDiffusion은 경량화 모델</td> </tr> <tr> <td><strong>On-Device 실행 가능 여부</strong></td> <td>❌ 불가능 (고성능 GPU 필요)</td> <td>가능 (iPhone 15 Pro에서 0.2초 생성)</td> <td>MobileDiffusion이 훨씬 가벼움</td> </tr> <tr> <td><strong>학습 데이터 크기</strong></td> <td><strong>33M (4K 데이터 포함, SD v1.5의 1.65%)</strong></td> <td><strong>150M (모바일 최적화된 데이터)</strong></td> <td>MobileDiffusion이 더 큰 데이터셋 사용</td> </tr> <tr> <td><strong>이미지 품질 평가 (FID Score)</strong></td> <td><strong>8.23 (PixArt-α 대비 개선됨)</strong></td> <td><strong>11.67 (1-step) / 8.65 (50-step DDIM)</strong></td> <td>PixArt-Σ가 품질 우수, MobileDiffusion은 속도 최적화</td> </tr> <tr> <td><strong>텍스트-이미지 정렬 (CLIP Score)</strong></td> <td><strong>0.2797 (PixArt-α 대비 향상됨)</strong></td> <td><strong>0.320 (1-step) / 0.325 (50-step DDIM)</strong></td> <td>MobileDiffusion이 더 나은 정렬 성능</td> </tr> <tr> <td><strong>생성 속도</strong></td> <td>❌ 느림 (4K 생성에 고사양 GPU 필요)</td> <td>0.2초 (iPhone 15 Pro에서 실시간 생성)</td> <td>MobileDiffusion이 훨씬 빠름</td> </tr> </tbody> </table> </div> </article> <br><br><br><br> <div id="giscus_thread" style="max-width: 930px; margin: 0 auto;"> <script>
      let giscusTheme = determineComputedTheme();
      let giscusAttributes = {
        src: 'https://giscus.app/client.js',
        'data-repo': 'hoonably/hoonably.github.io',
        'data-repo-id': 'R_kgDOPFCdOg',
        'data-category': 'Comments',
        'data-category-id': 'DIC_kwDOPFCdOs4CsU3N',
        'data-mapping': 'title',
        'data-strict': '1',
        'data-reactions-enabled': '0',
        'data-emit-metadata': '0',
        'data-input-position': 'bottom',
        'data-theme': giscusTheme,
        'data-lang': 'ko',
        crossorigin: 'anonymous',
        async: '',
      };

      let giscusScript = document.createElement('script');
      Object.entries(giscusAttributes).forEach(([key, value]) => giscusScript.setAttribute(key, value));
      document.getElementById('giscus_thread').appendChild(giscusScript);
    </script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> <br><br><br><br> </div> </div> </div> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Jeonghoon Park. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script defer src="/assets/js/bootstrap-toc.min.js?c82ff4de8b0955d6ff14f5b05eed7eb6"></script> <script defer src="https://cdn.jsdelivr.net/npm/bootstrap-table@1.22.4/dist/bootstrap-table.min.js" integrity="sha256-4rppopQE9POKfukn2kEvhJ9Um25Cf6+IDVkARD0xh78=" crossorigin="anonymous"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>