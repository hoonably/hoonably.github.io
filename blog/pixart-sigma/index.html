<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta name="google-site-verification" content="UF9aPIHL0gyy9XNMhsgSZizZ_Ni9ciW6GIzLr4ZYIZc"> <meta http-equiv="Permissions-Policy" content="interest-cohort=()"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> PixArt-Σ: Weak-to-Strong Training of Diffusion Transformer for 4K Text-to-Image Generation | hoonably </title> <meta name="author" content="Jeonghoon Park"> <meta name="description" content="Undergraduate student at UNIST (CSE), interested in AI, optimization, and systems programming. "> <meta name="keywords" content="UNIST, computer science, undergraduate, on-device AI, optimization, problem solving"> <meta http-equiv="Cache-Control" content="no-cache, no-store, must-revalidate"> <meta http-equiv="Pragma" content="no-cache"> <meta http-equiv="Expires" content="0"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-table@1.22.4/dist/bootstrap-table.min.css" integrity="sha256-uRX+PiRTR4ysKFRCykT8HLuRCub26LgXJZym3Yeom1c=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link defer href="/assets/css/bootstrap-toc.min.css?6f5af0bb9aab25d79b2448143cbeaa88" rel="stylesheet"> <link rel="shortcut icon" href="/assets/img/profile/profile.webp?b5bec9d555338d1029578e54703400f7"> <link rel="stylesheet" href="/assets/css/pretendard-subset.css"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://jeonghoonpark.com/blog/pixart-sigma/"> <script src="/assets/js/theme.js?c06f90403cefcf6ac822b3d318259fcc"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-dark.css?7f7b80282ea53f5dd6b976ff3d9857f9" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> hoonably </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="row"> <div class="col-sm-3"> <nav id="toc-sidebar" class="sticky-top"></nav> </div> <div class="col-sm-9"> <div class="pagein"> <div class="post"> <header class="post-header"> <h1 class="post-title">PixArt-Σ: Weak-to-Strong Training of Diffusion Transformer for 4K Text-to-Image Generation</h1> <p class="post-meta"> Created on February 08, 2025 </p> <p class="post-tags"> <a href="/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/tag/ai"> <i class="fa-solid fa-hashtag fa-sm"></i> AI</a>   ·   <a href="/blog/category/paper"> <i class="fa-solid fa-tag fa-sm"></i> Paper</a> </p> </header> <article class="post-content"> <div id="markdown-content" class="notion"> <table class="simple-table" id="198451cf-7b79-805f-bd44-e09e7b51e51b"><tbody> <tr id="198451cf-7b79-803e-8cf3-c2ed86d84ade"> <th class="simple-table-header-color simple-table-header" id="MApI" style="width:125.5px">ArXiv</th> <td class="" id="L|H:" style="width:580.5px"><a href="https://arxiv.org/abs/2403.04692" rel="external nofollow noopener" target="_blank">https://arxiv.org/abs/2403.04692</a></td> </tr> <tr id="198451cf-7b79-80eb-8b93-f3080c4fd2b0"> <th class="simple-table-header-color simple-table-header" id="MApI" style="width:125.5px">Project Page</th> <td class="" id="L|H:" style="width:580.5px"><a href="https://pixart-alpha.github.io/PixArt-sigma-project/" rel="external nofollow noopener" target="_blank">https://pixart-alpha.github.io/PixArt-sigma-project/</a></td> </tr> <tr id="198451cf-7b79-80aa-8b1c-fc11c387db38"> <th class="simple-table-header-color simple-table-header" id="MApI" style="width:125.5px">Github Code</th> <td class="" id="L|H:" style="width:580.5px"><a href="https://github.com/PixArt-alpha/PixArt-sigma" rel="external nofollow noopener" target="_blank">https://github.com/PixArt-alpha/PixArt-sigma</a></td> </tr> <tr id="241451cf-7b79-80fd-a1c0-e7b1b709d3d0"> <th class="simple-table-header-color simple-table-header" id="MApI" style="width:125.5px">Affiliation</th> <td class="" id="L|H:" style="width:580.5px"> Huawei Noah’s Ark Lab, Dalian University of Technology, HKU, HKUST</td> </tr> </tbody></table> <p class="" id="198451cf-7b79-80d2-b472-d6b4113fd4ef"> </p> <figure class="block-color-teal_background callout" id="198451cf-7b79-8031-9793-d00fb2183a11" style="white-space:pre-wrap;display:flex"><div style="font-size:1.5em"><span class="icon">💡</span></div> <div style="width:100%"> <strong>Key Differentiator</strong><li style="list-style-type:disc">기존 연구였던 PixArt-α에서 최적화를 통해 4K 초고해상도까지 가능하도록 연구</li> <li style="list-style-type:disc">4K를 transformer를 활용해 directly로 한번에 생성</li> </div></figure> <p class="" id="198451cf-7b79-80dd-a527-d58350acefed"> </p> <div style="position:relative; width:100%; aspect-ratio:1214/749;"> <iframe src="https://docs.google.com/presentation/d/e/2PACX-1vRFd2ZFGe1cINmVpTzQ6hn6SOMPVCFsLh4TSWCD5mMP_ffYFqn7xWZAgPsraIg4MA/pubembed?start=false&amp;loop=false&amp;delayms=3000" style="position:absolute; top:0; left:0; width:100%; height:100%;" frameborder="0" allowfullscreen="true" mozallowfullscreen="true" webkitallowfullscreen="true"> </iframe> </div> <h1 class="" id="198451cf-7b79-8054-9266-dd0fbbab0df3">2. Related Work</h1> <h3 class="" id="198451cf-7b79-80e7-8cdf-c20770f56386"> <strong>PixArt-α (ICLR 2024 Spotlight) </strong> </h3> <li style="list-style-type:disc"> <strong>최초의 Transformer 기반 Diffusion Model (DiT)로 1024×1024 해상도까지 생성 가능</strong> </li> <h3 class="" id="198451cf-7b79-803d-aa36-d7a69c28e183"> <strong>Stable Diffusion XL (SDXL, 2023)</strong> </h3> <li style="list-style-type:disc"> <strong>Latent Diffusion Model (LDM) 구조를 활용하여 1024×1024 이상의 고해상도 이미지 생성 가능</strong> </li> <h3 class="" id="198451cf-7b79-80ab-9702-cb59f71cd9e5"> <strong>GigaGAN (Adobe, 2023)</strong> </h3> <li style="list-style-type:disc"> <strong>GAN 기반 초고해상도 이미지 생성 모델 (1024px 이상 지원)</strong> </li> <h3 class="" id="198451cf-7b79-80a8-868a-db925c0f61f7"> <strong>LLaVA (Visual Instruction Tuning, 2023) </strong> </h3> <li style="list-style-type:disc"> <strong>이미지-텍스트 정렬을 학습하여 이미지에 대한 설명(캡션)을 자동으로 생성하는 모델</strong> </li> <h3 class="" id="198451cf-7b79-80f9-8912-c30f3ce54c23"> <strong>DALL·E 3 (OpenAI, 2023)</strong> </h3> <li style="list-style-type:disc"> <strong>GPT-4 기반 텍스트 이해력을 활용하여 프롬프트를 더 정밀하게 반영</strong> </li> <p class="" id="198451cf-7b79-8005-83d0-f4946cd8ffde"> </p> <p class="" id="198451cf-7b79-8009-b0be-d2add40b8edc"> </p> <h1 class="" id="198451cf-7b79-803f-91bc-fe73edcc8649">3. Framework</h1> <h2 class="" id="198451cf-7b79-802c-aba9-d4325efaeb2a">3.1 Data Analysis</h2> <table class="simple-table" id="198451cf-7b79-806a-b5fd-ccf03e0bc696"><tbody> <tr id="198451cf-7b79-8035-93a0-da8afe5819bc"> <td class="" id="FloJ" style="width:230px"></td> <td class="" id="RKqt" style="width:230px"> <strong>Data</strong> </td> <td class="" id="}{dw" style="width:230px"></td> </tr> <tr id="198451cf-7b79-803d-af4d-d1501fec2a76"> <td class="" id="FloJ" style="width:230px">Internal-α</td> <td class="" id="RKqt" style="width:230px">14M</td> <td class="" id="}{dw" style="width:230px"></td> </tr> <tr id="198451cf-7b79-80ee-af10-f8e54e7ee345"> <td class="" id="FloJ" style="width:230px"> <strong>Internal-Σ</strong> </td> <td class="" id="RKqt" style="width:230px"> <strong>33M</strong> </td> <td class="" id="}{dw" style="width:230px">&gt;=1K (33M)<br>real photo 4K (8M)<br> </td> </tr> <tr id="198451cf-7b79-80c3-8e22-d316a427fc0d"> <td class="" id="FloJ" style="width:230px">SD v1.5<br>(open-source)<br> </td> <td class="" id="RKqt" style="width:230px">2B</td> <td class="" id="}{dw" style="width:230px"></td> </tr> </tbody></table> <p class="" id="198451cf-7b79-8094-a271-f15fe615d403">a 때보다 데이터가 많이 늘었고, 4K real photo도 추가함.</p> <p class="" id="198451cf-7b79-804e-a0e8-ea8d09177909">하지만 SD v1.5가 2B 데이터인걸 감안하면 아주 제한적인 데이터.</p> <p class="" id="198451cf-7b79-8047-a9b8-d44900df2519">하지만 효과적으로 training함.</p> <p class="" id="198451cf-7b79-808f-bfc7-fc83e49af522">이미지의 예술적 품질을 평가하는 Aesthetic Scoring Model(AES)을 사용하여  <strong>2M(200만 장)의 고품질 이미지 선별</strong>.</p> <p class="" id="198451cf-7b79-8080-9945-d495868ec074"> → 해상도가 높아질수록 모델의 충실도(프레셰 초점 거리(FID) [18])와 의미적 정렬(CLIP 점수)이 향상</p> <p class="" id="198451cf-7b79-80dd-93c1-eaeba7f736e3"> </p> <h3 class="" id="198451cf-7b79-80c0-b8ba-d7a58115cbd8">Better Text-Image Alignment</h3> <p class="" id="198451cf-7b79-80ae-965a-ec87b601306a">➡  <strong>텍스트 프롬프트(설명)와 생성된 이미지가 얼마나 일치하는지</strong></p> <p class="" id="198451cf-7b79-80f7-9a72-eedfecb581fe"> <strong>즉, 사용자가 입력한 텍스트(prompt)와 모델이 생성한 이미지가 얼마나 정확하게 대응하는지를 평가하는 개념</strong></p> <hr id="198451cf-7b79-801c-a94a-e793a150eaf7"> <p class="" id="198451cf-7b79-800b-943b-f61d0b223d53"> </p> <p class="" id="198451cf-7b79-8096-84b6-d5cdcd2f5df3">PixArt-α 는 LLaVa를 사용하였고, PixArt-Σ는 Share-Captioner 사용</p> <table class="simple-table" id="198451cf-7b79-80d5-be53-ec995af83c2a"><tbody> <tr id="198451cf-7b79-8006-b421-c92e94756f9c"> <td class="" id="Nq=E">항목</td> <td class="" id="&gt;m?`">LLaVA</td> <td class="" id="URoO">Share-Captioner</td> </tr> <tr id="198451cf-7b79-80e9-bf0a-d06eba170da4"> <td class="" id="Nq=E"> <strong>기반 모델</strong> </td> <td class="" id="&gt;m?`">CLIP + LLaMA</td> <td class="" id="URoO">GPT-4V (GPT-4 with Vision)</td> </tr> <tr id="198451cf-7b79-804b-ba84-e90260dc87ed"> <td class="" id="Nq=E"> <strong>텍스트 생성</strong> </td> <td class="" id="&gt;m?`">비교적 단순</td> <td class="" id="URoO">더 길고 세밀한 설명</td> </tr> <tr id="198451cf-7b79-800d-be93-f670c3a83f1f"> <td class="" id="Nq=E"> <strong>정확도</strong> </td> <td class="" id="&gt;m?`">가끔 환각 문제 발생</td> <td class="" id="URoO">더 높은 정확도</td> </tr> <tr id="198451cf-7b79-80ea-b426-f684de0c5237"> <td class="" id="Nq=E"> <strong>이미지 디테일 반영</strong> </td> <td class="" id="&gt;m?`">제한적 (단순 설명)</td> <td class="" id="URoO">더 정밀한 객체 및 관계 설명</td> </tr> <tr id="198451cf-7b79-80c3-85ac-e5d3a5db0589"> <td class="" id="Nq=E"> <strong>캡션 품질</strong> </td> <td class="" id="&gt;m?`">일반적인 설명 수준</td> <td class="" id="URoO">고품질, 구체적인 묘사 가능</td> </tr> </tbody></table> <p class="" id="198451cf-7b79-8054-b0bf-d21d70addb5a">다음과 같은 환각 (Hallucinations)가 발생했었음</p> <figure class="image" id="198451cf-7b79-8065-861b-c4b5ec4453e4"><picture><img class="img-fluid rounded z-depth-1" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" src="/files/2025-02-09-pixart-sigma/image.webp" style="width:710px"></picture></figure> <table class="simple-table" id="198451cf-7b79-80f3-978e-cf487938785a"><tbody> <tr id="198451cf-7b79-8013-b727-c467469468e9"> <td class="" id="k:ap"> <strong>항목</strong> </td> <td class="" id="dz&gt;|"> <strong>PixArt-α</strong> </td> <td class="" id="OS[X"> <strong>PixArt-Σ</strong> </td> </tr> <tr id="198451cf-7b79-80e9-bc66-c227557f3ed0"> <td class="" id="k:ap"> <strong>텍스트 해석 길이</strong> </td> <td class="" id="dz&gt;|">120 토큰</td> <td class="" id="OS[X"> <strong>300 토큰 (2.5배 증가)</strong> </td> </tr> <tr id="198451cf-7b79-8041-9e0a-c4af31775aaa"> <td class="" id="k:ap"> <strong>캡션 생성 모델</strong> </td> <td class="" id="dz&gt;|">LLaVA (단순함)</td> <td class="" id="OS[X"> <strong>Share-Captioner (정확한 설명)</strong> </td> </tr> <tr id="198451cf-7b79-8046-9264-eaa64c9255c9"> <td class="" id="k:ap"> <strong>CLIP Score</strong> </td> <td class="" id="dz&gt;|">0.2787</td> <td class="" id="OS[X"> <strong>0.2797 (향상됨)</strong> </td> </tr> <tr id="198451cf-7b79-808c-913b-d00e8ef74ed4"> <td class="" id="k:ap"> <strong>환각 문제 해결</strong> </td> <td class="" id="dz&gt;|">일부 존재</td> <td class="" id="OS[X"> <strong>환각 감소 (더 정밀한 캡션 사용)</strong> </td> </tr> </tbody></table> <p class="" id="198451cf-7b79-80e2-a725-d5aaa614509c">➡  <strong>PixArt-Σ는 더 긴 문장을 해석하고, 더 정교한 캡션을 사용하여 텍스트-이미지 정렬 성능을 높였음</strong>.</p> <p class="" id="198451cf-7b79-80f6-826c-e0f1bc0b8c01">➡  <strong>Share-Captioner를 사용하여 텍스트와 이미지 간 정보 일치도를 개선</strong>함.</p> <p class="" id="198451cf-7b79-8025-9e40-fd291a222d6b"> </p> <h3 class="" id="198451cf-7b79-808e-be20-f1c17483c338">평가 데이터셋 구성 (High-Quality Evaluation Dataset)</h3> <li style="list-style-type:disc">기존 모델들이 사용하는  <strong>MSCOCO 데이터셋은 예술적 품질과 텍스트-이미지 정렬을 평가하기에 충분하지 않음</strong>.</li> <li style="list-style-type:disc">따라서 PixArt-Σ는  <strong>새로운 평가 데이터셋(30,000개 샘플) 구축</strong>.</li> <li style="list-style-type:disc">평가 항목:<ol class="numbered-list" id="198451cf-7b79-8003-89f5-c0abf99ff796" start="1" type="1"><li> <strong>Fréchet Inception Distance (FID)</strong> → 이미지 품질 평가</li></ol> <ol class="numbered-list" id="198451cf-7b79-80a2-b92d-e8a45717310e" start="2" type="1"><li> <strong>CLIP Score</strong> → 텍스트-이미지 정렬 성능 평가</li></ol> </li> <figure class="image" id="198451cf-7b79-8081-a740-d196f7dc6842"><picture><img class="img-fluid rounded z-depth-1" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" src="/files/2025-02-09-pixart-sigma/image%201.webp" style="width:709.9921875px"></picture></figure> <p class="" id="198451cf-7b79-80c0-b162-f80a0b19ea6d"> </p> <h2 class="" id="198451cf-7b79-80b8-ae3c-d5fcacbb1181">3.2 Efficient DiT Design</h2> <h3 class="" id="198451cf-7b79-80e2-8888-c17a52a8ee63"> <strong>Key-Value (KV) Token Compression 기법</strong> </h3> <p class="" id="198451cf-7b79-8049-9263-f5e57018fa91"> <strong>🔹 기존 Attention 연산 문제</strong></p> <li style="list-style-type:disc">Self-Attention은  <strong>Query(Q), Key(K), Value(V)의 곱을 계산</strong>하는 방식이므로,토큰 개수가 많아질수록  <strong>연산량이 O(N²)으로 증가</strong>함.</li> <li style="list-style-type:disc"> <strong>해결 방법</strong>: Key와 Value 토큰을 압축하여 연산량을 줄임.</li> <p class="" id="198451cf-7b79-80c4-b162-ebc204c2c617"> <strong>🔹 PixArt-Σ의 KV Token Compression 방식</strong></p> <figure class="equation" id="230451cf-7b79-80f5-be60-edfdfb4a39fb"><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style> <div class="equation-container"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>Attention</mtext><mo stretchy="false">(</mo><mi>Q</mi><mo separator="true">,</mo><mi>K</mi><mo separator="true">,</mo><mi>V</mi><mo stretchy="false">)</mo><mo>=</mo><mtext>softmax</mtext><mrow><mo fence="true">(</mo><mfrac><mrow><mi>Q</mi><mo>⋅</mo><msub><mi>f</mi><mi>c</mi></msub><mo stretchy="false">(</mo><mi>K</mi><msup><mo stretchy="false">)</mo><mi>T</mi></msup></mrow><msqrt><msub><mi>d</mi><mi>k</mi></msub></msqrt></mfrac><mo fence="true">)</mo></mrow><msub><mi>f</mi><mi>c</mi></msub><mo stretchy="false">(</mo><mi>V</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\text{Attention}(Q, K, V) = \text{softmax}\left( \frac{Q \cdot f_c(K)^T}{\sqrt{d_k}} \right) f_c(V)</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">Attention</span></span><span class="mopen">(</span><span class="mord mathnormal">Q</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.4684em;vertical-align:-0.95em;"></span><span class="mord text"><span class="mord">softmax</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size3">(</span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.5183em;"><span style="top:-2.2528em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8572em;"><span class="svg-align" style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord" style="padding-left:0.833em;"><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-2.8172em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail" style="min-width:0.853em;height:1.08em;"><svg height="1.08em" preserveaspectratio="xMinYMin slice" viewbox="0 0 400000 1080" width="400em" xmlns="http://www.w3.org/2000/svg"><path d="M95,702 c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14 c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54 c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10 s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429 c69,-144,104.5,-217.7,106.5,-221 l0 -0 c5.3,-9.3,12,-14,20,-14 H400000v40H845.2724 s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7 c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z M834 80h400000v40h-400000z"></path></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1828em;"><span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.1076em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.93em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size3">)</span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.1076em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mclose">)</span></span></span></span></span></div></figure> <li style="list-style-type:disc"> <strong>PixArt-Σ (토큰 압축 적용)</strong>:</li> <li style="list-style-type:circle">Key(K)와 Value(V)를  <strong>Stride 2의 Group Convolution</strong>을 사용해 압축</li> <li style="list-style-type:circle">이를 통해 토큰 개수를  <strong>N → N/R^2 으로 줄임</strong> </li> <li style="list-style-type:circle">정확도가 크게 떨어지지 않는 선에서 R을 조정 (1~4)하기</li> <li style="list-style-type:circle">최종적으로  <strong>연산량을 기존 대비 약 34% 절감</strong> </li> <p class="" id="198451cf-7b79-8049-9ab7-f2a09ab8e72c">  <strong>핵심 효과</strong></p> <li style="list-style-type:disc"> <strong>4K 해상도 이미지 생성 속도 향상</strong> (연산량 감소)</li> <li style="list-style-type:disc"> <strong>메모리 사용량 감소 → 더 작은 GPU에서도 실행 가능</strong> </li> <li style="list-style-type:disc"> <strong>기존 PixArt-α 모델에서 자연스럽게 업그레이드 가능</strong> (기존 모델의 가중치를 활용)</li> <p class="" id="198451cf-7b79-80d8-8f6b-d3d2449972f5"> </p> <div class="column-list" id="198451cf-7b79-809a-ac9f-d17f72b6045b"> <div class="column" id="198451cf-7b79-8071-9b2c-c5a415a72560" style="width:31.25%"><figure class="image" id="198451cf-7b79-8086-824b-e53cc50346f3"><picture><img class="img-fluid rounded z-depth-1" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" src="/files/2025-02-09-pixart-sigma/image%202.webp" style="width:384px"></picture></figure></div> <div class="column" id="198451cf-7b79-8081-ab48-dd6e6c89f2de" style="width:68.75%"><figure class="image" id="198451cf-7b79-8021-88a9-e77e27d26536"><picture><img class="img-fluid rounded z-depth-1" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" src="/files/2025-02-09-pixart-sigma/image%203.webp" style="width:414.984375px"></picture></figure></div> </div> <p class="" id="198451cf-7b79-80b5-9ee9-ed637f7cb885"> </p> <h2 class="" id="198451cf-7b79-809c-b328-de46d4823a87"><mark class="highlight-red_background">3.3 Weak-to-Strong Training Strategy</mark></h2> <p class="" id="198451cf-7b79-808a-acef-c10179883a61">PixArt-Σ의 Weak-to-Strong Training은  <strong>기존 모델의 가중치를 활용하여 빠르게 적응하도록 설계됨</strong>.</p> <p class="" id="198451cf-7b79-80c3-9764-c9e7f02bbfe9">이 과정에서  <strong>3단계의 학습 전략</strong>이 적용됨.</p> <h3 class="" id="198451cf-7b79-8065-9a2f-eeba0942ed68"> <strong>(1) VAE 적응 (VAE Adaptation)</strong> </h3> <li style="list-style-type:disc">PixArt-α에서 사용하던 기존 VAE를  <strong>Stable Diffusion XL(SDXL)의 VAE로 교체</strong> </li> <li style="list-style-type:disc"> <strong>VAE 교체 후 빠른 적응을 위해 2K Training Steps 만에 수렴하도록 학습 전략 적용</strong>.</li> <li style="list-style-type:disc">새로운 VAE 적용 후에도  <strong>기존 모델의 가중치를 재사용하여 빠르게 학습 가능</strong>.</li> <figure class="image" id="198451cf-7b79-80fd-9882-fd418e35e033"><picture><img class="img-fluid rounded z-depth-1" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" src="/files/2025-02-09-pixart-sigma/image%204.webp" style="width:192px"></picture></figure> <h3 class="" id="198451cf-7b79-8089-ab89-e83180516114"> <strong>(2) 해상도 업그레이드 (Resolution Upscaling)</strong> </h3> <li style="list-style-type:disc">256px → 512px → 1024px → 4K로 점진적으로 해상도를 증가시키며 학습.</li> <p class="" id="198451cf-7b79-8041-8bb3-c3d39baceb06"> </p> <li style="list-style-type:disc"> <strong>PE Interpolation</strong>(위치 임베딩 보간법)을 적용하여, 기존 해상도의 가중치를 새 해상도에서도 자연스럽게 사용 가능하도록 조정.</li> <li style="list-style-type:circle">보간법 (Interpolation)은  <strong>알려진 값을 기반으로 값을 계산하는 프로세스</strong> </li> <li style="list-style-type:circle">Transformer 기반 모델(예: DiT, ViT 등)은  <strong>입력 이미지의 각 위치 정보를 표현하기 위해 위치 임베딩을 사용</strong>.</li> <li style="list-style-type:circle">모델이 256×256에서 학습되었다면,  <strong>256×256 해상도에 최적화된 위치 임베딩을 학습함</strong>.</li> <li style="list-style-type:circle">하지만 해상도를 1024×1024로 증가시키면,  <strong>기존 256×256 위치 임베딩과 구조가 달라져 모델 성능이 급격히 저하됨</strong>.</li> <li style="list-style-type:circle">기존 위치 임베딩을 1024×1024 크기로 보간(interpolation)</li> <li style="list-style-type:circle">즉, 256개의 값을 1024개로 확장하는 과정에서 자연스럽게 매끄러운 값으로 변환됨.</li> <li style="list-style-type:circle">이를 통해 새로운 해상도에서도 기존 모델의 공간 정보가 유지됨.</li> <p class="" id="198451cf-7b79-80f3-8aec-ce3be5a8bf54"> </p> <li style="list-style-type:disc"> <strong>단 1000 Training Steps만으로도 해상도 증가에 적응 가능</strong>.</li> <figure class="image" id="198451cf-7b79-8079-b2a7-f961c1a116f2"><picture><img class="img-fluid rounded z-depth-1" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" src="/files/2025-02-09-pixart-sigma/image%205.webp" style="width:336px"></picture></figure> <h3 class="" id="198451cf-7b79-8021-804d-dbb1290586b1"> <strong>(3) KV Token Compression 도입 (연산 최적화)</strong> </h3> <li style="list-style-type:disc">PixArt-Σ 모델은 KV Token Compression을 적용했음</li> <li style="list-style-type:disc"> <span style="border-bottom:0.05em solid">하지만 </span> <strong><span style="border-bottom:0.05em solid">기존 모델과 구조가 달라서 성능 저하 위험이 있음</span></strong><span style="border-bottom:0.05em solid">.</span> </li> <li style="list-style-type:disc">PixArt-Σ에서는  <strong>기존 모델에서 자연스럽게 적응하도록 "Conv Avg Init." 전략 적용</strong>.</li> <h3 class="" id="198451cf-7b79-80a9-a350-e200bda87902"> <strong>평균 연산(Averaging) 기반 초기화</strong> </h3> <li style="list-style-type:disc"> <strong>Conv Avg Init은 가중치 값을 </strong><code> <strong>1/R²</strong></code> <strong>로 설정하여, 기존 정보를 최대한 유지하면서 부드럽게 전환함</strong>.</li> <li style="list-style-type:disc"> <strong>즉, 단순히 압축하는 것이 아니라 기존 공간 정보를 최대한 보존하는 방식</strong>.</li> <p class="" id="198451cf-7b79-8089-b96e-f0e7e4db6b4b"> </p> <li style="list-style-type:disc">초기에는 압축 없이 학습 후,  <strong>학습이 안정화되면 KV Compression을 적용하여 연산량 감소</strong>.</li> <li style="list-style-type:disc"> <strong>4K 이미지 생성 시 연산량 34% 절감</strong>.</li> <p class="" id="198451cf-7b79-8021-a917-e67f5a6d2ffa">  <strong>결과적으로, 기존 PixArt-α 대비 적은 연산량과 빠른 학습으로 4K 이미지 생성이 가능해짐.</strong></p> <figure class="image" id="198451cf-7b79-800d-b133-d38528657563"><picture><img class="img-fluid rounded z-depth-1" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" src="/files/2025-02-09-pixart-sigma/image%206.webp" style="width:288px"></picture></figure> <p class="" id="198451cf-7b79-805c-b618-eaa6d23e9448"> </p> <p class="" id="198451cf-7b79-80d2-9295-eea09dac9e2e"> </p> <h1 class="" id="198451cf-7b79-800f-95c4-ffd719a9f131">4. Experiment</h1> <h2 class="" id="198451cf-7b79-8032-bc3b-d4e84333d747">4.1 Implementation Details (구현 세부사항)</h2> <h3 class="" id="198451cf-7b79-8096-aeb0-d3139434547a"> <strong>1. 모델 구성</strong> </h3> <p class="" id="198451cf-7b79-8072-8835-d3827b25682f">  <strong>텍스트 인코더</strong></p> <li style="list-style-type:disc"> <strong>Flan-T5-XXL 사용</strong> (Imagen 및 PixArt-α와 동일)</li> <li style="list-style-type:disc">기존 모델에서  <strong>120개 토큰</strong>을 사용하던 것을  <strong>300개 토큰까지 확장</strong>하여 더 정밀한 텍스트-이미지 정렬 가능.</li> <p class="" id="198451cf-7b79-80d3-bc34-cdd1e68aa78e">  <strong>VAE (Variational Autoencoder) 적용</strong></p> <li style="list-style-type:disc"> <strong>Stable Diffusion XL(SDXL)의 VAE 사용</strong> </li> <li style="list-style-type:disc"> <strong>더 높은 품질의 이미지 디코딩 가능</strong> → 세밀한 디테일 보존</li> <p class="" id="198451cf-7b79-801e-8dc7-f70530015975">  <strong>기반 모델</strong></p> <li style="list-style-type:disc"> <strong>PixArt-α를 베이스 모델로 사용</strong> </li> <li style="list-style-type:disc"> <strong>256px 사전 학습된 체크포인트를 활용하여 4K까지 확장</strong> </li> <p class="" id="198451cf-7b79-80d7-ab1d-f28fb1bb798b">  <strong>KV Token Compression 적용</strong></p> <li style="list-style-type:disc"> <strong>연산량 34% 절감</strong> </li> <li style="list-style-type:disc"> <strong>초고해상도(4K) 이미지 생성을 가능하게 함</strong> </li> <hr id="198451cf-7b79-8009-9d3d-c828f602e868"> <h3 class="" id="198451cf-7b79-800c-aaf2-d021f5bd42f8"> <strong>2. 학습 환경 및 하드웨어</strong> </h3> <p class="" id="198451cf-7b79-806a-98d7-c1396cbb93c7">  <strong>훈련 GPU 환경</strong></p> <li style="list-style-type:disc"> <strong>1K 모델 학습: 32 V100 GPUs 사용</strong> </li> <li style="list-style-type:disc"> <strong>2K &amp; 4K 모델 학습: 16 A100 GPUs 사용</strong> </li> <p class="" id="198451cf-7b79-80d2-9986-de3d7f458523">  <strong>최적화 알고리즘</strong></p> <li style="list-style-type:disc"> <strong>CAME Optimizer 사용</strong> (AdamW 대신)</li> <li style="list-style-type:disc"> <strong>학습률: 2e-5 (고정 Learning Rate 사용)</strong> </li> <li style="list-style-type:disc"> <strong>Weight Decay: 0</strong> </li> <p class="" id="198451cf-7b79-807d-a4aa-f5dafdfab886">  <strong>Position Embedding Interpolation (PE Interp.) 적용</strong></p> <li style="list-style-type:disc">낮은 해상도에서 학습된 모델을 고해상도로 변환할 때  <strong>위치 임베딩을 보간(interpolation)하여 적용</strong>.</li> <li style="list-style-type:disc">이를 통해  <strong>고해상도로 확장 시 성능 저하 없이 빠르게 적응 가능</strong>.</li> <hr id="198451cf-7b79-8064-ac3f-fd3b6b7d810a"> <h3 class="" id="198451cf-7b79-8071-8e2f-dd8e4d0eef7e"> <strong>3. 학습 데이터 및 훈련 과정</strong> </h3> <p class="" id="198451cf-7b79-8048-805f-c1c9dd7b6d0f">  <strong>훈련 데이터셋</strong></p> <li style="list-style-type:disc"> <strong>총 33M(3,300만 개)의 고해상도 이미지 사용</strong> </li> <li style="list-style-type:disc"> <strong>1K 해상도 이상의 데이터만 포함</strong> </li> <li style="list-style-type:disc"> <strong>4K 해상도 이미지 2.3M(230만 개) 포함</strong> </li> <li style="list-style-type:disc"> <strong>Aesthetic Scoring Model(AES) 적용하여 고품질 이미지 선별</strong> </li> <p class="" id="198451cf-7b79-8019-a79e-efc94e58a05f">  <strong>훈련 과정</strong></p> <li style="list-style-type:disc"> <strong>256px → 512px → 1024px → 4K 해상도로 점진적 업스케일링 적용</strong> </li> <li style="list-style-type:disc"> <strong>VAE 교체 후 2K Training Steps 내 빠르게 적응</strong> </li> <li style="list-style-type:disc"> <strong>PE Interpolation을 적용하여 고해상도에서 추가 학습 비용 절감</strong> </li> <p class="" id="198451cf-7b79-80e6-b2c4-e913e9e4dc26">  <strong>학습 비용 절감</strong></p> <li style="list-style-type:disc">기존 PixArt-α 대비  <strong>훈련 비용 9%만 사용하여 1K 생성 가능</strong> </li> <li style="list-style-type:disc"> <strong>KV Compression과 Weak-to-Strong Training을 결합하여 GPU 비용 절감</strong> </li> <p class="" id="198451cf-7b79-80b9-951b-fadb2f30e750"> </p> <p class="" id="198451cf-7b79-804c-8654-e422359a61ed"> </p> <h2 class="" id="198451cf-7b79-8031-8186-e079612487c8">4.2 실험 결과</h2> <h2 class="" id="198451cf-7b79-8033-86bc-c5fa7d3ddf32"> <strong>1. 이미지 품질 비교 (Qualitative Evaluation)</strong> </h2> <p class="" id="198451cf-7b79-8019-a5e5-dd97375bd5a0">PixArt-Σ는  <strong>포토리얼리즘(Photorealism), 디테일 수준, 스타일 다양성 측면에서 이전 모델보다 개선됨</strong>.</p> <p class="" id="198451cf-7b79-807a-85ee-eee09855d05a">아래와 같은 모델들과 비교됨:</p> <p class="" id="198451cf-7b79-803d-9ffa-c213b7134331"> </p> <figure class="image" id="198451cf-7b79-80f8-a191-f350b29fb79b"><picture><img class="img-fluid rounded z-depth-1" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" src="/files/2025-02-09-pixart-sigma/image%207.webp" style="width:480px"></picture></figure> <p class="" id="198451cf-7b79-80ac-8b3a-ef886b806396"> </p> <p class="" id="198451cf-7b79-80c4-a33b-e3c3c02712c2"> </p> <p class="" id="198451cf-7b79-80d8-bb97-ebb9a12132bd"> </p> <p class="" id="198451cf-7b79-8097-9a94-fa82db11526f"> </p> <p class="" id="198451cf-7b79-8059-825b-c6da0f5e1608"> </p> <p class="" id="198451cf-7b79-8048-ba4b-f63f89d79a78"> </p> <p class="" id="198451cf-7b79-8021-afee-d074f3cdb3f7"> </p> <h2 class="" id="198451cf-7b79-80f5-bba3-dc0e70703ea5">PixArt-α vs PixArt-Σ</h2> <table class="simple-table" id="198451cf-7b79-80a1-91fc-c9ca2a989170"><tbody> <tr id="198451cf-7b79-80d5-8a3d-cdbb1afe4fbd"> <td class="" id="JUp^">항목</td> <td class="" id="uy=K">PixArt-α (기존)</td> <td class="" id="]wOL" style="width:445px">PixArt-Σ (개선)</td> </tr> <tr id="198451cf-7b79-801c-90ce-d97324fab877"> <td class="" id="JUp^"> <strong>최대 해상도</strong> </td> <td class="" id="uy=K">1K (1024×1024)</td> <td class="" id="]wOL" style="width:445px"> <strong>4K (3840×2160) 지원</strong> </td> </tr> <tr id="198451cf-7b79-8085-9dc3-c4f934462637"> <td class="" id="JUp^"> <strong>연산량 최적화</strong> </td> <td class="" id="uy=K">없음</td> <td class="" id="]wOL" style="width:445px"> <strong>KV Token Compression 적용 (연산량 34% 감소)</strong> </td> </tr> <tr id="198451cf-7b79-808b-bf72-fa56cbecb820"> <td class="" id="JUp^"> <strong>VAE 모델</strong> </td> <td class="" id="uy=K">기본 VAE</td> <td class="" id="]wOL" style="width:445px"> <strong>SDXL VAE로 변경 (고품질 이미지 생성 가능)</strong> </td> </tr> <tr id="198451cf-7b79-8084-9874-e11b7d11ea6b"> <td class="" id="JUp^"> <strong>학습 전략</strong> </td> <td class="" id="uy=K">일반 학습</td> <td class="" id="]wOL" style="width:445px"> <strong>Weak-to-Strong Training (기존 모델 활용하여 빠르게 학습)</strong> </td> </tr> <tr id="198451cf-7b79-8072-aa76-eb1cd79052dd"> <td class="" id="JUp^"> <strong>텍스트 길이</strong> </td> <td class="" id="uy=K">120 토큰</td> <td class="" id="]wOL" style="width:445px"> <strong>300 토큰으로 확장 (더 정밀한 텍스트-이미지 정렬 가능)</strong> </td> </tr> <tr id="198451cf-7b79-80f0-9182-ec33f1eb9196"> <td class="" id="JUp^"> <strong>훈련 비용</strong> </td> <td class="" id="uy=K">높음</td> <td class="" id="]wOL" style="width:445px"> <strong>기존 대비 GPU 비용 9%로 절감</strong> </td> </tr> </tbody></table> <p class="" id="198451cf-7b79-8064-ae7e-cd23c918bd8a"> </p> <h3 class="" id="198451cf-7b79-8058-83a4-ed7ec9583819"> <strong>PixArt-Σ vs. MobileDiffusion 비교표</strong> </h3> <table class="simple-table" id="198451cf-7b79-800e-a4b6-d16e8b84b775"><tbody> <tr id="198451cf-7b79-8001-b9f3-c1b642e098d6"> <td class="" id="VJ[n">항목</td> <td class="" id="NDDF"> <strong>PixArt-Σ</strong> </td> <td class="" id="c|J;"> <strong>MobileDiffusion</strong> </td> <td class="" id="?As&gt;">비교</td> </tr> <tr id="198451cf-7b79-8095-865a-fedcff4a52be"> <td class="" id="VJ[n"> <strong>목표</strong> </td> <td class="" id="NDDF"> <strong>4K 초고해상도 이미지 생성</strong> </td> <td class="" id="c|J;"> <strong>모바일에서 실시간 생성 가능하도록 최적화</strong> </td> <td class="" id="?As&gt;">PixArt-Σ는 초고해상도 생성, MobileDiffusion은 On-Device 최적화</td> </tr> <tr id="198451cf-7b79-8030-bd88-d541063ff8e4"> <td class="" id="VJ[n"> <strong>모델 구조</strong> </td> <td class="" id="NDDF"> <strong>Diffusion Transformer (DiT)</strong> 기반</td> <td class="" id="c|J;"> <strong>Latent Diffusion + Optimized UNet</strong> </td> <td class="" id="?As&gt;">PixArt-Σ는 Transformer 기반, MobileDiffusion은 UNet 기반</td> </tr> <tr id="198451cf-7b79-8083-80c5-cc9bad65f7ae"> <td class="" id="VJ[n"> <strong>텍스트 인코더</strong> </td> <td class="" id="NDDF"> <strong>Flan-T5-XXL (300 토큰까지 가능)</strong> </td> <td class="" id="c|J;"> <strong>CLIP-ViT/L14 (텍스트-이미지 효율성 극대화)</strong> </td> <td class="" id="?As&gt;">PixArt-Σ가 더 긴 텍스트 입력 가능, MobileDiffusion은 가벼움</td> </tr> <tr id="198451cf-7b79-8083-837f-c2c385125a0a"> <td class="" id="VJ[n"> <strong>이미지 해상도</strong> </td> <td class="" id="NDDF"> <strong>4K (3840×2160) 직접 생성 가능</strong> </td> <td class="" id="c|J;"> <strong>512×512 (On-Device에서 빠르게 생성)</strong> </td> <td class="" id="?As&gt;">PixArt-Σ는 초고해상도, MobileDiffusion은 저해상도 최적화</td> </tr> <tr id="198451cf-7b79-803d-bb02-e9287fd93d35"> <td class="" id="VJ[n"> <strong>KV Token Compression</strong> </td> <td class="" id="NDDF"> <strong>Self-Attention 연산량 34% 절감 (R=2, R=4 적용)</strong> </td> <td class="" id="c|J;">❌ 사용하지 않음</td> <td class="" id="?As&gt;">PixArt-Σ는 4K 최적화, MobileDiffusion은 경량 모델이라 필요 없음</td> </tr> <tr id="198451cf-7b79-8042-9835-d0eb7808a997"> <td class="" id="VJ[n"> <strong>모델 크기</strong> </td> <td class="" id="NDDF"> <strong>0.6B 파라미터 (SDXL: 2.6B 대비 작음)</strong> </td> <td class="" id="c|J;"> <strong>386M (SD-1.5 대비 55% 축소)</strong> </td> <td class="" id="?As&gt;">MobileDiffusion이 더 작음</td> </tr> <tr id="198451cf-7b79-802e-80b0-e7547504eb6b"> <td class="" id="VJ[n"> <strong>VAE (Autoencoder)</strong> </td> <td class="" id="NDDF"> <strong>SDXL VAE 사용 (고품질 이미지 복원 가능)</strong> </td> <td class="" id="c|J;"> <strong>경량화된 VAE 적용 (512px에서 최적화됨)</strong> </td> <td class="" id="?As&gt;">PixArt-Σ는 품질 우선, MobileDiffusion은 속도 우선</td> </tr> <tr id="198451cf-7b79-807d-a27c-e0c6c6d78ee5"> <td class="" id="VJ[n"> <strong>해상도 업스케일링 기법</strong> </td> <td class="" id="NDDF"> <strong>PE Interpolation (기존 모델을 고해상도로 자연스럽게 변환)</strong> </td> <td class="" id="c|J;"> <strong>512px 고정 (Upscaling 없음)</strong> </td> <td class="" id="?As&gt;">PixArt-Σ는 해상도 확장 가능, MobileDiffusion은 저해상도 고정</td> </tr> <tr id="198451cf-7b79-80eb-ab58-f90c0ad23c61"> <td class="" id="VJ[n"> <strong>연산 최적화</strong> </td> <td class="" id="NDDF"> <strong>Weak-to-Strong Training (기존 모델 재사용으로 학습 비용 절감)</strong> </td> <td class="" id="c|J;"> <strong>Transformer 블록 제거 + Convolution 기반 최적화</strong> </td> <td class="" id="?As&gt;">PixArt-Σ는 기존 모델 활용, MobileDiffusion은 경량화 모델</td> </tr> <tr id="198451cf-7b79-8048-a2eb-eb05e085150c"> <td class="" id="VJ[n"> <strong>On-Device 실행 가능 여부</strong> </td> <td class="" id="NDDF">❌ 불가능 (고성능 GPU 필요)</td> <td class="" id="c|J;"> 가능 (iPhone 15 Pro에서 0.2초 생성)</td> <td class="" id="?As&gt;">MobileDiffusion이 훨씬 가벼움</td> </tr> <tr id="198451cf-7b79-80f1-9f3a-dcc59c45605f"> <td class="" id="VJ[n"> <strong>학습 데이터 크기</strong> </td> <td class="" id="NDDF"> <strong>33M (4K 데이터 포함, SD v1.5의 1.65%)</strong> </td> <td class="" id="c|J;"> <strong>150M (모바일 최적화된 데이터)</strong> </td> <td class="" id="?As&gt;">MobileDiffusion이 더 큰 데이터셋 사용</td> </tr> <tr id="198451cf-7b79-80e3-81e4-fe4efcbf9786"> <td class="" id="VJ[n"> <strong>이미지 품질 평가 (FID Score)</strong> </td> <td class="" id="NDDF"> <strong>8.23 (PixArt-α 대비 개선됨)</strong> </td> <td class="" id="c|J;"> <strong>11.67 (1-step) / 8.65 (50-step DDIM)</strong> </td> <td class="" id="?As&gt;">PixArt-Σ가 품질 우수, MobileDiffusion은 속도 최적화</td> </tr> <tr id="198451cf-7b79-80d3-ae36-e21ddc1797e0"> <td class="" id="VJ[n"> <strong>텍스트-이미지 정렬 (CLIP Score)</strong> </td> <td class="" id="NDDF"> <strong>0.2797 (PixArt-α 대비 향상됨)</strong> </td> <td class="" id="c|J;"> <strong>0.320 (1-step) / 0.325 (50-step DDIM)</strong> </td> <td class="" id="?As&gt;">MobileDiffusion이 더 나은 정렬 성능</td> </tr> <tr id="198451cf-7b79-80a1-9e7c-df04d417474b"> <td class="" id="VJ[n"> <strong>생성 속도</strong> </td> <td class="" id="NDDF">❌ 느림 (4K 생성에 고사양 GPU 필요)</td> <td class="" id="c|J;"> 0.2초 (iPhone 15 Pro에서 실시간 생성)</td> <td class="" id="?As&gt;">MobileDiffusion이 훨씬 빠름</td> </tr> </tbody></table> <p class="" id="199451cf-7b79-80a2-87bf-f11582cac427"> </p> <p class="" id="199451cf-7b79-8008-aee9-f50ebb0f8f2e"> </p> <p class="" id="199451cf-7b79-80c9-ab6a-cf2219553053"> </p> <p class="" id="199451cf-7b79-8073-88ff-f336107e89e2"> </p> <p class="" id="199451cf-7b79-8068-8550-e9600a5a0703"> </p> <p class="" id="199451cf-7b79-80fd-8c46-ebe12d66d827"> </p> <p><span class="sans" style="font-size:14px;padding-top:2em"></span></p> </div> </article> <br><br><br><br> <div id="giscus_thread" style="max-width: 930px; margin: 0 auto;"> <script>
      let giscusTheme = determineComputedTheme();
      let giscusAttributes = {
        src: 'https://giscus.app/client.js',
        'data-repo': 'hoonably/hoonably.github.io',
        'data-repo-id': 'R_kgDOPBaE1Q',
        'data-category': 'Comments',
        'data-category-id': 'DIC_kwDOPBaE1c4Cr9sR',
        'data-mapping': 'title',
        'data-strict': '1',
        'data-reactions-enabled': '0',
        'data-emit-metadata': '0',
        'data-input-position': 'bottom',
        'data-theme': giscusTheme,
        'data-lang': 'ko',
        crossorigin: 'anonymous',
        async: '',
      };

      let giscusScript = document.createElement('script');
      Object.entries(giscusAttributes).forEach(([key, value]) => giscusScript.setAttribute(key, value));
      document.getElementById('giscus_thread').appendChild(giscusScript);
    </script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> <br><br><br><br> </div> </div> </div> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Jeonghoon Park. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script defer src="/assets/js/bootstrap-toc.min.js?c82ff4de8b0955d6ff14f5b05eed7eb6"></script> <script defer src="https://cdn.jsdelivr.net/npm/bootstrap-table@1.22.4/dist/bootstrap-table.min.js" integrity="sha256-4rppopQE9POKfukn2kEvhJ9Um25Cf6+IDVkARD0xh78=" crossorigin="anonymous"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>