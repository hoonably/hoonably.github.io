<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta name="google-site-verification" content=""> <meta http-equiv="Permissions-Policy" content="interest-cohort=()"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Tiny LLM | Jeonghoon Park </title> <meta name="author" content="Jeonghoon Park"> <meta name="description" content="Investigating LLMs that can run in resource-constrained environments (such as on-device) and analyzed the accuracy and inference time of each model through various evaluation sets"> <meta name="keywords" content="UNIST, computer science, undergraduate, on-device AI, optimization, problem solving"> <meta http-equiv="Cache-Control" content="no-cache, no-store, must-revalidate"> <meta http-equiv="Pragma" content="no-cache"> <meta http-equiv="Expires" content="0"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-table@1.22.4/dist/bootstrap-table.min.css" integrity="sha256-uRX+PiRTR4ysKFRCykT8HLuRCub26LgXJZym3Yeom1c=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link defer href="/assets/css/bootstrap-toc.min.css?6f5af0bb9aab25d79b2448143cbeaa88" rel="stylesheet"> <link rel="shortcut icon" href="/assets/img/profile/profile.webp?b5bec9d555338d1029578e54703400f7"> <link rel="stylesheet" href="/assets/css/pretendard-subset.css"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://jeonghoonpark.com/projects/tinyllm/"> <script src="/assets/js/theme.js?c06f90403cefcf6ac822b3d318259fcc"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-dark.css?7f7b80282ea53f5dd6b976ff3d9857f9" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Jeonghoon Park </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">projects <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="row"> <div class="col-sm-3"> <nav id="toc-sidebar" class="sticky-top"></nav> </div> <div class="col-sm-9"> <div class="pagein"> <div class="post"> <header class="post-header"> <h1 class="post-title">Tiny LLM</h1> <p class="post-description">Investigating LLMs that can run in resource-constrained environments (such as on-device) and analyzed the accuracy and inference time of each model through various evaluation sets</p> </header> <article> <div class="repo p-2 text-center"> <a href="https://github.com/unist-uai/TinyLLM" rel="external nofollow noopener" target="_blank"> <img class="only-light w-100" alt="unist-uai/TinyLLM" src="https://github-readme-stats.vercel.app/api/pin/?username=unist-uai&amp;repo=TinyLLM&amp;theme=default&amp;locale=en&amp;show_owner=false&amp;description_lines_count=2"> <img class="only-dark w-100" alt="unist-uai/TinyLLM" src="https://github-readme-stats.vercel.app/api/pin/?username=unist-uai&amp;repo=TinyLLM&amp;theme=dark&amp;locale=en&amp;show_owner=false&amp;description_lines_count=2"> </a> </div> <blockquote class="block-tip"> <p><strong>📄 Notion (Korean):</strong> <a href="https://foil-plant-837.notion.site/tinyllm" rel="external nofollow noopener" target="_blank">Notion - TinyLLM</a></p> </blockquote> <hr> <p>You can see what I worked on through the Notion link above. I will only include the <strong>Result</strong> and <strong>Comments</strong> here.</p> <h3 id="models">Models</h3> <table> <thead> <tr> <th>Model Name</th> <th>Affiliation</th> <th>Model Size</th> <th>Release Date</th> <th>🔗 Link</th> </tr> </thead> <tbody> <tr> <td>Bloom</td> <td>BigScience</td> <td>560M</td> <td>2022.11</td> <td><a href="https://huggingface.co/bigscience/bloom-560m" rel="external nofollow noopener" target="_blank">Bloom</a></td> </tr> <tr> <td>Bloomz</td> <td>BigScience</td> <td>560M</td> <td>2022.11</td> <td><a href="https://huggingface.co/bigscience/bloomz-560m" rel="external nofollow noopener" target="_blank">Bloomz</a></td> </tr> <tr> <td>Cerebras-GPT</td> <td>Cerebras</td> <td>590M</td> <td>2023.03</td> <td><a href="https://huggingface.co/cerebras/Cerebras-GPT-590M" rel="external nofollow noopener" target="_blank">Cerebras-GPT</a></td> </tr> <tr> <td>Cerebras-GPT</td> <td>Cerebras</td> <td>256M</td> <td>2023.03</td> <td><a href="https://huggingface.co/cerebras/Cerebras-GPT-256M" rel="external nofollow noopener" target="_blank">Cerebras-GPT</a></td> </tr> <tr> <td>Cerebras-GPT</td> <td>Cerebras</td> <td>111M</td> <td>2023.03</td> <td><a href="https://huggingface.co/cerebras/Cerebras-GPT-111M" rel="external nofollow noopener" target="_blank">Cerebras-GPT</a></td> </tr> <tr> <td>Danube3</td> <td>H2O</td> <td>500M</td> <td>2024.07</td> <td><a href="https://huggingface.co/h2oai/h2o-danube3-500m-base" rel="external nofollow noopener" target="_blank">Danube3</a></td> </tr> <tr> <td>Flan-T5</td> <td>Google</td> <td>Base</td> <td>2023.01</td> <td><a href="https://huggingface.co/google/flan-t5-base" rel="external nofollow noopener" target="_blank">Flan-T5</a></td> </tr> <tr> <td>LaMini-GPT</td> <td>MBZUAI</td> <td>774M</td> <td>2023.04</td> <td><a href="https://huggingface.co/MBZUAI/LaMini-GPT-774M" rel="external nofollow noopener" target="_blank">LaMini-GPT</a></td> </tr> <tr> <td>LaMini-GPT</td> <td>MBZUAI</td> <td>124M</td> <td>2023.04</td> <td><a href="https://huggingface.co/MBZUAI/LaMini-GPT-124M" rel="external nofollow noopener" target="_blank">LaMini-GPT</a></td> </tr> <tr> <td>LiteLlama</td> <td>ahxt</td> <td>460M</td> <td>N/A</td> <td><a href="https://huggingface.co/ahxt/LiteLlama-460M-1T" rel="external nofollow noopener" target="_blank">LiteLlama</a></td> </tr> <tr> <td>OPT</td> <td>Meta</td> <td>350M</td> <td>2022.05</td> <td><a href="https://huggingface.co/facebook/opt-350m" rel="external nofollow noopener" target="_blank">OPT</a></td> </tr> <tr> <td>OPT</td> <td>Meta</td> <td>125M</td> <td>2022.05</td> <td><a href="https://huggingface.co/facebook/opt-125m" rel="external nofollow noopener" target="_blank">OPT</a></td> </tr> <tr> <td>Pythia</td> <td>EleutherAI</td> <td>410M</td> <td>2023.03</td> <td><a href="https://huggingface.co/EleutherAI/pythia-410m" rel="external nofollow noopener" target="_blank">Pythia</a></td> </tr> <tr> <td>Pythia</td> <td>EleutherAI</td> <td>160M</td> <td>2023.03</td> <td><a href="https://huggingface.co/EleutherAI/pythia-160m" rel="external nofollow noopener" target="_blank">Pythia</a></td> </tr> <tr> <td>PhoneLM</td> <td>mllmTeam</td> <td>0.5B</td> <td>2024.11</td> <td><a href="https://huggingface.co/mllmTeam/PhoneLM-0.5B" rel="external nofollow noopener" target="_blank">PhoneLM</a></td> </tr> <tr> <td>Qwen1.5</td> <td>Alibaba</td> <td>0.5B</td> <td>2024.02</td> <td><a href="https://huggingface.co/Qwen/Qwen1.5-0.5B" rel="external nofollow noopener" target="_blank">Qwen1.5</a></td> </tr> <tr> <td>Qwen2.5</td> <td>Alibaba</td> <td>0.5B</td> <td>2024.09</td> <td><a href="https://huggingface.co/Qwen/Qwen2.5-0.5B" rel="external nofollow noopener" target="_blank">Qwen2.5</a></td> </tr> <tr> <td>SmolLM</td> <td>Hugging Face</td> <td>360M</td> <td>2024.07</td> <td><a href="https://huggingface.co/HuggingFaceTB/SmolLM-360M" rel="external nofollow noopener" target="_blank">SmolLM</a></td> </tr> <tr> <td>SmolLM</td> <td>Hugging Face</td> <td>135M</td> <td>2024.07</td> <td><a href="https://huggingface.co/HuggingFaceTB/SmolLM-135M" rel="external nofollow noopener" target="_blank">SmolLM</a></td> </tr> <tr> <td>TinyLlama</td> <td>TinyLlama</td> <td>1.1B</td> <td>2023.12</td> <td><a href="https://huggingface.co/TinyLlama/TinyLlama_v1.1" rel="external nofollow noopener" target="_blank">TinyLlama</a></td> </tr> </tbody> </table> <h3 id="evaluation-datasets">Evaluation Datasets</h3> <table> <thead> <tr> <th>Dataset Name</th> <th>Explanation</th> <th>🔗 Link</th> </tr> </thead> <tbody> <tr> <td>ARC</td> <td>Science question dataset for QA.<br>- ARC-e : ARC-easy</td> <td><a href="https://huggingface.co/datasets/allenai/ai2_arc" rel="external nofollow noopener" target="_blank">ai2_arc</a></td> </tr> <tr> <td>OBQA</td> <td>a QA dataset modeled after open-book exams, designed to test multi-step reasoning, commonsense knowledge, and deep text comprehension.</td> <td><a href="https://huggingface.co/datasets/allenai/openbookqa" rel="external nofollow noopener" target="_blank">openbookqa</a></td> </tr> <tr> <td>BoolQ</td> <td>QA dataset for yes/no questions</td> <td><a href="https://huggingface.co/datasets/google/boolq" rel="external nofollow noopener" target="_blank">boolq</a></td> </tr> <tr> <td>PIQA</td> <td>QA dataset for physical commonsense reasoning and a corresponding</td> <td><a href="https://huggingface.co/datasets/ybisk/piqa" rel="external nofollow noopener" target="_blank">piqa</a></td> </tr> <tr> <td>SIQA</td> <td>question-answering, designed to evaluate social commonsense reasoning about people’s actions and their social implications.</td> <td><a href="https://huggingface.co/datasets/allenai/social_i_qa" rel="external nofollow noopener" target="_blank">social_i_qa</a></td> </tr> <tr> <td>WinoGrande</td> <td>fill-in-the-blank problems</td> <td><a href="https://huggingface.co/datasets/allenai/winogrande" rel="external nofollow noopener" target="_blank">winogrande</a></td> </tr> <tr> <td>HellaSwag</td> <td>Common sense natural language reasoning</td> <td><a href="https://huggingface.co/datasets/Rowan/hellaswag" rel="external nofollow noopener" target="_blank">hellaswag</a></td> </tr> </tbody> </table> <h3 id="environment">Environment</h3> <p>Jetson Orin Nano 8GB RAM <a href="https://developer.nvidia.com/embedded/learn/get-started-jetson-orin-nano-devkit" rel="external nofollow noopener" target="_blank">Link</a><br> python: 3.10.2</p> <h3 id="evaluation-result">Evaluation Result</h3> <p>nan: Failed inference (memory issue)</p> <h3 id="1-model-size-mb">1. Model Size (MB)</h3> <table> <thead> <tr> <th>Model</th> <th>Parameters</th> <th>ARC-e</th> <th>BoolQ</th> <th>OBQA</th> <th>PIQA</th> <th>SIQA</th> <th>WinoGrande</th> <th>Avg.</th> </tr> </thead> <tbody> <tr> <td>Cerebras-GPT-111M</td> <td>111M</td> <td>423.624</td> <td>423.624</td> <td>423.624</td> <td>423.624</td> <td>423.624</td> <td>423.624</td> <td>423.624</td> </tr> <tr> <td>Cerebras-GPT-256M</td> <td>256M</td> <td>976.475</td> <td>976.475</td> <td>976.475</td> <td>976.475</td> <td>976.475</td> <td>976.475</td> <td>976.475</td> </tr> <tr> <td>Cerebras-GPT-590M</td> <td>590M</td> <td>2251.86</td> <td>2251.86</td> <td>2251.86</td> <td>2251.86</td> <td>2251.86</td> <td>2251.86</td> <td>2251.86</td> </tr> <tr> <td>LaMini-GPT-124M</td> <td>124M</td> <td>474.703</td> <td>474.703</td> <td>474.703</td> <td>474.703</td> <td>474.703</td> <td>474.703</td> <td>474.703</td> </tr> <tr> <td>LaMini-GPT-774M</td> <td>774M</td> <td>2952.7</td> <td>nan</td> <td>2952.7</td> <td>nan</td> <td>nan</td> <td>2952.7</td> <td>2952.7</td> </tr> <tr> <td>LiteLlama-460M-1T</td> <td>460M</td> <td>1761.19</td> <td>1761.19</td> <td>1761.19</td> <td>1761.19</td> <td>1761.19</td> <td>1761.19</td> <td>1761.19</td> </tr> <tr> <td>Qwen1.5-0.5B</td> <td>500M</td> <td>1769.97</td> <td>1769.97</td> <td>1769.97</td> <td>nan</td> <td>1769.97</td> <td>1769.97</td> <td>1769.97</td> </tr> <tr> <td>Qwen2.5-0.5B</td> <td>500M</td> <td>1884.59</td> <td>1884.59</td> <td>1884.59</td> <td>1884.59</td> <td>1884.59</td> <td>1884.59</td> <td>1884.59</td> </tr> <tr> <td>SmolLM-135M</td> <td>135M</td> <td>513.134</td> <td>513.134</td> <td>513.134</td> <td>513.134</td> <td>513.134</td> <td>513.134</td> <td>513.134</td> </tr> <tr> <td>SmolLM-360M</td> <td>360M</td> <td>1380.24</td> <td>1380.24</td> <td>1380.24</td> <td>1380.24</td> <td>1380.24</td> <td>1380.24</td> <td>1380.24</td> </tr> <tr> <td>bloom-560m</td> <td>560M</td> <td>2133.23</td> <td>2133.23</td> <td>2133.23</td> <td>nan</td> <td>2133.23</td> <td>2133.23</td> <td>2133.23</td> </tr> <tr> <td>bloomz-560m</td> <td>560M</td> <td>2133.23</td> <td>2133.23</td> <td>2133.23</td> <td>2133.23</td> <td>2133.23</td> <td>2133.23</td> <td>2133.23</td> </tr> <tr> <td>opt-125m</td> <td>125M</td> <td>477.75</td> <td>477.75</td> <td>477.75</td> <td>477.75</td> <td>477.75</td> <td>477.75</td> <td>477.75</td> </tr> <tr> <td>opt-350m</td> <td>350M</td> <td>1263.41</td> <td>1263.41</td> <td>1263.41</td> <td>1263.41</td> <td>1263.41</td> <td>1263.41</td> <td>1263.41</td> </tr> <tr> <td>pythia-160m</td> <td>160M</td> <td>619.213</td> <td>619.213</td> <td>619.213</td> <td>619.213</td> <td>619.213</td> <td>619.213</td> <td>619.213</td> </tr> <tr> <td>pythia-410m</td> <td>410M</td> <td>1546.23</td> <td>1546.23</td> <td>1546.23</td> <td>1546.23</td> <td>1546.23</td> <td>1546.23</td> <td>1546.23</td> </tr> </tbody> </table> <h3 id="2-accuracy-">2. Accuracy (%)</h3> <table> <thead> <tr> <th>Model</th> <th>Parameters</th> <th>ARC-e</th> <th>BoolQ</th> <th>OBQA</th> <th>PIQA</th> <th>SIQA</th> <th>WinoGrande</th> <th>Avg.</th> </tr> </thead> <tbody> <tr> <td>Cerebras-GPT-111M</td> <td>111M</td> <td>26.4912</td> <td>38</td> <td>25</td> <td>49.2</td> <td>33.7</td> <td>49.5659</td> <td>36.9929</td> </tr> <tr> <td>Cerebras-GPT-256M</td> <td>256M</td> <td>26.4912</td> <td>38.1</td> <td>25</td> <td>49.2</td> <td>33.7</td> <td>49.5659</td> <td>37.0095</td> </tr> <tr> <td>Cerebras-GPT-590M</td> <td>590M</td> <td>26.4912</td> <td>37.9</td> <td>25</td> <td>49.2</td> <td>33.7</td> <td>49.5659</td> <td>36.9762</td> </tr> <tr> <td>LaMini-GPT-124M</td> <td>124M</td> <td>24.9123</td> <td>62.4</td> <td>24</td> <td>50.8</td> <td>33.1</td> <td>50.4341</td> <td>40.9411</td> </tr> <tr> <td>LaMini-GPT-774M</td> <td>774M</td> <td>32.6316</td> <td>nan</td> <td>31.2</td> <td>nan</td> <td>nan</td> <td>51.0655</td> <td>38.299</td> </tr> <tr> <td>LiteLlama-460M-1T</td> <td>460M</td> <td>25.614</td> <td>38.1</td> <td>25.2</td> <td>49.3</td> <td>34</td> <td>49.5659</td> <td>36.9633</td> </tr> <tr> <td>Qwen1.5-0.5B</td> <td>500M</td> <td>54.7368</td> <td>59.7</td> <td>42</td> <td>nan</td> <td>42.3</td> <td>50.8287</td> <td>49.9131</td> </tr> <tr> <td>Qwen2.5-0.5B</td> <td>500M</td> <td>62.807</td> <td>64.6</td> <td>44.8</td> <td>59.5</td> <td>52.3</td> <td>50.9077</td> <td>55.8191</td> </tr> <tr> <td>SmolLM-135M</td> <td>135M</td> <td>24.2105</td> <td>60.4</td> <td>25.8</td> <td>49.9</td> <td>32.8</td> <td>50.4341</td> <td>40.5908</td> </tr> <tr> <td>SmolLM-360M</td> <td>360M</td> <td>21.7544</td> <td>39.7</td> <td>23.6</td> <td>52.5</td> <td>34.3</td> <td>49.5659</td> <td>36.9034</td> </tr> <tr> <td>bloom-560m</td> <td>560M</td> <td>26.3158</td> <td>38.3</td> <td>25.8</td> <td>nan</td> <td>33.7</td> <td>49.5659</td> <td>34.7363</td> </tr> <tr> <td>bloomz-560m</td> <td>560M</td> <td>24.2105</td> <td>62.5</td> <td>21.8</td> <td>50.6</td> <td>32.9</td> <td>50.3552</td> <td>40.3943</td> </tr> <tr> <td>opt-125m</td> <td>125M</td> <td>26.4912</td> <td>43.4</td> <td>25.4</td> <td>49.4</td> <td>33.7</td> <td>49.487</td> <td>37.9797</td> </tr> <tr> <td>opt-350m</td> <td>350M</td> <td>26.3158</td> <td>38.4</td> <td>24.8</td> <td>49.9</td> <td>32.6</td> <td>49.5659</td> <td>36.9303</td> </tr> <tr> <td>pythia-160m</td> <td>160M</td> <td>26.3158</td> <td>38</td> <td>25.2</td> <td>48.6</td> <td>33</td> <td>49.2502</td> <td>36.7277</td> </tr> <tr> <td>pythia-410m</td> <td>410M</td> <td>26.3158</td> <td>37.8</td> <td>25</td> <td>49.2</td> <td>33.7</td> <td>49.6448</td> <td>36.9434</td> </tr> </tbody> </table> <figure> <picture> <img src="/assets/img/projects/tinyllm/accuracy.webp" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <h3 id="3-inference-time-ms">3. Inference Time (ms)</h3> <table> <thead> <tr> <th>Model</th> <th>Parameters</th> <th>ARC-e</th> <th>BoolQ</th> <th>OBQA</th> <th>PIQA</th> <th>SIQA</th> <th>WinoGrande</th> <th>Avg.</th> </tr> </thead> <tbody> <tr> <td>Cerebras-GPT-111M</td> <td>111M</td> <td>47.8482</td> <td>75.0534</td> <td>42.6519</td> <td>67.5944</td> <td>46.5603</td> <td>49.3566</td> <td>54.8441</td> </tr> <tr> <td>Cerebras-GPT-256M</td> <td>256M</td> <td>118.458</td> <td>197.908</td> <td>104.827</td> <td>118.09</td> <td>125.461</td> <td>76.8072</td> <td>123.592</td> </tr> <tr> <td>Cerebras-GPT-590M</td> <td>590M</td> <td>251.496</td> <td>407.803</td> <td>227.772</td> <td>279.49</td> <td>252.317</td> <td>195.598</td> <td>269.079</td> </tr> <tr> <td>LaMini-GPT-124M</td> <td>124M</td> <td>55.5167</td> <td>91.169</td> <td>50.3607</td> <td>70.0167</td> <td>53.6331</td> <td>51.48</td> <td>62.0294</td> </tr> <tr> <td>LaMini-GPT-774M</td> <td>774M</td> <td>331.246</td> <td>nan</td> <td>288.771</td> <td>nan</td> <td>nan</td> <td>241.842</td> <td>287.286</td> </tr> <tr> <td>LiteLlama-460M-1T</td> <td>460M</td> <td>173.447</td> <td>278.426</td> <td>156.089</td> <td>181.297</td> <td>173.079</td> <td>124.438</td> <td>181.129</td> </tr> <tr> <td>Qwen1.5-0.5B</td> <td>500M</td> <td>175.618</td> <td>305.815</td> <td>155.574</td> <td>nan</td> <td>174.686</td> <td>146.179</td> <td>191.574</td> </tr> <tr> <td>Qwen2.5-0.5B</td> <td>500M</td> <td>197.737</td> <td>330.037</td> <td>173.806</td> <td>213.579</td> <td>197.794</td> <td>143.201</td> <td>209.359</td> </tr> <tr> <td>SmolLM-135M</td> <td>135M</td> <td>125.591</td> <td>143.362</td> <td>124.124</td> <td>138.117</td> <td>125.266</td> <td>125.496</td> <td>130.326</td> </tr> <tr> <td>SmolLM-360M</td> <td>360M</td> <td>161.715</td> <td>274.149</td> <td>151.589</td> <td>176.19</td> <td>158.66</td> <td>143.47</td> <td>177.629</td> </tr> <tr> <td>bloom-560m</td> <td>560M</td> <td>206.418</td> <td>357.453</td> <td>178.741</td> <td>nan</td> <td>213.107</td> <td>149.083</td> <td>220.96</td> </tr> <tr> <td>bloomz-560m</td> <td>560M</td> <td>206.628</td> <td>357.817</td> <td>178.633</td> <td>257.519</td> <td>213.568</td> <td>148.324</td> <td>227.081</td> </tr> <tr> <td>opt-125m</td> <td>125M</td> <td>56.6352</td> <td>86.7192</td> <td>51.8376</td> <td>63.6035</td> <td>55.3677</td> <td>46.6623</td> <td>60.1376</td> </tr> <tr> <td>opt-350m</td> <td>350M</td> <td>144.791</td> <td>231.819</td> <td>129.27</td> <td>148.27</td> <td>142.364</td> <td>100.038</td> <td>149.425</td> </tr> <tr> <td>pythia-160m</td> <td>160M</td> <td>57.3411</td> <td>89.2453</td> <td>53.2252</td> <td>63.1686</td> <td>55.5747</td> <td>50.21</td> <td>61.4608</td> </tr> <tr> <td>pythia-410m</td> <td>410M</td> <td>153.6</td> <td>247.236</td> <td>135.242</td> <td>153.365</td> <td>150.89</td> <td>103.307</td> <td>157.273</td> </tr> </tbody> </table> <figure> <picture> <img src="/assets/img/projects/tinyllm/inference.webp" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <h3 id="4-peak-gpu-memory-usage-gb">4. Peak GPU Memory Usage (GB)</h3> <table> <thead> <tr> <th>Model</th> <th>Parameters</th> <th>ARC-e</th> <th>BoolQ</th> <th>OBQA</th> <th>PIQA</th> <th>SIQA</th> <th>WinoGrande</th> <th>Avg.</th> </tr> </thead> <tbody> <tr> <td>Cerebras-GPT-111M</td> <td>111M</td> <td>0.518592</td> <td>0.607112</td> <td>0.511304</td> <td>0.604109</td> <td>0.509212</td> <td>0.48632</td> <td>0.539441</td> </tr> <tr> <td>Cerebras-GPT-256M</td> <td>256M</td> <td>1.09269</td> <td>1.21178</td> <td>1.07552</td> <td>1.20522</td> <td>1.07341</td> <td>1.04991</td> <td>1.11809</td> </tr> <tr> <td>Cerebras-GPT-590M</td> <td>590M</td> <td>2.38433</td> <td>2.55191</td> <td>2.37</td> <td>2.54645</td> <td>2.36661</td> <td>2.33764</td> <td>2.42616</td> </tr> <tr> <td>LaMini-GPT-124M</td> <td>124M</td> <td>0.518301</td> <td>0.582409</td> <td>0.511014</td> <td>0.580349</td> <td>0.508922</td> <td>0.499037</td> <td>0.533339</td> </tr> <tr> <td>LaMini-GPT-774M</td> <td>774M</td> <td>3.03155</td> <td>nan</td> <td>3.02419</td> <td>nan</td> <td>nan</td> <td>3.01209</td> <td>3.02261</td> </tr> <tr> <td>LiteLlama-460M-1T</td> <td>460M</td> <td>1.76578</td> <td>1.83748</td> <td>1.75761</td> <td>1.83512</td> <td>1.75526</td> <td>1.74412</td> <td>1.78256</td> </tr> <tr> <td>Qwen1.5-0.5B</td> <td>500M</td> <td>1.93748</td> <td>2.19273</td> <td>1.90575</td> <td>nan</td> <td>1.89908</td> <td>1.85993</td> <td>1.959</td> </tr> <tr> <td>Qwen2.5-0.5B</td> <td>500M</td> <td>1.95148</td> <td>2.15225</td> <td>1.92665</td> <td>2.14751</td> <td>1.92128</td> <td>1.89048</td> <td>1.99828</td> </tr> <tr> <td>SmolLM-135M</td> <td>135M</td> <td>0.555858</td> <td>0.633439</td> <td>0.546275</td> <td>0.631614</td> <td>0.546517</td> <td>0.534195</td> <td>0.57465</td> </tr> <tr> <td>SmolLM-360M</td> <td>360M</td> <td>1.4055</td> <td>1.49492</td> <td>1.39445</td> <td>1.49281</td> <td>1.39473</td> <td>1.38053</td> <td>1.42716</td> </tr> <tr> <td>bloom-560m</td> <td>560M</td> <td>2.30397</td> <td>2.71227</td> <td>2.25459</td> <td>nan</td> <td>2.24332</td> <td>2.17851</td> <td>2.33853</td> </tr> <tr> <td>bloomz-560m</td> <td>560M</td> <td>2.30397</td> <td>2.71227</td> <td>2.25459</td> <td>2.71267</td> <td>2.24332</td> <td>2.17851</td> <td>2.40089</td> </tr> <tr> <td>opt-125m</td> <td>125M</td> <td>0.521742</td> <td>0.614046</td> <td>0.511907</td> <td>0.611887</td> <td>0.50906</td> <td>0.495602</td> <td>0.544041</td> </tr> <tr> <td>opt-350m</td> <td>350M</td> <td>1.30801</td> <td>1.43236</td> <td>1.29386</td> <td>1.42981</td> <td>1.28977</td> <td>1.27041</td> <td>1.33737</td> </tr> <tr> <td>pythia-160m</td> <td>160M</td> <td>0.727875</td> <td>0.838728</td> <td>0.719082</td> <td>0.834872</td> <td>0.717061</td> <td>0.689547</td> <td>0.754528</td> </tr> <tr> <td>pythia-410m</td> <td>410M</td> <td>1.7104</td> <td>1.8971</td> <td>1.68983</td> <td>1.8946</td> <td>1.6853</td> <td>1.65406</td> <td>1.75521</td> </tr> </tbody> </table> <figure> <picture> <img src="/assets/img/projects/tinyllm/gpu_usage.webp" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <hr> <h3 id="-thoughts">💬 Thoughts</h3> <p>This was the very first project I worked on after joining a research lab as an intern — and honestly, it felt like a proper first project. On my first day, I was handed a Jetson Nano and told to set it up. My first thought was: what is this? It’s so slow and frustrating! That was basically my first real encounter with Ubuntu. It felt like dealing with an old computer, but surprisingly it supported CUDA (though not the latest versions).</p> <p>At the time, I had no idea what I was even doing. Dataset? HuggingFace? What are those? I only started to get it after seeing others measuring accuracy — oh, so this is on-device AI! It’s running entirely on this GPU without any server. That’s when it clicked. When I saw models getting only 30% accuracy, I was like, is this even working? Feels like random guessing. Turns out it was because no fine-tuning had been done yet.</p> <p>It was also fascinating to learn that there are so many tiny LLMs out there, and the goal was to compare them in terms of latency and accuracy to see which ones perform best.</p> <p>I also got introduced to WandB and started learning how to write automation scripts. It was actually my first time automating anything. Since the measurements were slow and involved lots of repetition, I finally understood why automation matters. Ever since then, I’ve preferred automating workflows in all my projects.</p> <p>Looking back, I had no idea what I was doing and just followed along at first — but I think my professor intentionally gave me this as a starting point: explore whether LLMs could run on small edge devices and what kind of efficiency they could reach. But along the way, I ended up learning so many valuable things — Docker, WandB, automation, conda environments, data visualization, and more.</p> <p>It might not seem like a big deal later, but for someone who started out knowing nothing, this was a really important project. It gave me a solid foundation and made me feel like I was finally part of a research group.</p> <hr> <h3 id="-느낀-점">💬 느낀 점</h3> <p>처음으로 연구실 인턴을 시작하면서 진행한 프로젝트다. 사실상 첫 프로젝트 다운 프로젝트인 것 같다. 들어가자마자 Jetson Nano를 주셔서 세팅을 해보면서 와 이게 뭐지? 완전 느리고 답답하다! 하면서 실제 우분투를 사실상 처음 만져봤다. 옛날 컴퓨터 만지듯이 답답했는데 GPU는 또 CUDA가 지원이 되네? (물론 최신버전은 안됨)</p> <p>처음에 이게 뭐하는건지도 몰랐는데, 데이터셋? 허깅페이스? 이게 뭐지? 하다가 다른 분들이 정답률 체크하는거 보고 아! 이게 온디바이스 AI구나! 서버 없이 이 GPU로 돌리는거구나! 깨달았다. 근데 정답률 30% 나오는거보고 “이게 맞나? 찍는거랑 똑같은데?” 했는데 그냥 finetunning 안하고 돌려서 그런 것 같다. Tiny한 LLM들이 생각보다 여러가지가 있고, 그중에서 어떤 것이 Latency와 정확도가 괜찮은지 체크해보는게 신기했다.</p> <p>그러면서 MLOps인 WandB도 알게 되었고, 자동화 스크립트를 만들어서 하는 방법도 알게 되었다. 사실 자동화는 처음 써봤다. 측정이 오래걸리고 같은 작업을 반복하다보니 자동화를 왜 쓰는지 이해가 되었고, 이 이후 프로젝트에서도 자동화를 선호하게 되었다.</p> <p>얼렁뚱땅 처음에 몰라서 따라가기만 했지만, 결국 작은 On-device에서도 돌리기 위한 LLM이 있는지, 어느정도의 효율이 나오는지 알아보라고 교수님이 첫 시작을 던져준 것 같다. 근데 생각보다 Docker, WandB, 자동화, conda, 환경세팅, 데이터 시각화 등등… 다른 부분에서도 엄청난 도움이 되었다. 나중가면 별거 아닌것 처럼 보이지만, 아무것도 몰랐던 나에게 많은 정보들을 알게해준 좋은 연구실의 시작지점이라서 기억에 남는 것 같다.</p> </article> <br><br><br><br> <div id="giscus_thread" style="max-width: 930px; margin: 0 auto;"> <script>
      let giscusTheme = determineComputedTheme();
      let giscusAttributes = {
        src: 'https://giscus.app/client.js',
        'data-repo': 'hoonably/hoonably.github.io',
        'data-repo-id': 'R_kgDOPBaE1Q',
        'data-category': 'Comments',
        'data-category-id': 'DIC_kwDOPBaE1c4Cr9sR',
        'data-mapping': 'title',
        'data-strict': '1',
        'data-reactions-enabled': '0',
        'data-emit-metadata': '0',
        'data-input-position': 'bottom',
        'data-theme': giscusTheme,
        'data-lang': 'ko',
        crossorigin: 'anonymous',
        async: '',
      };

      let giscusScript = document.createElement('script');
      Object.entries(giscusAttributes).forEach(([key, value]) => giscusScript.setAttribute(key, value));
      document.getElementById('giscus_thread').appendChild(giscusScript);
    </script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> <br><br><br><br> </div> </div> </div> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Jeonghoon Park. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script defer src="/assets/js/bootstrap-toc.min.js?c82ff4de8b0955d6ff14f5b05eed7eb6"></script> <script defer src="https://cdn.jsdelivr.net/npm/bootstrap-table@1.22.4/dist/bootstrap-table.min.js" integrity="sha256-4rppopQE9POKfukn2kEvhJ9Um25Cf6+IDVkARD0xh78=" crossorigin="anonymous"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>